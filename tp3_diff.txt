diff --git a/.clang-files b/.clang-files
index 6bdb3dc..91d629f 100644
--- a/.clang-files
+++ b/.clang-files
@@ -1,6 +1,9 @@
 kern/env.c
 kern/kdebug.c
 kern/pmap.c
+kern/sched.c
 kern/syscall.c
 kern/trap.c
+lib/fork.c
+lib/ipc.c
 lib/libmain.c
diff --git a/.vscode/settings.json b/.vscode/settings.json
new file mode 100644
index 0000000..0349cd6
--- /dev/null
+++ b/.vscode/settings.json
@@ -0,0 +1,5 @@
+{
+  "files.associations": {
+    "lib.h": "c"
+  }
+}
\ No newline at end of file
diff --git a/Analisis env_pop_tf.ods b/Analisis env_pop_tf.ods
new file mode 100644
index 0000000..e5d0e1c
Binary files /dev/null and b/Analisis env_pop_tf.ods differ
diff --git a/GNUmakefile b/GNUmakefile
index b9737ea..6833b52 100644
--- a/GNUmakefile
+++ b/GNUmakefile
@@ -141,9 +141,12 @@ include lib/Makefrag
 include user/Makefrag
 
 
+CPUS ?= 1
+
 QEMUOPTS = -drive file=$(OBJDIR)/kern/kernel.img,index=0,media=disk,format=raw -serial mon:stdio -gdb tcp:$(GDBSERV)
 QEMUOPTS += $(shell if $(QEMU) -nographic -help | grep -q '^-D '; then echo '-D qemu.log'; fi)
 IMAGES = $(OBJDIR)/kern/kernel.img
+QEMUOPTS += -smp $(CPUS)
 QEMUOPTS += $(QEMUEXTRA) -d guest_errors
 
 gdb:
@@ -254,18 +257,10 @@ handin-check:
 
 UPSTREAM := $(shell git remote -v | grep "pdos.csail.mit.edu/6.828/2016/jos.git (fetch)" | awk '{split($$0,a," "); print a[1]}')
 
-tarball: handin-check
-	git archive --format=tar HEAD > lab$(LAB)-handin.tar
-	git diff $(UPSTREAM)/lab$(LAB) > /tmp/lab$(LAB)diff.patch
-	tar -rf lab$(LAB)-handin.tar /tmp/lab$(LAB)diff.patch
-	gzip -c lab$(LAB)-handin.tar > lab$(LAB)-handin.tar.gz
-	rm lab$(LAB)-handin.tar
-	rm /tmp/lab$(LAB)diff.patch
-
 tarball-pref: handin-check
 	@SUF=$(LAB); \
 	if test $(LAB) -eq 3 -o $(LAB) -eq 4; then \
-		read -p "Which part would you like to submit? [a, b, c (lab 4 only)]" p; \
+		read -p "Which part would you like to submit? [a, b, c (c for lab 4 only)]" p; \
 		if test "$$p" != a -a "$$p" != b; then \
 			if test ! $(LAB) -eq 4 -o ! "$$p" = c; then \
 				echo "Bad part \"$$p\""; \
@@ -277,12 +272,12 @@ tarball-pref: handin-check
 	else \
 		rm -f .suf; \
 	fi; \
-	git archive --format=tar HEAD > lab$(LAB)-handin.tar
-	git diff $(UPSTREAM)/lab$(LAB) > /tmp/lab$(LAB)diff.patch
-	tar -rf lab$(LAB)-handin.tar /tmp/lab$(LAB)diff.patch
-	gzip -c lab$(LAB)-handin.tar > lab$(LAB)-handin.tar.gz
-	rm lab$(LAB)-handin.tar
-	rm /tmp/lab$(LAB)diff.patch
+	git archive --format=tar HEAD > lab$$SUF-handin.tar; \
+	git diff $(UPSTREAM)/lab$(LAB) > /tmp/lab$$SUF-diff.patch; \
+	tar -rf lab$$SUF-handin.tar /tmp/lab$$SUF-diff.patch; \
+	gzip -c lab$$SUF-handin.tar > lab$$SUF-handin.tar.gz; \
+	rm lab$$SUF-handin.tar; \
+	rm /tmp/lab$$SUF-diff.patch; \
 
 myapi.key:
 	@echo Get an API key for yourself by visiting $(WEBSUB)/
diff --git a/TP1.md b/TP1.md
index fcc03c1..4b64f1f 100644
--- a/TP1.md
+++ b/TP1.md
@@ -3,149 +3,19 @@ TP1: Memoria virtual en JOS
 
 page2pa
 -------
-La función `page2pa` se enecuentra definida en el archivo `pmap.h`:
 
-```
-static inline physaddr_t
-page2pa(struct PageInfo *pp)
-{
-	return (pp - pages) << PGSHIFT;
-}
-```
-Para entender su comportamiento es necesario comprender que representa cada tipo de dato:
-* `typedef uint32_t physaddr_t:` el tipo de dato `physaddr_t` es un entero sin signo de 32 bits, utilizado para representar el valor de una dirección de memoria física.
-* `struct PageInfo:` como se indica en el enunciado son estructuras con información asociada a las páginas de memoria física.
-* `struct PageInfo *pages:` es el arreglo de páginas de memoria física, es decir es un puntero al primer `struct PageInfo` que está asociado a la primer página de memoria física
-
-Entonces `(pp - pages)` es una cuenta que realiza aritmética de punteros en la que da el resultado del índice de la página de memoria física a la que corresponde la variable `pp`. Finalmente a este índice se le realiza un shift a izquierda de 12 posiciones (el valor de `PGSHIFT`), que es equivalente a multiplicar por la potencia 12 de 2, es decir `4096`, que es precisamiente el tamaño en bytes de cada página.
+...
 
 
 boot_alloc_pos
 --------------
 
-a) Partiendo desde KERNBASE, ubicado en `0xf0000000` (memoria virtual), el `kernel` es mapeado a partir del próximo `MB` desde esta posición, es decir en:
-
-`KERNBASE + 0x00100000 = 0xf0000000 + 0x00100000 = 0xf0100000`
-
-A partir de esta posición de memoria irá el `kernel`. Para determinar que posición de memoria devolverá el `boot_alloc(0)` antes de alocar memoria, es decir el valor con que se inicializá la variable `nextfree`, podemos averiguarlo de dos modos:
-
-1) Corriendo el comando `size` sobre el binario, determinamos el tamaño del `kernel`:
-```
-➜  TP1-SisOp git:(master) ✗ size obj/kern/kernel 
-   text	   data	    bss	    dec	    hex	filename
-  34506	  41728	   1616	  77850	  1301a	obj/kern/kernel
-```
-Como vemos ocupa `77850` bytes (`0x0001301a` en hexadecimal). Por lo tanto sumamos este valor a la posición memoria donde empieza el `kernel`: 
-
-`0xf0100000 + 0x0001301a = 0xf011301a`
-
-Con lo cuál sabiendo que `nextfree` se inicializa en la dirección de memoria virtual de la página siguiente a la última página del `kernel`, deducimos que se inicializará en `0xf0114000`.
-
-2) Otro modo es ejecutar el comando `nm` sobre el binario, con la opción `-n` para obtener los símbolos del mismo ordenados según su posición en memoria:
-```
-➜  TP1-SisOp git:(master) ✗ nm -n obj/kern/kernel
-0010000c T _start
-f010000c T entry
-...
-...
 ...
-f0113948 B kern_pgdir
-f011394c B pages
-f0113950 B end
-```
-Podemos ver que el último símbolo `end` (que de hecho es el que se utiliza para inicializar `nextfree`) se ubica en `0xf0113950`, con lo cual volvemos a deducir que `nextfree` estará en `0xf0114000`.
-
-Para comprobar esto se agregó el siguiente código tras implementar la función `boot_alloc()`:
-```
-void
-mem_init(void)
-{
-	uint32_t cr0;
-	size_t n;
-
-	// Find out how much memory the machine has (npages & npages_basemem).
-	i386_detect_memory();
-
-	// Remove this line when you're ready to test this function.
-	cprintf("Nextfree, la pagina inmediata luego de que termina el kernel en el AS: %p \n", boot_alloc(0));
-	.
-	.
-	.
-```
-Ejecutando el `kernel` se obtiene lo siguiente:
-
-![alt text](https://github.com/gabyrobles93/TP1-SisOp/blob/master/nextfree.png)
-
-b) A continuación se puede ver una sesión de `gdb` con lo que pide el enunciado y además comprueba lo formulado en el inciso anterior
-```
-➜  TP1-SisOp git:(master) ✗ make gdb
-gdb -q -s obj/kern/kernel -ex 'target remote 127.0.0.1:26000' -n -x .gdbinit
-Leyendo símbolos desde obj/kern/kernel...hecho.
-Remote debugging using 127.0.0.1:26000
-aviso: No executable has been specified and target does not support
-determining executable automatically.  Try using the "file" command.
-0x0000fff0 in ?? ()
-.gdbinit: No existe el archivo o el directorio.
-(gdb) b boot_alloc 
-Punto de interrupción 1 at 0xf0100995: file kern/pmap.c, line 98.
-(gdb) c
-Continuando.
-
-Breakpoint 1, boot_alloc (n=0) at kern/pmap.c:98
-98		if (!nextfree) {
-(gdb) p nextfree 
-$1 = 0x0
-(gdb) n
-100			nextfree = ROUNDUP((char *) end, PGSIZE);
-(gdb) p (char*)&end
-$2 = 0xf0113950 "\020"
-(gdb) n
-112		if ((uintptr_t)ROUNDUP(nextfree + n, PGSIZE) > (KERNBASE + (4 << 20))) {
-(gdb) p nextfree 
-$3 = 0xf0114000 ""
-(gdb) n
-116		if (n > 0) {
-(gdb) n
-123	}
-(gdb) p nextfree 
-$4 = 0xf0114000 ""
-(gdb) n
-mem_init () at kern/pmap.c:145
-```
 
 
 page_alloc
 ----------
- ¿En qué se diferencia `page2pa()` de `page2kva()`?
- 
-El comportamiento de la función `page2pa()` fue descrito en la primer parte. La función `page2kva()`, hace uso de la misma pero en vez de retornar la dirección física asociada al `struct PageInfo` pasado por parámetro, a esta dirección física le aplica la macro `KADDR` que devuelve la dirección virtual correspondiente (siempre y cuando corresponde a una dirección del kernel, caso contrario ejecuta un `panic`).
-...
-
-map_region_large
-----------------
-¿Cuánta memoria se ahorró de este modo? ¿Es una cantidad fija, o depende de la memoria física de la computadora?
-
-El uso de Large Pages tiene un ahorro de memoria. Lo podemos ver con el siguiente análisis:
 
-Para referenciar `4 MiB` de memoria física **sin** large pages necesitamos:
-* Un `PDE (Page Directory Entry)` equivalente a `4 bytes`.
-* Una `Page Table` con todas sus entradas (1024 entradas de `4 bytes`) las cuales referencian cada una a una página de memoria física de `4096 bytes`.
-Entonces tenemos `1024 x 4096 bytes = 4 MiB`.
-
-Para referenciar `4MiB` de memoria física **con** large pages necesitamos:
-* Un `PDE (Page Directory Entry)` equivalente a `4 bytes`.
-Con ese `PDE` ya referenciamos a los `4 MiB` de memoria física.
-
-Entonces el ahorro de memoria, **por cada large page**, es lo que ocupa la `Page Table`: `4096 bytes`.
-
-Con esto concluimos que dependiendo de cuánta memoria física tengamos distinta será la cantidad que tengamos que referenciar con estas estructuras. Utilizando la siguiente ecuación:
-
-`Ahorrado = (Mem_fís_total / 4 MiB) * 4 KiB = MiB_fis_total * KiB` 
-
-Tenemos los siguientes resultados para distintas memorias físicas de máquinas virtuales en las que corremos `JOS`:
-* `64 MiB`: nos ahorramos `64 KiB`.
-* `128 MiB`: nos ahorramos `128 KiB`.
-* `256 MiB`: nos ahorramos `256 KiB`.
+...
 
-Este cálculo es aproximado ya que despreciamos el tamaño que ocupa la `Page Directory`.
 
diff --git a/TP2.md b/TP2.md
index 4816bfe..5dfffb0 100644
--- a/TP2.md
+++ b/TP2.md
@@ -3,23 +3,533 @@ TP2: Procesos de usuario
 
 env_alloc
 ---------
+Inicializa un nuevo Environment (proceso) que se encuentre libre. Entre otras cosas, le asigna un identificador único. El algoritmo para generar un nuevo identificador es el siguiente:
 
-...
+1. ¿Qué identificadores se asignan a los primeros 5 procesos creados? (Usar base hexadecimal.)
 
+```
+	// Generate an env_id for this environment.
+	generation = (e->env_id + (1 << ENVGENSHIFT)) & ~(NENV - 1);
+	if (generation <= 0)  // Don't create a negative env_id.
+		generation = 1 << ENVGENSHIFT;
+	e->env_id = generation | (e - envs);
+```
+
+Como todos los structs Env se inicializaron en 0 (con meminit), inicialmente tendrán env_id = 0. En la última línea puede observarse una operación `or` en donde el término derecho es una resta entre dos punteros (aritmética de punteros), donde `e` es la dirección de memoria del enviroment libre siendo incializado y `envs` es la base del arreglo de enviroments. Por lo tanto, esta resta no es mas que el offset de la dirección del enviroment libre siendo inicializado.
+
+Los primeros cinco procesos creados tendrán los siguientes identificadores:
+
+```
+Identificador número 1: 0x1000 = 4096
+Identificador número 2: 0x1001 = 4097
+Identificador número 3: 0x1002 = 4098
+Identificador número 4: 0x1003 = 4099
+Identificador número 5: 0x1004 = 4100
+```
+
+2. Supongamos que al arrancar el kernel se lanzan NENV proceso a ejecución. A continuación se destruye el proceso asociado a envs[630] y se lanza un proceso que cada segundo muere y se vuelve a lanzar. ¿Qué identificadores tendrá este proceso en sus sus primeras cinco ejecuciones?
+
+En la primer ejecución, en el momento que se lanzan NENV procesos, el proceso asociado a envs[630] tendrá el identificador 0x1276. Al morir, dicho identificador seguirá asociado al struct de ese proceso. En su próxima ejecución, en el algoritmo de asignación de id, `e->env_id` tendrá el valor antiguo, por lo que la primera línea donde se hace el cálculo para `generation`, dará un valor distinto que para la primera ejecución. En particular, tendrá un aumento de 4096 unidades (decimal) en cada ejecución. Puesto que el `environment index` es siempre el mismo lo que se va modificando es el `Uniqueifier` que distingue procesos con el mismo índice que fueron creados en distintos tiempos.
+
+Por lo que las primeras 5 ejecuciones de ese proceso tienen los siguientes ids:
+
+```
+1er env_id: 0x1276 = 4726
+2do env_id: 0x2276 = 8822
+3er env_id: 0x3276 = 12918
+4to env_id: 0x4276 = 17014
+5to env_id: 0x5276 = 21110
+```
 
 env_init_percpu
 ---------------
 
-...
+La instrucción `lgdt` ("Load Global Descriptor Table Register") recibe como operando la dirección de un struct del tipo `Pseudodesc`, que no es más que un uint16_t para LÍMITE y un uint32_t para BASE (en total 6 bytes). Donde BASE es la dirección virtual de la gdt (Global Descriptor Table) y LÍMITE es sizeof(gdt) - 1.
+
+Dicha instrucción guarda estos valores (BASE y LÍMITE) en un registro especial de CPU denominado GDTR. Dicho registro, en x86, tiene 48 bits de longitud. Los 16 bits mas bajos indican el tamaño de la GDT y los 32 bits mas altos indican su ubicación en memoria.
+
+```
+GDTR:
+|LIMIT|----BASE----|
+```
+
+Referencia: https://c9x.me/x86/html/file_module_x86_id_156.html
 
 
 env_pop_tf
 ----------
 
-...
+Esta función restaura el TrapFrame de un Environment. Un TrapFrame no es mas una estructura que guarda una "foto" del estado de los registros en el momento que se realizó un context switch. Cuando el kernel decide que ese Environment debe volver a ejecución realiza una serie de pasos, y el último de ellos es la función `env_pop_tf()`. El switch siempre se hace desde kernel a user space (nunca de user a user space).
+
+1. ¿Qué hay en `(%esp)` tras el primer `movl` de la función?
 
+El primer `movl` de la función es:
+```
+movl %0,%%esp
+```
+Que no hace otra cosa más que hacer que apuntar %esp a el TrapFrame del environment (nuevo tope de stack).
+Luego, con `popal` se hace una serie de pops (quitando cosas del nuevo stack, es decir, del TrapFrame) que se van asignando a los registros del CPU.
+
+2. ¿Qué hay en `(%esp)` justo antes de la instrucción `iret`? ¿Y en `8(%esp)`?
+
+Justo antes de la instrucción `iret`, `(%esp)` tiene `uintptr_t tf_eip`. Mientras que en `8(%esp)` tenemos `uint32_t tf_eflags`.
+
+3. ¿Cómo puede determinar la CPU si hay un cambio de ring (nivel de privilegio)?
+
+En la función `env_alloc` (que inicializa un proceso de usuario), se ejecutan las siguientes líneas:
+
+```
+	e->env_tf.tf_ds = GD_UD | 3;
+	e->env_tf.tf_es = GD_UD | 3;
+	e->env_tf.tf_ss = GD_UD | 3;
+	e->env_tf.tf_esp = USTACKTOP;
+	e->env_tf.tf_cs = GD_UT | 3;
+```
+Que setean los 2 bits mas bajos del registro de cada segmento, que equivale al 3er ring. Además, se marcan con GD_UD (global descriptor user data) y GD_UT (global descriptor user text).
+De esta manera el CPU sabe si el code segment a ejecutar pertenece al usuario o al kernel. Si pertenece al usuario, entonces `iret` restaura los registros SS (stack segment) y ESP (stack pointer). El stack pointer caerá dentro de [USTACKTOP-PGSIZE, USTACKTOP].
 
 gdb_hello
 ---------
+1. Poner un breakpoint en env_pop_tf() y continuar la ejecución hasta allí.
+```
+(gdb) b env_pop_tf
+Punto de interrupción 1 at 0xf0102ead: file kern/env.c, line 514.
+(gdb) c
+Continuando.
+Se asume que la arquitectura objetivo es i386
+=> 0xf0102ead <env_pop_tf>:	push   %ebp
+
+Breakpoint 1, env_pop_tf (tf=0xf01c0000) at kern/env.c:514
+514	{
+```
+
+2. En QEMU, entrar en modo monitor (Ctrl-a c), y mostrar las cinco primeras líneas del comando info registers.
+```
+(qemu) info registers 
+EAX=003bc000 EBX=f01c0000 ECX=f03bc000 EDX=0000023d
+ESI=00010094 EDI=00000000 EBP=f0118fd8 ESP=f0118fbc
+EIP=f0102ead EFL=00000092 [--S-A--] CPL=0 II=0 A20=1 SMM=0 HLT=0
+ES =0010 00000000 ffffffff 00cf9300 DPL=0 DS   [-WA]
+CS =0008 00000000 ffffffff 00cf9a00 DPL=0 CS32 [-R-]
+```
+
+3. De vuelta a GDB, imprimir el valor del argumento tf
+
+```
+(gdb) p tf
+$1 = (struct Trapframe *) 0xf01c0000
+```
+
+4. Imprimir, con `x/Nx tf` tantos enteros como haya en el struct Trapframe donde N = sizeof(Trapframe) / sizeof(int).
+```
+(gdb) print sizeof(struct Trapframe) / sizeof(int)
+$2 = 17
+(gdb) x/17x tf
+0xf01c0000:	0x00000000	0x00000000	0x00000000	0x00000000
+0xf01c0010:	0x00000000	0x00000000	0x00000000	0x00000000
+0xf01c0020:	0x00000023	0x00000023	0x00000000	0x00000000
+0xf01c0030:	0x00800020	0x0000001b	0x00000000	0xeebfe000
+0xf01c0040:	0x00000023
+```
+
+5. Avanzar hasta justo después del `movl ...,%esp`, usando `si M` para ejecutar tantas instrucciones como sea necesario en un solo paso.
+```
+(gdb) disas
+Dump of assembler code for function env_pop_tf:
+=> 0xf0102ead <+0>:	push   %ebp
+   0xf0102eae <+1>:	mov    %esp,%ebp
+   0xf0102eb0 <+3>:	sub    $0xc,%esp
+   0xf0102eb3 <+6>:	mov    0x8(%ebp),%esp
+   0xf0102eb6 <+9>:	popa   
+   0xf0102eb7 <+10>:	pop    %es
+   0xf0102eb8 <+11>:	pop    %ds
+   0xf0102eb9 <+12>:	add    $0x8,%esp
+   0xf0102ebc <+15>:	iret   
+   0xf0102ebd <+16>:	push   $0xf010573c
+   0xf0102ec2 <+21>:	push   $0x20c
+   0xf0102ec7 <+26>:	push   $0xf0105706
+   0xf0102ecc <+31>:	call   0xf01000a9 <_panic>
+End of assembler dump.
+(gdb) si 4
+=> 0xf0102eb6 <env_pop_tf+9>:	popa   
+0xf0102eb6	515		asm volatile("\tmovl %0,%%esp\n"
+(gdb) disas
+Dump of assembler code for function env_pop_tf:
+   0xf0102ead <+0>:	push   %ebp
+   0xf0102eae <+1>:	mov    %esp,%ebp
+   0xf0102eb0 <+3>:	sub    $0xc,%esp
+   0xf0102eb3 <+6>:	mov    0x8(%ebp),%esp
+=> 0xf0102eb6 <+9>:	popa   
+   0xf0102eb7 <+10>:	pop    %es
+   0xf0102eb8 <+11>:	pop    %ds
+   0xf0102eb9 <+12>:	add    $0x8,%esp
+   0xf0102ebc <+15>:	iret   
+   0xf0102ebd <+16>:	push   $0xf010573c
+   0xf0102ec2 <+21>:	push   $0x20c
+   0xf0102ec7 <+26>:	push   $0xf0105706
+   0xf0102ecc <+31>:	call   0xf01000a9 <_panic>
+End of assembler dump.
+```
+
+
+6. Comprobar, con `x/Nx $sp` que los contenidos son los mismos que tf (donde N es el tamaño de tf).
+
+```
+(gdb) x/17x $sp
+0xf01c0000:	0x00000000	0x00000000	0x00000000	0x00000000
+0xf01c0010:	0x00000000	0x00000000	0x00000000	0x00000000
+0xf01c0020:	0x00000023	0x00000023	0x00000000	0x00000000
+0xf01c0030:	0x00800020	0x0000001b	0x00000000	0xeebfe000
+0xf01c0040:	0x00000023
+```
+
+7. Explicar con el mayor detalle posible cada uno de los valores. Para los valores no nulos, se debe indicar dónde se configuró inicialmente el valor, y qué representa.
+
+Para explicar cada uno de los valores, se debe entender que a este punto el "stack" tiene la estructura de un Trapframe, que se vió que tiene un tamaño de 17 `ints` (68 bytes). La estructura de un Trapframe es la siguiente:
+
+```
+struct Trapframe {
+	struct PushRegs tf_regs;
+	uint16_t tf_es;
+	uint16_t tf_padding1;
+	uint16_t tf_ds;
+	uint16_t tf_padding2;
+	uint32_t tf_trapno;
+	/* below here defined by x86 hardware */
+	uint32_t tf_err;
+	uintptr_t tf_eip;
+	uint16_t tf_cs;
+	uint16_t tf_padding3;
+	uint32_t tf_eflags;
+	/* below here only when crossing rings, such as from user to kernel */
+	uintptr_t tf_esp;
+	uint16_t tf_ss;
+	uint16_t tf_padding4;
+} __attribute__((packed));
+```
+
+Donde la estructura PushRegs se conforma como:
+
+```
+struct PushRegs {
+	/* registers as pushed by pusha */
+	uint32_t reg_edi;
+	uint32_t reg_esi;
+	uint32_t reg_ebp;
+	uint32_t reg_oesp;	
+	uint32_t reg_ebx;
+	uint32_t reg_edx;
+	uint32_t reg_ecx;
+	uint32_t reg_eax;
+} __attribute__((packed));
+```
+Las primeras dos líneas de valores de $sp:
+
+```
+0xf01c0000:	0x00000000	0x00000000	0x00000000	0x00000000
+              reg_edi     reg_esi     reg_ebp     reg_oesp
+
+0xf01c0010:	0x00000000	0x00000000	0x00000000	0x00000000
+              reg_ebx     reg_edx     reg_ecx     reg_eax 
+```
+
+Son 8 `ints` (32 bytes) y se corresponde con la estructura de PushRegs, que son todos nulos (lógico si es la primera vez que entra en contexto este environment).
+
+Luego, en la tercer línea de valores:
+
+```
+0xf01c0020:	0x00000023	0x00000023	0x00000000	0x00000000
+		          pad - es    pad - ds    "trapno"    "tf_err" 
+```
+Los primeros 2 `ints` corresponden a `tf_es` + `tf_padding1` y `tf_ds` + `padding2` respectivamente.
+Los valores de `es` y `ds` `(0x0023)` se deben a que en `env_alloc()` se inicializaron con el valor `GD_UD | 3` (Global descriptor number = User Data y 3er ring).
+
+En la cuarta línea de valores tenemos:
+
+```
+0xf01c0030:	0x00800020	0x0000001b	0x00000000	0xeebfe000
+              tf_eip      pad - cs    tf_eflags   tf_esp
+```
+El valor de tf_eip (instruction pointer) es la dirección a la primera línea del código ejecutable del environment. Si investigamos el elf con `readelf -S obj/user/hello` se observa lo siguiente:
+
+```
+There are 11 section headers, starting at offset 0x7690:
+
+Section Headers:
+  [Nr] Name              Type            Addr     Off    Size   ES Flg Lk Inf Al
+  [ 0]                   NULL            00000000 000000 000000 00      0   0  0
+->[ 1] .text             PROGBITS        00800020 006020 000d19 00  AX  0   0 16 <- (*)
+  [ 2] .rodata           PROGBITS        00800d3c 006d3c 000280 00   A  0   0  4
+  [ 3] .data             PROGBITS        00801000 007000 000004 00  WA  0   0  4
+  [ 4] .bss              NOBITS          00801004 007004 000004 00  WA  0   0  4
+  [ 5] .stab_info        PROGBITS        00200000 001000 000010 00  WA  0   0  1
+  [ 6] .stab             PROGBITS        00200010 001010 002905 0c   A  7   0  4
+  [ 7] .stabstr          STRTAB          00202915 003915 0017ee 00   A  0   0  1
+  [ 8] .symtab           SYMTAB          00000000 007004 000440 10      9  25  4
+  [ 9] .strtab           STRTAB          00000000 007444 0001fd 00      0   0  1
+  [10] .shstrtab         STRTAB          00000000 007641 00004e 00      0   0  1
+```
+
+La línea señalada con `-> <- (*)` indica que el text segment, donde se ubica el código ejecutable, comienza en la dirección 0x00800020.
+
+El valor de `cs` `(0x0000001b)` es el resultado de haberlo inicializado como `GD_UT | 3` en `env_alloc()`. Dichos valores setean el Global Descriptor Number como User Text y 3er Ring de privilegios.
+
+El valor de `esp/stack pointer (0xeebfe000)` se corresponde la dirección del stack seteado en `env_alloc()`, que es `USTACKTOP`. Esto es, el tope del stack en el Address Space del environment. Esquema:
+```
+ *    USTACKTOP  --->  +------------------------------+ 0xeebfe000
+ *                     |      Normal User Stack       | RW/RW  PGSIZE
+ *                     +------------------------------+ 0xeebfd000
+```
+
+Por último, la quinta línea:
+```
+0xf01c0040:	0x00000023
+              pad - ss
+```
+
+El valor de `ss` (stack segment) se corresponde con lo seteado en env_alloc(), que es exactamente lo mismo que se hizo para `ds` (data segment) y `es` (extra segment).
+
+
+8. Continuar hasta la instrucción iret, sin llegar a ejecutarla. Mostrar en este punto, de nuevo, las cinco primeras líneas de info registers en el monitor de QEMU. Explicar los cambios producidos.
+```
+(gdb) disas
+Dump of assembler code for function env_pop_tf:
+   0xf0102ead <+0>:	push   %ebp
+   0xf0102eae <+1>:	mov    %esp,%ebp
+   0xf0102eb0 <+3>:	sub    $0xc,%esp
+   0xf0102eb3 <+6>:	mov    0x8(%ebp),%esp
+=> 0xf0102eb6 <+9>:	popa   
+   0xf0102eb7 <+10>:	pop    %es
+   0xf0102eb8 <+11>:	pop    %ds
+   0xf0102eb9 <+12>:	add    $0x8,%esp
+   0xf0102ebc <+15>:	iret   
+   0xf0102ebd <+16>:	push   $0xf010573c
+   0xf0102ec2 <+21>:	push   $0x20c
+   0xf0102ec7 <+26>:	push   $0xf0105706
+   0xf0102ecc <+31>:	call   0xf01000a9 <_panic>
+End of assembler dump.
+(gdb) si 4
+=> 0xf0102ebc <env_pop_tf+15>:	iret   
+0xf0102ebc	515		asm volatile("\tmovl %0,%%esp\n"
+(gdb) disas
+Dump of assembler code for function env_pop_tf:
+   0xf0102ead <+0>:	push   %ebp
+   0xf0102eae <+1>:	mov    %esp,%ebp
+   0xf0102eb0 <+3>:	sub    $0xc,%esp
+   0xf0102eb3 <+6>:	mov    0x8(%ebp),%esp
+   0xf0102eb6 <+9>:	popa   
+   0xf0102eb7 <+10>:	pop    %es
+   0xf0102eb8 <+11>:	pop    %ds
+   0xf0102eb9 <+12>:	add    $0x8,%esp
+=> 0xf0102ebc <+15>:	iret   
+   0xf0102ebd <+16>:	push   $0xf010573c
+   0xf0102ec2 <+21>:	push   $0x20c
+   0xf0102ec7 <+26>:	push   $0xf0105706
+   0xf0102ecc <+31>:	call   0xf01000a9 <_panic>
+End of assembler dump.
+```
+
+Anterior:
+```
+(qemu) info registers
+EAX=003bc000 EBX=f01c0000 ECX=f03bc000 EDX=0000023d
+ESI=00010094 EDI=00000000 EBP=f0118fd8 ESP=f0118fbc
+EIP=f0102ead EFL=00000092 [--S-A--] CPL=0 II=0 A20=1 SMM=0 HLT=0
+ES =0010 00000000 ffffffff 00cf9300 DPL=0 DS   [-WA]
+CS =0008 00000000 ffffffff 00cf9a00 DPL=0 CS32 [-R-]
+```
+
+Actual:
+```
+(qemu) info registers
+EAX=00000000 EBX=00000000 ECX=00000000 EDX=00000000
+ESI=00000000 EDI=00000000 EBP=00000000 ESP=f01c0030
+EIP=f0102ebc EFL=00000096 [--S-AP-] CPL=0 II=0 A20=1 SMM=0 HLT=0
+ES =0023 00000000 ffffffff 00cff300 DPL=3 DS   [-WA]
+CS =0008 00000000 ffffffff 00cf9a00 DPL=0 CS32 [-R-]
+```
+
+Se actualizaron los valores de los registros de propósito general (`EDI`, `ESI`, `EBP`, `EBX`, `EDX`, `ECX` y `EAX`) a los valores traidos del Trapframe. Esto fué gracias a la instrucción `popal`
+
+Se actualizó el valor del registro `ES`. Esto fué gracias a la instrucción `popl %%es`
+
+Se actualizó el valor del registro `DS`. Esto fué gracias a la instrucción `popl %%ds`
+
+El cambio producido en `EIP` se debe a que el instruccion pointer avanzó algunas pocas líneas de código, pero no porque se haya traido del Trapframe.
+
+El code segment no se vió afectado, tampoco los flags.
+
+9. Ejecutar la instrucción iret. En ese momento se ha realizado el cambio de contexto y los símbolos del kernel ya no son válidos.
+
+Imprimir el valor del contador de programa con `p $pc` o `p $eip`
+
+```
+(gdb) p $pc
+$1 = (void (*)()) 0x800020
+```
+
+Cargar los símbolos de hello con `symbol-file obj/user/hello`. Volver a imprimir el valor del contador de programa
+
+```
+(gdb) p $pc
+$1 = (void (*)()) 0x800020 <_start>
+```
+Mostrar una última vez la salida de info registers en QEMU, y explicar los cambios producidos.
+
+```
+(qemu) info registers
+EAX=00000000 EBX=00000000 ECX=00000000 EDX=00000000
+ESI=00000000 EDI=00000000 EBP=00000000 ESP=eebfe000
+EIP=00800020 EFL=00000002 [-------] CPL=3 II=0 A20=1 SMM=0 HLT=0
+ES =0023 00000000 ffffffff 00cff300 DPL=3 DS   [-WA]
+CS =001b 00000000 ffffffff 00cffa00 DPL=3 CS32 [-R-]
+```
+
+Ahora se actualizaron el `EIP` (Instruction pointer), `CS` (code segment), `EFL` (EFLAGS), y el `SS` (Stack Pointer) a los valores indicados por Trapframe.
+
+10. Poner un breakpoint temporal (tbreak, se aplica una sola vez) en la función syscall() y explicar qué ocurre justo tras ejecutar la instrucción `int $0x30`. Usar, de ser necesario, el monitor de QEMU.
+```
+(gdb) tbreak syscall
+Punto de interrupción temporal 2 at 0x8009ed: file lib/syscall.c, line 23.
+(gdb) c
+Continuando.
+=> 0x8009ed <syscall+17>:	mov    0x8(%ebp),%ecx
+
+Temporary breakpoint 2, syscall (num=0, check=-289415544, a1=4005551752, 
+    a2=13, a3=0, a4=0, a5=0) at lib/syscall.c:23
+23		asm volatile("int %1\n"
+```
+
+Al ejecutar la instrucción `int $0x30` se genera una interrupción que es tomada por el `kernel`.
+
+La información de info registers es:
+
+```
+EAX=00000000 EBX=00000000 ECX=00000000 EDX=00000663
+ESI=00000000 EDI=00000000 EBP=00000000 ESP=00000000
+EIP=0000e062 EFL=00000002 [-------] CPL=0 II=0 A20=1 SMM=0 HLT=0
+ES =0000 00000000 0000ffff 00009300
+CS =f000 000f0000 0000ffff 00009b00
+```
+Observar que ahora tanto `ES` como `CS` (code segment) tienen sus últimos bits en 0, lo que significa que se está en el Ring 0 de privilegios (modo `kernel`).
+
+
+kern_idt
+--------
+
+1. ¿Cómo decidir si usar TRAPHANDLER o TRAPHANDLER_NOEC? ¿Qué pasaría si se usara solamente la primera?
+
+Para decidir si usar una u la otra, se debe analizar para cada excepción/interrupción, si para esta el CPU automáticamente hace un push al stack del código de error o no. Para el primer caso se debe utilizar la macro `TRAPHANDLER` y para el segundo `TRAPHANDLER_NOEC`. Si se utilizara solamente la primera, en los casos de excepciones/interrupciones donde el CPU no haga `push` del código de error, el stack basado en el trapframe estaría con un formato inválido, desencadenando en errores graves.
+
+2. ¿Qué cambia, en la invocación de handlers, el segundo parámetro (istrap) de la macro `SETGATE`? ¿Por qué se elegiría un comportamiento u otro durante un syscall?
+
+Con el valor `istrap = 0`, el CPU deshabilita las interrupciones cuando se está en modo kernel. Con `istrap = 1`, el CPU no las desactiva. En `JOS`, no se considerará que el CPU tome interripciones cuando se esté en modo kernel. Otros kernels más avanzados podrían ponerlo a 1.
+
+3. Leer `user/softint.c` y ejecutarlo con `make run-softint-nox`. ¿Qué excepción se genera? Si hay diferencias con la que invoca el programa… ¿por qué mecanismo ocurre eso, y por qué razones?
+
+
+Al ejecutar `make run-softint-nox` se obtiene lo siguiente por salida estándar:
+
+```
+[00000000] new env 00001000
+Incoming TRAP frame at 0xefffffbc
+TRAP frame at 0xf01c0000
+  edi  0x00000000
+  esi  0x00000000
+  ebp  0xeebfdfd0
+  oesp 0xefffffdc
+  ebx  0x00000000
+  edx  0x00000000
+  ecx  0x00000000
+  eax  0x00000000
+  es   0x----0023
+  ds   0x----0023
+  trap 0x0000000d General Protection
+  err  0x00000072
+  eip  0x00800036
+  cs   0x----001b
+  flag 0x00000082
+  esp  0xeebfdfd0
+  ss   0x----0023
+[00001000] free env 00001000
+Destroyed the only environment - nothing more to do!
+```
+
+Puede oservarse que el valor de `trap` es 0x0000000d que se corresponde con el decimal 13. El `trap` con dicho número es "General Protection" que es causado por "Any memory reference and other protection checks". Esto es diferente a la que se invocó en el programa (14 = page fault). Esto se debe a que en el llamado de la interrupción 14 en `softint.c` se tiene privilegios de modo usuario, mientras que dicha interrupción en el archivo `trap.c`, `SETGATE(idt[T_PGFLT], 0, GD_KT, trap_14, 0);` fue declarada con un nivel de privilegio 0 (el quinto argumento) lo que quiere decir que solo el kernel puede transferir la ejecución a esa interrupción. Si se intenta violar esta regla ocurre una excepción `General Protection` (13) que es justamente la que ocurre.
+
+
+user_evilhello
+--------------
+
+Tenemos la primer versión del programa `evihello.c`:
+```
+// evil hello world -- kernel pointer passed to kernel
+// kernel should destroy user environment in response
+
+#include <inc/lib.h>
+
+void
+umain(int argc, char **argv)
+{
+	// try to print the kernel entry point as a string!  mua ha ha!
+	sys_cputs((char*)0xf010000c, 100);
+}
+```
+Con el cual tenemos la siguiente salida:
+```
+[00000000] new env 00001000
+Incoming TRAP frame at 0xefffffbc
+f�rIncoming TRAP frame at 0xefffffbc
+[00001000] exiting gracefully
+[00001000] free env 00001000
+Destroyed the only environment - nothing more to do!
+```
+
+Mientras que con la siguiente versión:
+```
+#include <inc/lib.h>
+
+void
+umain(int argc, char **argv)
+{
+    char *entry = (char *) 0xf010000c;
+    char first = *entry;
+    sys_cputs(&first, 1);
+}
+```
+
+Tenemos la siguiente salida:
+```
+[00000000] new env 00001000
+Incoming TRAP frame at 0xefffffbc
+[00001000] user fault va f010000c ip 00800039
+TRAP frame at 0xf01c0000
+  edi  0x00000000
+  esi  0x00000000
+  ebp  0xeebfdfd0
+  oesp 0xefffffdc
+  ebx  0x00000000
+  edx  0x00000000
+  ecx  0x00000000
+  eax  0x00000000
+  es   0x----0023
+  ds   0x----0023
+  trap 0x0000000e Page Fault
+  cr2  0xf010000c
+  err  0x00000005 [user, read, protection]
+  eip  0x00800039
+  cs   0x----001b
+  flag 0x00000082
+  esp  0xeebfdfb0
+  ss   0x----0023
+[00001000] free env 00001000
+Destroyed the only environment - nothing more to do!
+```
+1. ¿En qué se diferencia el código de la versión en `evilhello.c` mostrada arriba?
+En la segunda versión primero se intenta acceder explícitamente a la dirección `0xf010000c` desde la aplicación de usuario. Dado que esta memoria pertenece al kernel, ocurre aquí el page fault.
+
+2. ¿En qué cambia el comportamiento durante la ejecución? ¿Por qué? ¿Cuál es el mecanismo?
+Como vemos para la segunda versión el proceso es destruído a causa del Page Fault. Pero para el primer caso simplemente se le pasa la dirección al kernel y dicha dirección será accedida en modo kernel dentro del handler de la syscall, por ello es que no ocurre ningún Page Fault y el programa termina correctamente. Por esto es necesario que el kernel valide los punteros que envía el usuario como argumentos de las syscalls.
+
+
 
-...
diff --git a/TP3.md b/TP3.md
new file mode 100644
index 0000000..57a45f7
--- /dev/null
+++ b/TP3.md
@@ -0,0 +1,501 @@
+TP3: Multitarea con desalojo
+============================
+
+static_assert
+-------------
+
+**¿cómo y por qué funciona la macro `static_assert` que define JOS?**
+**La implementación de `static_assert` es la siguiente:**
+```
+// static_assert(x) will generate a compile-time error if 'x' is false.
+#define static_assert(x)	switch (x) case 0: case (x):
+```
+Esto genera un error en tiempo de compilación, lo que no quiere decir que tenga el mismo comportamiento que `_Static_assert`. La implementación de `JOS` lo que hace es recibir una expresión `x` que en caso de ser falsa (`case 0`) generará el código `case (x)` con lo cual habrá una duplicación en el valor `case`. A continuación se puede ver una prueba:
+```
+In file included from kern/pmap.c:7:0:
+kern/pmap.c: In function ‘page_init’:
+./inc/assert.h:18:45: error: duplicate case value
+ #define static_assert(x) switch (x) case 0: case (x):
+                                             ^
+kern/pmap.c:371:2: note: in expansion of macro ‘static_assert’
+  static_assert(MPENTRY_PADDR % PGSIZE == 1);
+  ^~~~~~~~~~~~~
+./inc/assert.h:18:37: note: previously used here
+ #define static_assert(x) switch (x) case 0: case (x):
+                                     ^
+kern/pmap.c:371:2: note: in expansion of macro ‘static_assert’
+  static_assert(MPENTRY_PADDR % PGSIZE == 1);
+  ^~~~~~~~~~~~~
+```
+
+env_return
+----------
+
+**Al terminar un proceso su función `umain()` ¿dónde retoma la ejecución el kernel? Describir la secuencia de llamadas desde que termina `umain()` hasta que el kernel dispone del proceso.**
+
+En `lib/entry.S` (usuario) se llama a la función `libmain()`. Ésta última es quien configura la variable `thisenv` y el nombre del binario en caso de existir y finalmente llama a `umain()` por lo tanto, una vez que termina `umain()` la ejecución retorna aquí en `libmain()` quien es la encargada de llamar a `exit()` para que el kernel disponga del proceso.
+
+**¿En qué cambia la función env_destroy() en este TP, respecto al TP anterior?**
+
+En el TP anterior como no disponíamos de múltiples procesos no se hacía ningún tipo de validación y se liberaba el proceso. En la nueva implementación ya que el mismo proceso podría estar corriendo en otro CPU es necesario comprobarlo (el `if` comprueba si está corriendo y si además no es el proceso actual de este CPU), si esto es así se cambia el estado a `ENV_DYING`, con lo que se convierte en un "proceso zombie" y será liberado la próxima vez que se le ceda el control. En caso de no ser así se lo libera y se hace una última validación para comprobar que el proceso no era el que estaba corriendo en ese momento. En caso de ser así se actualiza `curenv` y se fuerza el cambio con otro proceso con `sched_yield`.
+
+sys_yield
+---------
+
+**Leer y estudiar el código del programa `user/yield.c`. Cambiar la función `i386_init()` para lanzar tres instancias de dicho programa, y mostrar y explicar la salida de `make qemu-nox`**
+La función de `yield.c` simplemente realiza un ciclo for en el que se desaloja y luego de retomar el control del CPU, imprime por salida estándar un mensaje para indicar que retomó la ejecución, su `PID` y el número de iteración en la que se encuentra. Al correr el comando indicado se obtuvo la siguiente salida:
+```
+SMP: CPU 0 found 1 CPU(s)
+enabled interrupts: 1 2
+[00000000] new env 00001000
+[00000000] new env 00001001
+[00000000] new env 00001002
+Hello, I am environment 00001000.
+Hello, I am environment 00001001.
+Hello, I am environment 00001002.
+Back in environment 00001000, iteration 0.
+Back in environment 00001001, iteration 0.
+Back in environment 00001002, iteration 0.
+Back in environment 00001000, iteration 1.
+Back in environment 00001001, iteration 1.
+Back in environment 00001002, iteration 1.
+Back in environment 00001000, iteration 2.
+Back in environment 00001001, iteration 2.
+Back in environment 00001002, iteration 2.
+Back in environment 00001000, iteration 3.
+Back in environment 00001001, iteration 3.
+Back in environment 00001002, iteration 3.
+Back in environment 00001000, iteration 4.
+All done in environment 00001000.
+[00001000] exiting gracefully
+[00001000] free env 00001000
+Back in environment 00001001, iteration 4.
+All done in environment 00001001.
+[00001001] exiting gracefully
+[00001001] free env 00001001
+Back in environment 00001002, iteration 4.
+All done in environment 00001002.
+[00001002] exiting gracefully
+[00001002] free env 00001002
+No runnable environments in the system!
+```
+Se puede observar como se crean los tres procesos y en cada iteración cada proceso se desaloja intencionalmente. Primero arranca `00001000`, se desaloja, luego por `round-robin` irá el proceso siguiente `00001001`, entra al ciclo y se desaloja, por último empieza el ciclo el proceso `00001002` que se desaloja y por la política de `round-robin` ahora le tocará al proceso `00001000` nuevamente e imprime el primer mensaje por pantalla `"Back in enviroment..."`. Así se repiten todos los ciclos hasta que el primer proceso llega al último y podemos observar como el kernel cede el CPU a otros procesos recién cuando el proceso actual muere (ya que no hay llamadas explícitas a `schied_yield()` y no están habilitadas las interrupciones del timer).
+
+envid2env
+---------
+
+**Responder qué ocurre:**
+**en `JOS`, si un proceso llama a `sys_env_destroy(0)`**
+Cuando se hace el llamado `sys_env_destroy(0)`, lo primero que hace la syscall es pasar de `envid` a `struct Env *`, con lo que se hace llamado a `envid2env(0)`. Dicha función si se invoca con 0 devuelve el proceso actual, es decir `curenv`. Luego se llama a `env_destroy()`, con lo que está destruyendo el proceso actual (en dicha función se agrega la comprobación de: si se está destruyendo al proceso actual se hace llamado a `schied_yield` para correr otro programa `RUNNABLE`).
+
+**en Linux, si un proceso llama a `kill(0, 9)`**
+
+En Linux, mediante el comando `kill` se puede enviar una señal a un proceso o grupo de procesos. En particular, la señal número 9 significa KILL (terminar con el/los procesos). Si un proceso llama `kill(0, 9)` entonces terminará con todos los procesos cuyo ID de grupo sea el mismo que el suyo, incluido a si mismo.
+
+**E ídem para:**
+**JOS: `sys_env_destroy(-1)`**
+La definición de `envid_t` en `env.h` indica que ID's negativos significan errores. En particular tendremos un comportamiento inesperado ya que el en la sentencia: 
+`e = &envs[ENVX(envid)];`
+Estaremos accediendo a `envs[NENV]` ya que -1 es equivalente a todos los bits en 1.
+Con lo que seguramente falle en el siguiente `if`:
+```
+if (e->env_status == ENV_FREE || e->env_id != envid) {
+  *env_store = 0;
+  return -E_BAD_ENV;
+}
+```
+y devuelva `-E_BAD_ENV` y la syscall devuelve el error al usuario.
+
+**Linux: `kill(-1, 9)`**
+
+Según el manual de kill de linux, el comando `kill -9 -1` termina con todos los procesos que se pueda terminar.
+
+dumbfork
+--------
+
+**1. Si, antes de llamar a `dumbfork()`, el proceso se reserva a sí mismo una página con `sys_page_alloc()` ¿se propagará una copia al proceso hijo? ¿Por qué?**
+
+Si un proceso se reserva una página a si mismo con `sys_page_alloc()`, dicha página va a mapearse en su address space en la dirección virutal `va` que le indique por parámetro. Para dicha dirección se valida que esté por debajo de UTOP. Si el mapeo se hace en el Pogram Data & Heap o en el Normal User Stack, entonces dicha página va a propagarse como copia al hijo. Esto se debe a que dumfork realiza copia al address space de hijo de las páginas asociadas al Program Data & Heap y Normal User Stack.
+
+**2. ¿Se preserva el estado de solo-lectura en las páginas copiadas? Mostrar, con código en espacio de usuario, cómo saber si una dirección de memoria es modificable por el proceso, o no. (Ayuda: usar las variables globales `uvpd` y/o `uvpt`.)**
+
+No, no se preserva el estado de solo lectura ya que todas las páginas necesarias que se van alocando se hace con los permisos `PTE_P|PTE_U|PTE_W`, independientemente de los permisos originales de la página que se está duplicando.
+En el siguiente fragmento de código podemos saber si una dirección de memoria es modificable por el proceso o no:
+```
+pde_t pde = uvpd[PDX(addr)];
+
+// Verificamos bit de presencia de la page table.
+if (pde & PTE_P) {
+  // Obtenemos el PTE
+  pte_t pte = uvpt[PGNUM(addr)];
+
+  // Verificamos bit de presencia de la página
+  if (pte & PTE_P) {
+    if (pte & PTE_W) {
+      // Modificable por el usuario
+    } else {
+      // No modificable por el usuario
+    }
+  ...
+```
+
+**3. Describir el funcionamiento de la función `duppage()`.**
+
+Se puede observar en el código original comentarios explicando la función paso por paso. Básicamente copia el contenido de una página de un proceso padre a un proceso hijo. Para ello realiza los siguientes pasos:
+1. Aloca una página para el proceso destino mapeada en la dirrección parámetro `addr`.
+2. Mapea la página recién alocada en la dirección `UTEMP` del proceso padre.
+3. El proceso padre copia el contenido de su página en dirección `addr` en la dirección `UTEMP` (en consecuencia escribe en `addr` del proceso hijo).
+4. Desmapea las direcciones del paso 2.
+
+**4. Supongamos que se añade a `duppage()` un argumento booleano que indica si la página debe quedar como solo-lectura en el proceso hijo:**
+  * **indicar qué llamada adicional se debería hacer si el booleano es `true`**
+  * **describir un algoritmo alternativo que no aumente el número de llamadas al sistema, que debe quedar en 3 (1 × alloc, 1 × map, 1 × unmap).**
+
+Un proceso puede cambiarse los permisos de una página re-mapeando la página en la nueva dirección con `sys_page_map` (pasando los nuevos permisos). Por lo tanto, si `duppage()` recibe `true` como parámetro, se debería añadir al final la siguiente llamada adicional:
+
+```
+	if ((r = sys_page_map(dstenv, addr, dstenv, addr, PTE_P|PTE_U)) < 0)
+		panic("sys_page_map: %e", r);
+```
+
+Un algoritmo alternativo podría obtenerse cambiando el orden de las operaciones. Si las operaciones originales son:
+
+```
+. Alocar una página para el proceso destino y mapearla en la dirección addr
+. Mapear la misma página en el proceso del padre, en la dirección UTEMP.
+. Copiar el contenido de la página addr (del padre) en la página de la dirección UTEMP
+. Desmapear el mapeo de UTEMP del padre.
+```
+
+El algoritmo alternativo presentaría el siguiente orden:
+
+```
+. Alocar una página para el proceso padre y mapearla en la dirección `UTEMP`
+. Copiar el contenido de la página addr (del padre) en la página de la dirección UTEMP
+. Mapear la misma página en el proceso hijo, en la dirección addr.
+. Desmapear el mapeo de UTEMP del padre.
+```
+
+**5. ¿Por qué se usa `ROUNDDOWN(&addr)` para copiar el stack? ¿Qué es `addr` y por qué, si el stack crece hacia abajo, se usa `ROUNDDOWN` y no `ROUNDUP`?**
+
+Se usa &addr por que es una variable local y por lo tanto vive en el stack, y ROUNDOWN por que queremos el principio de la página
+
+multicore_init
+--------------
+
+**1. ¿Qué código copia, y a dónde, la siguiente línea de la función boot_aps()?**
+
+```
+memmove(code, mpentry_start, mpentry_end - mpentry_start);
+```
+En el sistema operativo, los CPUs se pueden clasificar en dos tipos: BSP (bootstrap procesors) responsables de bootear el sistema operativo, y APs (application procesors) activados por el BSP una vez que el S.O. esté up and running.
+
+El CPU BSP, tras inicializar el sistema operativo, llama a la función boot_aps(), que inicializa los CPUs del tipo APs.
+Los APs inician en modo real (sin virtualizaciones, page directories, etc.) al igual que lo hizo anteriormente BSP. La diferencia es que ahora tenemos un procesador ya virtualizado, que puede 'ayudar' al resto en este proceso.
+
+La línea en cuestión, es ejecutada por BSP, y lo que hace es copiar código que servirá de entry-point para los APs. Dicho código, ubicado en `mpentry.S`, presenta los tags `mpentry_start` y `mpentry_end`, que sirve para ubicarlo y determinar su tamaño. El mismo es copiado en la dirección física `MPENTRY_PADDR`, que no estará previamente en uso.
+
+
+**2. ¿Para qué se usa la variable global mpentry_kstack? ¿Qué ocurriría si el espacio para este stack se reservara en el archivo kern/mpentry.S, de manera similar a bootstack en el archivo kern/entry.S?**
+
+Previo a que un AP se inicialice con la función `lapic_startap()`, el BSP setea una variable global que es un puntero al kernel stack del cpu próximo a inicializar.
+
+El espacio para ese stack no puede reservarse en el archivo `mpentry.S`, ya que como arranca en modo real, no tiene ninguna referencia del page directory ya creado del kernel.
+
+
+**3. Cuando QEMU corre con múltiples CPUs, éstas se muestran en GDB como hilos de ejecución separados. Mostrar una sesión de GDB en la que se muestre cómo va cambiando el valor de la variable global mpentry_kstack**
+
+```
+(gdb) watch mpentry_kstack 
+	Hardware watchpoint 1: mpentry_kstack
+(gdb) continue
+	Continuing.
+	The target architecture is assumed to be i386
+	=> 0xf0100186 <boot_aps+127>:	mov    %esi,%ecx
+
+	Thread 1 hit Hardware watchpoint 1: mpentry_kstack
+
+	Old value = (void *) 0x0
+	New value = (void *) 0xf024b000 <percpu_kstacks+65536>
+	boot_aps () at kern/init.c:105
+	105			lapic_startap(c->cpu_id, PADDR(code));
+(gdb) bt
+	#0  boot_aps () at kern/init.c:105
+	#1  0xf010020f in i386_init () at kern/init.c:55
+	#2  0xf0100047 in relocated () at kern/entry.S:89
+(gdb) info threads
+	  Id   Target Id         Frame 
+	* 1    Thread 1 (CPU#0 [running]) boot_aps () at kern/init.c:105
+	  2    Thread 2 (CPU#1 [halted ]) 0x000fd412 in ?? ()
+	  3    Thread 3 (CPU#2 [halted ]) 0x000fd412 in ?? ()
+	  4    Thread 4 (CPU#3 [halted ]) 0x000fd412 in ?? ()
+(gdb) continue
+	Continuing.
+	=> 0xf0100186 <boot_aps+127>:	mov    %esi,%ecx
+
+	Thread 1 hit Hardware watchpoint 1: mpentry_kstack
+
+	Old value = (void *) 0xf024b000 <percpu_kstacks+65536>
+	New value = (void *) 0xf0253000 <percpu_kstacks+98304>
+	boot_aps () at kern/init.c:105
+	105			lapic_startap(c->cpu_id, PADDR(code));
+(gdb) info threads
+	  Id   Target Id         Frame 
+	* 1    Thread 1 (CPU#0 [running]) boot_aps () at kern/init.c:105
+	  2    Thread 2 (CPU#1 [running]) 0xf010029d in mp_main () at kern/init.c:123
+	  3    Thread 3 (CPU#2 [halted ]) 0x000fd412 in ?? ()
+	  4    Thread 4 (CPU#3 [halted ]) 0x000fd412 in ?? ()
+(gdb) thread 2
+	[Switching to thread 2 (Thread 2)]
+	#0  0xf010029d in mp_main () at kern/init.c:123
+	123		xchg(&thiscpu->cpu_status, CPU_STARTED); // tell boot_aps() we're up
+(gdb) bt
+	#0  0xf010029d in mp_main () at kern/init.c:123
+	#1  0x00007060 in ?? ()
+(gdb) p cpunum()
+	Could not fetch register "orig_eax"; remote failure reply 'E14'
+(gdb) thread 1
+	[Switching to thread 1 (Thread 1)]
+	#0  boot_aps () at kern/init.c:105
+	105			lapic_startap(c->cpu_id, PADDR(code));
+(gdb) p cpunum()
+	Could not fetch register "orig_eax"; remote failure reply 'E14'
+(gdb) continue
+	Continuing.
+	=> 0xf0100186 <boot_aps+127>:	mov    %esi,%ecx
+
+	Thread 1 hit Hardware watchpoint 1: mpentry_kstack
+
+	Old value = (void *) 0xf0253000 <percpu_kstacks+98304>
+	New value = (void *) 0xf025b000 <percpu_kstacks+131072>
+	boot_aps () at kern/init.c:105
+	105			lapic_startap(c->cpu_id, PADDR(code));
+
+```
+
+Las ejecuciones `p cpnum()` resultaron en el siguiente error:
+
+```
+Could not fetch register "orig_eax"; remote failure reply 'E14'
+```
+Lo cual fue validado con el docente. De todas formas, las impresiones deberían haber sido '1' y '0' en cada invocación. Siempre será N-1 donde N es el número de cpu thread.
+
+
+**4. En el archivo kern/mpentry.S se puede leer:**
+
+```
+# We cannot use kern_pgdir yet because we are still
+# running at a low EIP.
+movl $(RELOC(entry_pgdir)), %eax
+```
+**a) ¿Qué valor tiene el registro %eip cuando se ejecuta esa línea? Responder con redondeo a 12 bits, justificando desde qué región de memoria se está ejecutando este código.**
+**b) ¿Se detiene en algún momento la ejecución si se pone un breakpoint en mpentry_start? ¿Por qué?**
+
+a) Esa línea pertenece al código entry point de un AP, dicho código fué mapeado a la dirección `MPENTRY_PADDR` con `memmove()` en `boot_aps()`. Esa dirección es `0x7000` (es una dirección física). Por lo tanto, el registro `%eip` cuando pasa por esa instrucción, redondeada a 12 bits, es `0x7000`.
+
+b) No, la ejecución no se detiene si se pone un breakpoint en `mpentry_start`. GDB desconoce la dirección de esa instrucción, esto se debe a que ese cpu está en real-mode y no tiene virtualización de memoria (que es lo que necesita gdb para ubicarlo).
+
+
+**4. Con GDB, mostrar el valor exacto de %eip y mpentry_kstack cuando se ejecuta la instrucción anterior en el último AP.**
+
+Con los siguientes comandos se llega al breakpoint deseado `(0x7000)` en el thread 4 (último AP)
+
+```
+(gdb) b *0x7000 thread 4
+	Breakpoint 1 at 0x7000
+(gdb) continue
+	Continuing.
+	Thread 2 received signal SIGTRAP, Trace/breakpoint trap.
+	[Switching to Thread 2]
+	The target architecture is assumed to be i8086
+	[ 700:   0]    0x7000:	cli    
+	0x00000000 in ?? ()
+(gdb) disable 1
+(gdb) si 10
+	The target architecture is assumed to be i386
+	=> 0x7020:	mov    $0x10,%ax
+	0x00007020 in ?? ()
+(gdb) enable 1
+(gdb) continue
+	Continuing.
+	Thread 3 received signal SIGTRAP, Trace/breakpoint trap.
+	[Switching to Thread 3]
+	The target architecture is assumed to be i8086
+	[ 700:   0]    0x7000:	cli    
+	0x00000000 in ?? ()
+(gdb) disable 1
+(gdb) si 10
+	The target architecture is assumed to be i386
+	=> 0x7020:	mov    $0x10,%ax
+	0x00007020 in ?? ()
+(gdb) enable 1
+(gdb) continue
+Continuing.
+	Thread 4 received signal SIGTRAP, Trace/breakpoint trap.
+	[Switching to Thread 4]
+	The target architecture is assumed to be i8086
+	[ 700:   0]    0x7000:	cli    
+	0x00000000 in ?? ()
+```
+
+Con los siguientes comandos se visualizan las 10 próximas instrucciones:
+
+```
+(gdb) disable 1
+(gdb) si 10
+	The target architecture is assumed to be i386
+	=> 0x7020:	mov    $0x10,%ax
+	0x00007020 in ?? ()
+(gdb) x/10i $eip
+	=> 0x7020:	mov    $0x10,%ax
+	   0x7024:	mov    %eax,%ds
+	   0x7026:	mov    %eax,%es
+	   0x7028:	mov    %eax,%ss
+	   0x702a:	mov    $0x0,%ax
+	   0x702e:	mov    %eax,%fs
+	   0x7030:	mov    %eax,%gs
+	   0x7032:	mov    $0x11f000,%eax
+	   0x7037:	mov    %eax,%cr3
+	   0x703a:	mov    %cr4,%eax
+```
+
+Como vemos, `eax` se seteará con el valor `$0x11f000` que corresponde con la dirección física del símbolo `entry_pgdir` que es la entrada al page directory del kernel. Podemos poner un breakpoint y visualizar el valor de `eip` en esta línea haciendo:
+
+```
+(gdb) watch $eax == 0x11f000
+	Watchpoint 3: $eax == 0x11f000
+(gdb) continue
+	Continuing.
+	=> 0x7037:	mov    %eax,%cr3
+	Thread 4 hit Watchpoint 3: $eax == 0x11f000
+	Old value = 0
+	New value = 1
+	0x00007037 in ?? ()
+(gdb) p $eip
+$1 = (void (*)()) 0x7037
+
+```
+Luego continuamos ejecutando líneas con `si` hasta la línea en que se se setea el stack en `mpentry_kstack` e imprimimos dicha dirección.
+
+```
+(gdb) si
+...
+(gdb) p mpentry_kstack
+$4 = (void *) 0xf025b000 <percpu_kstacks+131072>
+```
+
+ipc_recv
+---------
+
+**1. Un proceso podría intentar enviar el valor númerico -E_INVAL vía ipc_send(). ¿Cómo es posible distinguir si es un error, o no? En estos casos:**
+
+```
+CASO A:
+envid_t src = -1;
+int r = ipc_recv(&src, 0, NULL);
+
+if (r < 0)
+  if (/* ??? */)
+    puts("Hubo error.");
+  else
+    puts("Valor negativo correcto.")
+```
+
+
+```
+CASO B
+// Versión B
+int r = ipc_recv(NULL, 0, NULL);
+
+if (r < 0)
+  if (/* ??? */)
+    puts("Hubo error.");
+  else
+    puts("Valor negativo correcto.")
+```
+
+En el caso A, el wrapper `ipc_recv` fue llamado con un valor de `from_env_store` distinto de NULL, por lo que de fallar la syscall dicho valor será puesto a cero. Entonces el código para diferenciar un error de un valor negativo enviado podría ser:
+
+```
+CASO A:
+envid_t src = -1;
+int r = ipc_recv(&src, 0, NULL);
+
+if (r < 0)
+  if (!src)
+    puts("Hubo error.");
+  else
+    puts("Valor negativo correcto.")
+```
+
+En el caso B, tanto `from_env_store` como `perm_store` pasados como parámetro son `NULL`, lo que significa que no servirán para distinguir un error de la syscall. En este caso puede utilizarse el registro `eax`, que si retorna con éxito, es puesto a 0. El código sería el siguiente:
+
+```
+CASO B
+// Versión B
+int r = ipc_recv(NULL, 0, NULL);
+
+if (r < 0)
+  if (!thisenv->env_tf.tf_regs.reg_eax)
+    puts("Hubo error.");
+  else
+    puts("Valor negativo correcto.")
+```
+
+sys_ipc_try_send
+----------------
+
+**Implementar la llamada al sistema `sys_ipc_try_send()` siguiendo los comentarios en el código, y responder:**
+
+**1. ¿Cómo se podría hacer bloqueante esta llamada? Esto es: qué estrategia de implementación se podría usar para que, si un proceso A intenta a enviar a B, pero B no está esperando un mensaje, el proceso A sea puesto en estado `ENV_NOT_RUNNABLE`, y sea despertado una vez B llame a `ipc_recv()`.**
+
+Se podria usar un mecanismo similar al que utiliza `sys_ipc_recv` agregando un flag del tipo `bool env_ipc_sending;` en el `struct Env`. De esta manera ambas syscalls primero validarán errores y luego en caso del send si el proceso pasado por parámetro no está dormido en receiving, el sender se va a dormir. Así el proceso que recibe (ahora la syscall recibirá el id del proceso que espera recibir), comprobará si este está intentando enviar datos con el flag propuesto. Como este es el caso, mapeará y tomará el dato necesario y despertará al sender y retornará. El caso análogo en el que el receive llega primero y este se pone en NOT RUNNEABLE ya lo conocemos y es el implementado hasta ahora.
+
+**2. Con esta nueva estrategia de implementación mejorada ¿podría ocurrir un deadlock? Poner un ejemplo de código de usuario que entre en deadlock.**
+
+Conversado en clase con docente, a la espera de e-mail.
+
+**3. ¿Podría el kernel detectar el deadlock, e impedirlo devolviendo un nuevo error, E_DEADLOCK? ¿Qué función o funciones tendrían que modificarse para ello?**
+
+Conversado en clase con docente, a la espera de e-mail.
+
+Ejecución de Tests
+----
+
+```
+make[1]: Leaving directory '/home/grobles/FIUBA/Sistemas Operativos/TP1-SisOp'
+helloinit: OK (2.4s) 
+Part 0 score: 1/1
+
+yield: OK (1.2s) 
+spin0: Timeout! OK (1.2s) 
+Part 1 score: 2/2
+
+dumbfork: OK (0.8s) 
+forktree: OK (2.0s) 
+spin: OK (2.0s) 
+Part 2 score: 3/3
+
+yield2: OK (1.0s) 
+stresssched: OK (2.1s) 
+Part 3 score: 2/2
+
+sendpage: OK (2.0s) 
+pingpong: OK (1.9s) 
+primes: OK (3.3s) 
+Part 4 score: 3/3
+
+faultread: OK (1.3s) 
+faultwrite: OK (2.3s) 
+faultdie: OK (1.9s) 
+faultregs: OK (2.2s) 
+faultalloc: OK (1.8s) 
+faultallocbad: OK (2.1s) 
+faultnostack: OK (1.8s) 
+faultbadhandler: OK (2.2s) 
+faultevilhandler: OK (1.8s) 
+Part 5 score: 9/9
+
+Score: 20/20
+```
+
diff --git a/TP3_EXPLANATION b/TP3_EXPLANATION
new file mode 100644
index 0000000..759369f
--- /dev/null
+++ b/TP3_EXPLANATION
@@ -0,0 +1,158 @@
+TP3: MULTIPLES PROCESOS DE USUARIO DE MANERA RECURRENTE
+
+Necesitamos un planificador (SCHEDULER).
+
+¿Cómo crear procesos?
+
+|MULTI - CPU| 
+
+PARTE 1
+
+Hay un reloj que se configura para que interrumpa periodicamente y le de el control al s.o.
+Las tareas timer_irq y timer_preempt se encargan de eso.
+
+Cada vez que se ejecute la interrupcion del reloj, esas tareas van a llamar al planificador para que cambie de proceso.
+
+El planificador será Round Robin, bien sencillo, que dada la lista de 1024 envs, arrancará en el proceso actual y avanzará
+hacia adelante buscando el siguiente proceso que está en estado RUNNABLE.
+
+En el planificador: curenv => next available (y llamar a la función env_run())
+
+No empezar siempre por el indice 0 del arreglo, sino siempre le daremos oportunidades a los primeros.
+Lo que se hace es agarrar curenv, fijarnos donde esta en el arreglo, y empezar a schedulear a partir del siguiente.
+Eso hace que sea un round robin efectivamente.
+
+env_run() no devuelve nunca, pasa a modo usuario, y para que ese modo usuario termine lo tiene que destruir el kernel en modo kernel.
+
+Syscall asociada: sys_yield	Permite que un proceso de usuario se saque a si mismo de la cpu.
+
+---------------------------------
+tarea: timer_irq
+En modo kernel no vamos a aceptar ninguna interrupcion ni siquiera la del reloj. Eso se maneja en el campo istrap del SETGATE. En JOS todas estarán en 0, para desactivar interrupciones en modo kernel. Se habilitan de nuevo en modo usuario. 
+
+Nosotros no somos los que vamos a activar y desactivar interrupciones al entrar y salir del kernel, esto se hace automático con el parámetro istrap. Hay un FLAG en el campo EFLAGS que marca si estan habilitadas o no. Al restaurar EFLAGS, se restaura ese flag.
+
+punto 3: Hay que habilitar en el EFLAG de un nuevo proceso creado, poner el flag de interrupciones a 1.
+	Hay que setear el flag FL_IF en env_alloc (ESTO ES UNA SOLA LINEA XDD GRACIAS DATO)
+
+----------------------------------
+tarea: sched_yield: planificador que permite cambiar de proceso. son 10 líneas un ciclo for buscando un proceso que se pueda ejecutar y ejecutarlo
+----------------------------------
+tarea: timer_preempt
+lapic_eoi() : Cuando hay interrupciones externas, hay que indicarle al dispositivo que la recibí y la estoy manejando. Se le indica al hardware que el S.O. tomó la interrupción.
+----------------------------------
+
+En trapentry.S hay que llamar al handler, se debe llamar con NOEC.
+
+Que pasa cuando termina main de proceso de usuario -> En lib/entry.S comienzan a ejecutarse los procesos. En un momento hay un call libmain que hace un par de cositas y luego llama a umain (lib/libmain.c) y luego a exit().
+
+TOTAL PARTE 1: 28 líneas de código.
+
+PARTE 2
+¿Cómo crear procesos? : FORK
+En JOS que es un exokernel, existe una syscall que se llama Sys_exofork.
+A crea B, el padre de B es A, B tiene otro envid, se hace una copia de los registros, pero NO SE HACE UNA COPIA DEL ESPACIO DE DIRECCIONES DEL PADRE. 
+
+JOS da un numero de syscall para que el proceso padre pueda configurar el address space del proceso hijo (Por eso exokernel, es medio vacio para que lo implemente el usuario). Por ejemplo: alocar una página del padre al hijo, mapear una pagina entre padre e hijo (para que la compartan).
+	sys_env_set_status()
+	..
+	..
+	..
+	lo que hacen es verificar permisos etc.. y despues llaman a funciones del kernel (ej: env_alloc)
+
+dumbfork: ya está implemetnado, llama a exofork y para todo el código del programa, duplica la página, y el stack también (duppage).
+duppage: es llamada desde el padre para configurar al hijo. Queremos copiar todo el espacio de direcciones en nustor hijo, pues el hijo esta vacio. Alocamos una pagina en la direccion que nos dicen, y queremos copiar lo que hay en una direccion, en esa direccion del hijo (UTEMP es una direccion temporal). Con memove copio de mi direccion a la tempora y luego me la mapeo a mi mismo.
+
+Tres versiones de Fork:
+	DUMP (ya esta hecha)
+	V0	(Parte 2)
+	COW	(Parte 5)
+
+en V0, vamos a hacer una version parecida a la DUMP, pero que se de cuenta que si una pagina es de solo lectura haga que se pueda compartir. Si es de escritura entonces la copiará (no la compartirá).
+En COW, que se hara en la parte 5, haremos tambien que se pueda compartir lo que es sólo escritura.
+
+
+Parte 3: Ejecucion en paralelo multi core
+Va a haber una cpu que arranca primero e inicializa el sistema y se encarga de arrancar las demás, con una función en kern/init.c que se llama lapic_init (para iniciar interrupciones) y mp_init (para encontrar cpus hay e inicializarlas, máximo 8). Esto no nos interesa xD. bppt_aps, una vez detectado los procesadores adicionales, los pone a hacer trabajo, arranca una cpu con tal código, y le pasa el código. entry.S tiene el codigo que arranca la cpu, en kern/mpentry.S hace algo parecido, activa la memoria virtual, configura el stack, etc.. La cpu arranca en modo real, entonces, nosotros tenemos el codigo de la cpu cargado en memoria y están arriba en las direcciones altas, pero la cpu nueva no la puedo ejecutar ahi xq todavia no tiene paginado ni memoria virtual activada, pero ya no está abajo porque cuando haciamos el salto de entry page directory al posta del kernel, el kernel ya no tenia los mappings bajos. mp_main tiene la rutina para inicializar un cpu. En mp_main, hay que borrar el for infinito y usar ese espacio para llamar al scheduler.
+
+Tarea kernel_lock
+
+Puede ocurrir que dos procesos de usuario terminen a la vez entonces se vuelve al kernell en dos cpus a la vez (kernel concurrente en mas de una cpu). Modo kernel en dos cpus distintos es algo que no queremos. Necesitamos primitivas para mutual exclusion. 
+En JOS hay un sólo lock gigante, cuando entro al kernel lo agarro y cuando salgo lo suelto. Si hay 2 cpus con el kernel, uno de ellos estara en busy wait. Todas las veces que se entra en el kernel hay que adquirir ese log. 
+
+
+Cosa a tener en cuenta: cuando hay interripcion se ejecuta el handler, sobre el stack del kernel. EN pmap.c haciamos un boot_map_region, ahora hay que hacerlo para cada CPU (guiarse mirando cada stack de cada cpu en memmap.h).
+
+Tarea mem_init_mp
+Stacks de la cpu. Se hace un ciclo para que el procesador 0 mapee en el page directory el espacio de CADA CPU, por eso el ciclo for. 
+trap_init_percpu -> cada cpu tiene que llamarlo. 
+
+
+fork_v0
+
+dumbfork y fork_v0
+Son muy paraecidos, ambos tienenuna llamada a sys_exofork, y luego tienen un ciclo para cada página, donde ahí hacen cosas ligeramente distintas.
+
+El dumbfork llama a una función duppage()
+El fork_v0 llama a otra función dup_or_share()
+
+Luego, ponen al hijo en RUNNING (estado).
+
+Se resume en tres pasos: Se crea un hijo clonando al padre, se rellena al hijo, y se pone al hijo en ejecución.
+
+--
+duppage() hace una copia de cada página del padre en el hijo.
+En duppage copia solo la parte del texto (text segment). Sólo copia una región que se sabe que esta mapeada entera, entonces no chequea el bit de presencia, etc...
+
+Para que el padre le pase información al hijo, se hace un proceso: se aloca una nueva página y se inserta en el hijo (pagina fisica), con page map se mapea la direccion fisica de esa pagina en el espacio del padre, entonces el padre y el hijo estan referenciando la misma pagina fisica, luego el padre escribe en esa pagina y lo podra ver el hijo. Luego el padre hace un unmap (se las desmapea). Todo esto es porque no se puede manejar dos address spaces al mismo tiempo. Para este proceso se usa la función sys_page_map().
+--
+
+dup_or_page: Esto si copia todo el espacio de direcciones, desde ZERO hasta UTOP, salteando las páginas que no esta presentes (chequea el bit PTE_P).
+
+Si la página es de lectura, lo que hace es que tanto padre como hijo compartan la misma página física, pero si es de escritura, hace el mismo proceso de duppage() (borra la referencia del padre a la memoria física en un tercer paso).
+
+Es una pequeña mejora que si hay paginas de solo lectura, no las copia al pedo, pero igualmente es ineficiente como duppage().
+
+--
+fork_cow
+Los PDE tienen un bit llamado bit de COW (copy on write). Cuando una página compartida entre dos procesos de solo lectura intenta ser escrita, se genera un PAGE FAULT, excepcion tomada por el kernel, que se fijará si esa PDE tiene en 1 el bit de COW, en ese caso, hará una copia de esa página de modo que el padre y el hijo tendrán ahora sus paginas individuales, una copia de la otra, luego el procesos padre o hijo que intento escribir en esa página.
+Los page fault generan información extra en el registro CR2, es la unica excepcion que se necesita tener informacion extra xD.
+
+
+PARTE 5: MANEJO DE PAGE FAULTS
+
+El kernel recibe las interrupciones pero se lava las manos y el USUARIO tiene que manejar los forks, etc. El kernel de jobs va a dar un mecanismmo para que cuando ocurre un page fault se invoque a un manejador del proceso de usuario.
+
+U -> K -> U (manejador)
+
+Se nos da una syscall que le permite a un proceso setear un manejador para el page fault.
+
+Tarea: set_pgfault_upcall
+
+Diferencias entre excepciones y fault: algunas excepciones se reintenta la misma instruccion, otras se vuelve a la instruccion siguiente.
+Page fault: se reintenta la misma instrucción.
+
+Existira un trapframe del lado de usuario llamado UTRAPFAME (Es un struct tambien pero con menos cosas)
+
+_alltraps 		-> trap(tf)	 	-> env_pop_tf
+			trap compone un UTF y nos llama al maneajador de assembler.
+handler_asm	  handler(utf) (lib/fork.c)     -> handler_asm (*)
+
+Hay que escribir un cacho de assembler en el trapframe.
+
+La parte que lo complica todo, el handler (*) se ejecuta en una pila distinta de la pila del proceso, hay otra pila y la razon es q la pila del usuario podría estar en una página marcada como COW, la llamamos la pila de excepciones.
+
+-----------------------------------------------------
+
+IPC:
+En la comunicación entre procesos se puede compartir un valor entero y una página (opcionalmente)
+
+Send no es bloqueante y recv si es bloqueante.
+
+el sys_Try_send es no bloqeuante: devuelve inmediatamente: pueden pasar dos cosas, envió bien o devuelve error.
+Se tiene que fijar que el proceso destino esté trabado esperando (si tiene el flag ev->ipc_recv, esta esperando recibir algo)
+
+ipc_send si va a ser bloqueante, va a hacer iterar sys_Try_send hasta que retorne que pudo enviar bien.
+
+¿COMO HACER BLOQUEANTE EL SEND? TENDRIAMOS Q TENER UN MECANISMO SIMILAR AL DE RECV, SE TIENE QUE PODER TENER UN FLAG
+el unico deadlock que puede llegar a ocurrir es en modo usuario por mal uso de los wrappers de las syscalls.
diff --git a/TP_2_EXPLANATION b/TP_2_EXPLANATION
new file mode 100644
index 0000000..5a5f154
--- /dev/null
+++ b/TP_2_EXPLANATION
@@ -0,0 +1,184 @@
+05/10/2018
+
+git remote add -f catedra http://<repo_original>
+
+en lugar de git merge origin/tp2 haremos git merge catedra/tp2
+
+Implementaremos un Proceso de Usuario
+*************************************
+
+Primeras tres partes: Proceso hasta poder largar un proceso
+Partes 4 y 5: Manejos de Syscalls
+
+En JOS los procesos se llaman Enviroments.
+
+Para ejecutar un programa hacer
+$ make run-hello-nox
+
+Tienen ID los procesos/enviroments, el Kernel no tiene.
+
+Los binarios que se ejecutarán esta concatenados como binarios en la imagen del kernel, al final de la imagen del kernel que es un ELF. Esos binarios (ej hello) se empotran concatenados al final de la imagen del kernel. Se dejan ciertos símbolos para saber donde comienza y donde termina un binario, de otra manera sería un chorizo de binario gigante indistinguible.
+Esos simbolos se pueden analizar con  nm /obj/ken/kernel  y comienzan con _binary_obj_user_... (por cada binario que empotra genera esas entradas). El símbolo END apunta al final de la imágen del kernel, cuando ya no hay nada mas.
+
+La macro ENV_CREATE es una macro para que en lugar que yo escriba env_create(_binary_obj_user...), recibe la ubicación del binario que se quiere ejecutar. El makefile compila la imagen del Kernel junto a todos los programas del final, pero se puede ejecutar un solo programa con make xxxxxxx, lo recompilará todo y definirá una macro para correr el programa en particular, ej: hello.
+
+En env.c estaremos implementado el código
+
+Todos los programas de JOS se enlazan con la librería estándar de JOS, es como una mini librería de C.
+
+MODO USUARIO    	    	| MODO KERNEL (*)
+SYS_a(parametros)		|
+SYS_b(parametros)	  --> SYSCALL --> INT(X) --> Syscall(parámetros)
+SYS_c(parámetros)	  id +  parámetros
+				|
+
+El struct evn es lo que el kernel guarda de cada proceso, por ejemplo su ID, el ID del padre, el TIPO, env_status es un enum que da el estado de un proceso (dying muriendo, .. etc). nrun es el numero de veces que se escheduleo el proceso. env_pgdir es un puntero al page directory del proceso. Trapframe guarda info referida a los cambios de contexto.
+
+De UTOP para abajo son los mapeos particulares de cada proceso. De UTOP para arriba son los mapings del Kernel.
+
+Cuando arranca un proceso, su stack comienza en USTACKTOP (ver el dibujo de la memoria). El stack de cada proceso se guarda junto con los registros asociados a este proceso.
+
+El struct PushRegs guarda el estado de los registros al momento del context switch.
+
+En trap.h
+
+
+Las tres variables globales:
+	struct Env *env =  NULL //
+	
+	sttatic struct Env *env_free_list //
+
+	struct Env * curenv = NULL;
+
+Los structs que usamos para alojar procesos estan PRE-ALOCADOS y son 1024. No hay que alocarlos en forma dinámica. Los libres lo sacamos de env_free_list
+
+1ra tarea)
+
+Boot_alloc, memset
+Reserver memoria, mapear con boot_map_region
+
+2da tarea)
+
+Enlazarlos, convertir el arreglo en una lista enlazada
+
+En la lista de paginas libres terminabamos enlazando al revez. Aquí si importa que sea hacia adelante pues el indice de los enviroments facilita la vida que sea asi. HAY QUE ITERAR HACIA ATRÁS.
+
+En los enviroments libres tenemos:
+env_   a NULL
+El status es FREE
+
+
+La función env_alloc()
+***********************
+
+Hay un algoritmo de generación de IDs (PID)
+
+Aca se inicializa un enviroment (proceso) y va completando el struct.
+
+Acá NO SE COPIAN LOS valores del proceso padre, esto lo hace FORK, no confundirse.
+
+
+x86 antes tenia segmentos y sporta hasta 6 segmentos. En linux no se usan, se usa paginado a secas. Por la unica razon q se usan los segmentos es porque estan muy mezclados con lo que es el cambio de privilegios. Los registros que tienen cual segmento esta activo, tienen también el privilegio del segmento.
+
+Tenemos que saer que estan estos segmetos:
+CODE SEGMENT
+DATA SEGMENT
+STACK SEGMENT
+ES 
+FS
+GS
+
+El kernel usa los primeros 3 y los configura que son para él.
+
+El ds, ss y es los redirecciona a un segmento que se llama US (User data), el 3 indica que es un segmento que corre en Nivel 3.
+
+el registro esp se inicializa a una dirección fija USTACKTOP donde el kernel crea el espacio para ese proceso (stack).
+
+
+Tarea: env_setup_vm
+
+Simplemente agarrar el Page directory del kernel y asegurarse de que la parte UTOP es igual. Simplemente es copiar una pagina del page directory del kernel al page directory del enviroment (Es un memcpy).
+
+
+Hasta ahora fue que el kernel configure las estructuras para correr procesos de usuario.
+Falta como ejecutar esos procesos.
+
+Tarea: region_alloc
+
+Es una funcion de utilidad que basicamente dice quiero q mi proceso tenga 16 k lo que sea reservado, para poder cargar el binario y ahi lo puedo copiar. Tiene un ciclo que llama a page insert y page alloc.
+
+Tarea: load_icode
+
+Carga el código de la región donde esta a la región de memoria donde se tiene que ejecutar. 
+
+Hay código en el bootloader de JOS para iterar sobre los segmentos (ver PROGRAM HEADERS en apuntes de cuaderno)
+
+El PROGRAM HEADER se puede ver inspeccionando el ELF del ejecutable HELLO (que esta empotrado en el binario del Kernel)
+
+FOR EACH ProgramHeader:
+	region_alloc(VirtAddr, size)
+	memcpy(offset, size, virtAddr)
+
+OJO, esto puede romper porque el page directory actual es el del kernel. Podría averiguar qué direcciones son las del page directory del proceso. OO LO QUE RECOMIENDA DATO ES: Antes de empezar el ciclo, activar el Page Directory del enviroment, y al salir del ciclo, reactivar el del Kernel. Para esto cargarlo en el registro cr3 y para eso usar la función lcr3(e->pgdir).
+
+
+12/10/2018
+
+Parte 4: la mas importante
+Esta parte va a ser la implementación de syscalls: 
+inc/
+trap.h y syscall.h
+	  --> tiene el enumerado de las syscalls
+kern/
+trap.h y syscall.h y trapentry.S
+	  --> tiene el prototipo de la llamada syscall (ver gráfico (*))
+
+En las syscalls dentro del wrapper siempre se pasan 6 parámetros. 1 es medio especial asique se podría decir que reciben 5.
+La syscall del lado usuario se hace con asm_volatile, pasando los 5 parametros por registros al procesador. HACE LA INTERRUPCIÓN 80 (no es 80 el numeroen JOS pero es analogo) y aparecemos en la syscall del lado kernel,
+esta originalmente tiene un panic (syscall not implemented).
+Se debe hacer un switch del enum de las syscalls y llama a la función de la syscall adecuada.
+
+En principio, tenemos que implementar solamente el handler de las syscalls que las deriva a la función adecuada (como se dijo arriba) y un poquito de la syscall puts (sys_cputs).
+
+La interrupción por software con INT 80 hace que se vaya a buscar un manejador de la interrupción enuna tabla llamada IDTR que tiene punteros a los segmentos de código que son handlers de cada interrupción en particular.
+
+Tabla con punteros a handlers:
+0	| m1    ---> m1{ }
+1	| m2    ---> m2{ }
+2	| m3    ---> m3{ }
+...
+48	| m48
+
+Lo que hay que tener es un wraper ej: Trap(int exception)
+los manejadores m1 .. m48 estaran escritos en ASM y trap estara escrito en C
+
+El trap tendrá un switch que ejecutará cada m1, m2, etc con el parámetro del número de excepción que corresponde.
+
+Los manejadores lo primero que harán será guardar los registros (trap frame). 
+
+Función _alltraps: en algún momento va a hacer un pusha() y guarda los 8 registros en el stack
+
+el pusha hace que el cpu pushee varios registros en el struct trapframe. el inconveniente es que el tf_err a veces es pusheado y a veces no,
+dependiendo de la interrupción. Esto es odioso porque despues para restaurar los registros tenemos que tener esto en cuenta para mapearlos. Como solución a esto tenemos los wrappers TRAPHANDLER y TRAPHANDLER_NOE
+
+Hasta ahora tenemos los handlers, tienen su dirección, pero falta ponerlos en la tabla IDTR. La tabla es "Gatedesc" tiene tamaño de 256 posiciones. Cada entrada no solo tiene la dirección del handler, sino un cacho de data más. Esta data mas no hace falta setearla a mano,
+se puede hacer con la macro SETGATE en mmu.h
+
+trap_init() : la renellaremos con SETGATE(idt[1], 0, code_segment, manejador1, 0);
+				  ...
+				  SETGATE(idt[48], 0, code_segment, manejador48, 3);
+
+Los nombres manejador1..48 son los nombres que definimos nosotros para cada manejador. C no va a encontra
+
+
+la función trap() en trap.c:
+ En JOS no se aceptan interrupciones mientras se esta ejecutando el KERNEL, solo se aceptan desde el modo usuario.
+De lo primero que hace es guardar el trapframe del enviroment que se estaba ejecutando.
+La función termina volviendo al environment que la llamó.
+
+trap_dispatch() va a tener un switch para cada excepcion posible:
+	switch (tf->tf_trapno) {
+		case t_syscall....
+	}	
+
+En este switch vamos a tener manejadores para el T_BRKPT y para T_PGFLT (breackpoint y page fault), para el resto nose hará nada y se volverá al proceso original.
diff --git a/__pycache__/gradelib.cpython-36.pyc b/__pycache__/gradelib.cpython-36.pyc
index 8903521..dd49295 100644
Binary files a/__pycache__/gradelib.cpython-36.pyc and b/__pycache__/gradelib.cpython-36.pyc differ
diff --git a/conf/lab.mk b/conf/lab.mk
index 9561d17..0e4d031 100644
--- a/conf/lab.mk
+++ b/conf/lab.mk
@@ -1,2 +1,2 @@
-LAB=3
-PACKAGEDATE=Thu Sep 29 14:25:51 EDT 2016
+LAB=4
+PACKAGEDATE=Wed Oct 12 17:19:29 EDT 2016
diff --git a/diff_tp2.txt b/diff_tp2.txt
new file mode 100644
index 0000000..e700a74
--- /dev/null
+++ b/diff_tp2.txt
@@ -0,0 +1,1437 @@
+diff --git a/TP2.md b/TP2.md
+index 4816bfe..5dfffb0 100644
+--- a/TP2.md
++++ b/TP2.md
+@@ -3,23 +3,533 @@ TP2: Procesos de usuario
+ 
+ env_alloc
+ ---------
++Inicializa un nuevo Environment (proceso) que se encuentre libre. Entre otras cosas, le asigna un identificador único. El algoritmo para generar un nuevo identificador es el siguiente:
+ 
+-...
++1. ¿Qué identificadores se asignan a los primeros 5 procesos creados? (Usar base hexadecimal.)
+ 
++```
++	// Generate an env_id for this environment.
++	generation = (e->env_id + (1 << ENVGENSHIFT)) & ~(NENV - 1);
++	if (generation <= 0)  // Don't create a negative env_id.
++		generation = 1 << ENVGENSHIFT;
++	e->env_id = generation | (e - envs);
++```
++
++Como todos los structs Env se inicializaron en 0 (con meminit), inicialmente tendrán env_id = 0. En la última línea puede observarse una operación `or` en donde el término derecho es una resta entre dos punteros (aritmética de punteros), donde `e` es la dirección de memoria del enviroment libre siendo incializado y `envs` es la base del arreglo de enviroments. Por lo tanto, esta resta no es mas que el offset de la dirección del enviroment libre siendo inicializado.
++
++Los primeros cinco procesos creados tendrán los siguientes identificadores:
++
++```
++Identificador número 1: 0x1000 = 4096
++Identificador número 2: 0x1001 = 4097
++Identificador número 3: 0x1002 = 4098
++Identificador número 4: 0x1003 = 4099
++Identificador número 5: 0x1004 = 4100
++```
++
++2. Supongamos que al arrancar el kernel se lanzan NENV proceso a ejecución. A continuación se destruye el proceso asociado a envs[630] y se lanza un proceso que cada segundo muere y se vuelve a lanzar. ¿Qué identificadores tendrá este proceso en sus sus primeras cinco ejecuciones?
++
++En la primer ejecución, en el momento que se lanzan NENV procesos, el proceso asociado a envs[630] tendrá el identificador 0x1276. Al morir, dicho identificador seguirá asociado al struct de ese proceso. En su próxima ejecución, en el algoritmo de asignación de id, `e->env_id` tendrá el valor antiguo, por lo que la primera línea donde se hace el cálculo para `generation`, dará un valor distinto que para la primera ejecución. En particular, tendrá un aumento de 4096 unidades (decimal) en cada ejecución. Puesto que el `environment index` es siempre el mismo lo que se va modificando es el `Uniqueifier` que distingue procesos con el mismo índice que fueron creados en distintos tiempos.
++
++Por lo que las primeras 5 ejecuciones de ese proceso tienen los siguientes ids:
++
++```
++1er env_id: 0x1276 = 4726
++2do env_id: 0x2276 = 8822
++3er env_id: 0x3276 = 12918
++4to env_id: 0x4276 = 17014
++5to env_id: 0x5276 = 21110
++```
+ 
+ env_init_percpu
+ ---------------
+ 
+-...
++La instrucción `lgdt` ("Load Global Descriptor Table Register") recibe como operando la dirección de un struct del tipo `Pseudodesc`, que no es más que un uint16_t para LÍMITE y un uint32_t para BASE (en total 6 bytes). Donde BASE es la dirección virtual de la gdt (Global Descriptor Table) y LÍMITE es sizeof(gdt) - 1.
++
++Dicha instrucción guarda estos valores (BASE y LÍMITE) en un registro especial de CPU denominado GDTR. Dicho registro, en x86, tiene 48 bits de longitud. Los 16 bits mas bajos indican el tamaño de la GDT y los 32 bits mas altos indican su ubicación en memoria.
++
++```
++GDTR:
++|LIMIT|----BASE----|
++```
++
++Referencia: https://c9x.me/x86/html/file_module_x86_id_156.html
+ 
+ 
+ env_pop_tf
+ ----------
+ 
+-...
++Esta función restaura el TrapFrame de un Environment. Un TrapFrame no es mas una estructura que guarda una "foto" del estado de los registros en el momento que se realizó un context switch. Cuando el kernel decide que ese Environment debe volver a ejecución realiza una serie de pasos, y el último de ellos es la función `env_pop_tf()`. El switch siempre se hace desde kernel a user space (nunca de user a user space).
++
++1. ¿Qué hay en `(%esp)` tras el primer `movl` de la función?
+ 
++El primer `movl` de la función es:
++```
++movl %0,%%esp
++```
++Que no hace otra cosa más que hacer que apuntar %esp a el TrapFrame del environment (nuevo tope de stack).
++Luego, con `popal` se hace una serie de pops (quitando cosas del nuevo stack, es decir, del TrapFrame) que se van asignando a los registros del CPU.
++
++2. ¿Qué hay en `(%esp)` justo antes de la instrucción `iret`? ¿Y en `8(%esp)`?
++
++Justo antes de la instrucción `iret`, `(%esp)` tiene `uintptr_t tf_eip`. Mientras que en `8(%esp)` tenemos `uint32_t tf_eflags`.
++
++3. ¿Cómo puede determinar la CPU si hay un cambio de ring (nivel de privilegio)?
++
++En la función `env_alloc` (que inicializa un proceso de usuario), se ejecutan las siguientes líneas:
++
++```
++	e->env_tf.tf_ds = GD_UD | 3;
++	e->env_tf.tf_es = GD_UD | 3;
++	e->env_tf.tf_ss = GD_UD | 3;
++	e->env_tf.tf_esp = USTACKTOP;
++	e->env_tf.tf_cs = GD_UT | 3;
++```
++Que setean los 2 bits mas bajos del registro de cada segmento, que equivale al 3er ring. Además, se marcan con GD_UD (global descriptor user data) y GD_UT (global descriptor user text).
++De esta manera el CPU sabe si el code segment a ejecutar pertenece al usuario o al kernel. Si pertenece al usuario, entonces `iret` restaura los registros SS (stack segment) y ESP (stack pointer). El stack pointer caerá dentro de [USTACKTOP-PGSIZE, USTACKTOP].
+ 
+ gdb_hello
+ ---------
++1. Poner un breakpoint en env_pop_tf() y continuar la ejecución hasta allí.
++```
++(gdb) b env_pop_tf
++Punto de interrupción 1 at 0xf0102ead: file kern/env.c, line 514.
++(gdb) c
++Continuando.
++Se asume que la arquitectura objetivo es i386
++=> 0xf0102ead <env_pop_tf>:	push   %ebp
++
++Breakpoint 1, env_pop_tf (tf=0xf01c0000) at kern/env.c:514
++514	{
++```
++
++2. En QEMU, entrar en modo monitor (Ctrl-a c), y mostrar las cinco primeras líneas del comando info registers.
++```
++(qemu) info registers 
++EAX=003bc000 EBX=f01c0000 ECX=f03bc000 EDX=0000023d
++ESI=00010094 EDI=00000000 EBP=f0118fd8 ESP=f0118fbc
++EIP=f0102ead EFL=00000092 [--S-A--] CPL=0 II=0 A20=1 SMM=0 HLT=0
++ES =0010 00000000 ffffffff 00cf9300 DPL=0 DS   [-WA]
++CS =0008 00000000 ffffffff 00cf9a00 DPL=0 CS32 [-R-]
++```
++
++3. De vuelta a GDB, imprimir el valor del argumento tf
++
++```
++(gdb) p tf
++$1 = (struct Trapframe *) 0xf01c0000
++```
++
++4. Imprimir, con `x/Nx tf` tantos enteros como haya en el struct Trapframe donde N = sizeof(Trapframe) / sizeof(int).
++```
++(gdb) print sizeof(struct Trapframe) / sizeof(int)
++$2 = 17
++(gdb) x/17x tf
++0xf01c0000:	0x00000000	0x00000000	0x00000000	0x00000000
++0xf01c0010:	0x00000000	0x00000000	0x00000000	0x00000000
++0xf01c0020:	0x00000023	0x00000023	0x00000000	0x00000000
++0xf01c0030:	0x00800020	0x0000001b	0x00000000	0xeebfe000
++0xf01c0040:	0x00000023
++```
++
++5. Avanzar hasta justo después del `movl ...,%esp`, usando `si M` para ejecutar tantas instrucciones como sea necesario en un solo paso.
++```
++(gdb) disas
++Dump of assembler code for function env_pop_tf:
++=> 0xf0102ead <+0>:	push   %ebp
++   0xf0102eae <+1>:	mov    %esp,%ebp
++   0xf0102eb0 <+3>:	sub    $0xc,%esp
++   0xf0102eb3 <+6>:	mov    0x8(%ebp),%esp
++   0xf0102eb6 <+9>:	popa   
++   0xf0102eb7 <+10>:	pop    %es
++   0xf0102eb8 <+11>:	pop    %ds
++   0xf0102eb9 <+12>:	add    $0x8,%esp
++   0xf0102ebc <+15>:	iret   
++   0xf0102ebd <+16>:	push   $0xf010573c
++   0xf0102ec2 <+21>:	push   $0x20c
++   0xf0102ec7 <+26>:	push   $0xf0105706
++   0xf0102ecc <+31>:	call   0xf01000a9 <_panic>
++End of assembler dump.
++(gdb) si 4
++=> 0xf0102eb6 <env_pop_tf+9>:	popa   
++0xf0102eb6	515		asm volatile("\tmovl %0,%%esp\n"
++(gdb) disas
++Dump of assembler code for function env_pop_tf:
++   0xf0102ead <+0>:	push   %ebp
++   0xf0102eae <+1>:	mov    %esp,%ebp
++   0xf0102eb0 <+3>:	sub    $0xc,%esp
++   0xf0102eb3 <+6>:	mov    0x8(%ebp),%esp
++=> 0xf0102eb6 <+9>:	popa   
++   0xf0102eb7 <+10>:	pop    %es
++   0xf0102eb8 <+11>:	pop    %ds
++   0xf0102eb9 <+12>:	add    $0x8,%esp
++   0xf0102ebc <+15>:	iret   
++   0xf0102ebd <+16>:	push   $0xf010573c
++   0xf0102ec2 <+21>:	push   $0x20c
++   0xf0102ec7 <+26>:	push   $0xf0105706
++   0xf0102ecc <+31>:	call   0xf01000a9 <_panic>
++End of assembler dump.
++```
++
++
++6. Comprobar, con `x/Nx $sp` que los contenidos son los mismos que tf (donde N es el tamaño de tf).
++
++```
++(gdb) x/17x $sp
++0xf01c0000:	0x00000000	0x00000000	0x00000000	0x00000000
++0xf01c0010:	0x00000000	0x00000000	0x00000000	0x00000000
++0xf01c0020:	0x00000023	0x00000023	0x00000000	0x00000000
++0xf01c0030:	0x00800020	0x0000001b	0x00000000	0xeebfe000
++0xf01c0040:	0x00000023
++```
++
++7. Explicar con el mayor detalle posible cada uno de los valores. Para los valores no nulos, se debe indicar dónde se configuró inicialmente el valor, y qué representa.
++
++Para explicar cada uno de los valores, se debe entender que a este punto el "stack" tiene la estructura de un Trapframe, que se vió que tiene un tamaño de 17 `ints` (68 bytes). La estructura de un Trapframe es la siguiente:
++
++```
++struct Trapframe {
++	struct PushRegs tf_regs;
++	uint16_t tf_es;
++	uint16_t tf_padding1;
++	uint16_t tf_ds;
++	uint16_t tf_padding2;
++	uint32_t tf_trapno;
++	/* below here defined by x86 hardware */
++	uint32_t tf_err;
++	uintptr_t tf_eip;
++	uint16_t tf_cs;
++	uint16_t tf_padding3;
++	uint32_t tf_eflags;
++	/* below here only when crossing rings, such as from user to kernel */
++	uintptr_t tf_esp;
++	uint16_t tf_ss;
++	uint16_t tf_padding4;
++} __attribute__((packed));
++```
++
++Donde la estructura PushRegs se conforma como:
++
++```
++struct PushRegs {
++	/* registers as pushed by pusha */
++	uint32_t reg_edi;
++	uint32_t reg_esi;
++	uint32_t reg_ebp;
++	uint32_t reg_oesp;	
++	uint32_t reg_ebx;
++	uint32_t reg_edx;
++	uint32_t reg_ecx;
++	uint32_t reg_eax;
++} __attribute__((packed));
++```
++Las primeras dos líneas de valores de $sp:
++
++```
++0xf01c0000:	0x00000000	0x00000000	0x00000000	0x00000000
++              reg_edi     reg_esi     reg_ebp     reg_oesp
++
++0xf01c0010:	0x00000000	0x00000000	0x00000000	0x00000000
++              reg_ebx     reg_edx     reg_ecx     reg_eax 
++```
++
++Son 8 `ints` (32 bytes) y se corresponde con la estructura de PushRegs, que son todos nulos (lógico si es la primera vez que entra en contexto este environment).
++
++Luego, en la tercer línea de valores:
++
++```
++0xf01c0020:	0x00000023	0x00000023	0x00000000	0x00000000
++		          pad - es    pad - ds    "trapno"    "tf_err" 
++```
++Los primeros 2 `ints` corresponden a `tf_es` + `tf_padding1` y `tf_ds` + `padding2` respectivamente.
++Los valores de `es` y `ds` `(0x0023)` se deben a que en `env_alloc()` se inicializaron con el valor `GD_UD | 3` (Global descriptor number = User Data y 3er ring).
++
++En la cuarta línea de valores tenemos:
++
++```
++0xf01c0030:	0x00800020	0x0000001b	0x00000000	0xeebfe000
++              tf_eip      pad - cs    tf_eflags   tf_esp
++```
++El valor de tf_eip (instruction pointer) es la dirección a la primera línea del código ejecutable del environment. Si investigamos el elf con `readelf -S obj/user/hello` se observa lo siguiente:
++
++```
++There are 11 section headers, starting at offset 0x7690:
++
++Section Headers:
++  [Nr] Name              Type            Addr     Off    Size   ES Flg Lk Inf Al
++  [ 0]                   NULL            00000000 000000 000000 00      0   0  0
++->[ 1] .text             PROGBITS        00800020 006020 000d19 00  AX  0   0 16 <- (*)
++  [ 2] .rodata           PROGBITS        00800d3c 006d3c 000280 00   A  0   0  4
++  [ 3] .data             PROGBITS        00801000 007000 000004 00  WA  0   0  4
++  [ 4] .bss              NOBITS          00801004 007004 000004 00  WA  0   0  4
++  [ 5] .stab_info        PROGBITS        00200000 001000 000010 00  WA  0   0  1
++  [ 6] .stab             PROGBITS        00200010 001010 002905 0c   A  7   0  4
++  [ 7] .stabstr          STRTAB          00202915 003915 0017ee 00   A  0   0  1
++  [ 8] .symtab           SYMTAB          00000000 007004 000440 10      9  25  4
++  [ 9] .strtab           STRTAB          00000000 007444 0001fd 00      0   0  1
++  [10] .shstrtab         STRTAB          00000000 007641 00004e 00      0   0  1
++```
++
++La línea señalada con `-> <- (*)` indica que el text segment, donde se ubica el código ejecutable, comienza en la dirección 0x00800020.
++
++El valor de `cs` `(0x0000001b)` es el resultado de haberlo inicializado como `GD_UT | 3` en `env_alloc()`. Dichos valores setean el Global Descriptor Number como User Text y 3er Ring de privilegios.
++
++El valor de `esp/stack pointer (0xeebfe000)` se corresponde la dirección del stack seteado en `env_alloc()`, que es `USTACKTOP`. Esto es, el tope del stack en el Address Space del environment. Esquema:
++```
++ *    USTACKTOP  --->  +------------------------------+ 0xeebfe000
++ *                     |      Normal User Stack       | RW/RW  PGSIZE
++ *                     +------------------------------+ 0xeebfd000
++```
++
++Por último, la quinta línea:
++```
++0xf01c0040:	0x00000023
++              pad - ss
++```
++
++El valor de `ss` (stack segment) se corresponde con lo seteado en env_alloc(), que es exactamente lo mismo que se hizo para `ds` (data segment) y `es` (extra segment).
++
++
++8. Continuar hasta la instrucción iret, sin llegar a ejecutarla. Mostrar en este punto, de nuevo, las cinco primeras líneas de info registers en el monitor de QEMU. Explicar los cambios producidos.
++```
++(gdb) disas
++Dump of assembler code for function env_pop_tf:
++   0xf0102ead <+0>:	push   %ebp
++   0xf0102eae <+1>:	mov    %esp,%ebp
++   0xf0102eb0 <+3>:	sub    $0xc,%esp
++   0xf0102eb3 <+6>:	mov    0x8(%ebp),%esp
++=> 0xf0102eb6 <+9>:	popa   
++   0xf0102eb7 <+10>:	pop    %es
++   0xf0102eb8 <+11>:	pop    %ds
++   0xf0102eb9 <+12>:	add    $0x8,%esp
++   0xf0102ebc <+15>:	iret   
++   0xf0102ebd <+16>:	push   $0xf010573c
++   0xf0102ec2 <+21>:	push   $0x20c
++   0xf0102ec7 <+26>:	push   $0xf0105706
++   0xf0102ecc <+31>:	call   0xf01000a9 <_panic>
++End of assembler dump.
++(gdb) si 4
++=> 0xf0102ebc <env_pop_tf+15>:	iret   
++0xf0102ebc	515		asm volatile("\tmovl %0,%%esp\n"
++(gdb) disas
++Dump of assembler code for function env_pop_tf:
++   0xf0102ead <+0>:	push   %ebp
++   0xf0102eae <+1>:	mov    %esp,%ebp
++   0xf0102eb0 <+3>:	sub    $0xc,%esp
++   0xf0102eb3 <+6>:	mov    0x8(%ebp),%esp
++   0xf0102eb6 <+9>:	popa   
++   0xf0102eb7 <+10>:	pop    %es
++   0xf0102eb8 <+11>:	pop    %ds
++   0xf0102eb9 <+12>:	add    $0x8,%esp
++=> 0xf0102ebc <+15>:	iret   
++   0xf0102ebd <+16>:	push   $0xf010573c
++   0xf0102ec2 <+21>:	push   $0x20c
++   0xf0102ec7 <+26>:	push   $0xf0105706
++   0xf0102ecc <+31>:	call   0xf01000a9 <_panic>
++End of assembler dump.
++```
++
++Anterior:
++```
++(qemu) info registers
++EAX=003bc000 EBX=f01c0000 ECX=f03bc000 EDX=0000023d
++ESI=00010094 EDI=00000000 EBP=f0118fd8 ESP=f0118fbc
++EIP=f0102ead EFL=00000092 [--S-A--] CPL=0 II=0 A20=1 SMM=0 HLT=0
++ES =0010 00000000 ffffffff 00cf9300 DPL=0 DS   [-WA]
++CS =0008 00000000 ffffffff 00cf9a00 DPL=0 CS32 [-R-]
++```
++
++Actual:
++```
++(qemu) info registers
++EAX=00000000 EBX=00000000 ECX=00000000 EDX=00000000
++ESI=00000000 EDI=00000000 EBP=00000000 ESP=f01c0030
++EIP=f0102ebc EFL=00000096 [--S-AP-] CPL=0 II=0 A20=1 SMM=0 HLT=0
++ES =0023 00000000 ffffffff 00cff300 DPL=3 DS   [-WA]
++CS =0008 00000000 ffffffff 00cf9a00 DPL=0 CS32 [-R-]
++```
++
++Se actualizaron los valores de los registros de propósito general (`EDI`, `ESI`, `EBP`, `EBX`, `EDX`, `ECX` y `EAX`) a los valores traidos del Trapframe. Esto fué gracias a la instrucción `popal`
++
++Se actualizó el valor del registro `ES`. Esto fué gracias a la instrucción `popl %%es`
++
++Se actualizó el valor del registro `DS`. Esto fué gracias a la instrucción `popl %%ds`
++
++El cambio producido en `EIP` se debe a que el instruccion pointer avanzó algunas pocas líneas de código, pero no porque se haya traido del Trapframe.
++
++El code segment no se vió afectado, tampoco los flags.
++
++9. Ejecutar la instrucción iret. En ese momento se ha realizado el cambio de contexto y los símbolos del kernel ya no son válidos.
++
++Imprimir el valor del contador de programa con `p $pc` o `p $eip`
++
++```
++(gdb) p $pc
++$1 = (void (*)()) 0x800020
++```
++
++Cargar los símbolos de hello con `symbol-file obj/user/hello`. Volver a imprimir el valor del contador de programa
++
++```
++(gdb) p $pc
++$1 = (void (*)()) 0x800020 <_start>
++```
++Mostrar una última vez la salida de info registers en QEMU, y explicar los cambios producidos.
++
++```
++(qemu) info registers
++EAX=00000000 EBX=00000000 ECX=00000000 EDX=00000000
++ESI=00000000 EDI=00000000 EBP=00000000 ESP=eebfe000
++EIP=00800020 EFL=00000002 [-------] CPL=3 II=0 A20=1 SMM=0 HLT=0
++ES =0023 00000000 ffffffff 00cff300 DPL=3 DS   [-WA]
++CS =001b 00000000 ffffffff 00cffa00 DPL=3 CS32 [-R-]
++```
++
++Ahora se actualizaron el `EIP` (Instruction pointer), `CS` (code segment), `EFL` (EFLAGS), y el `SS` (Stack Pointer) a los valores indicados por Trapframe.
++
++10. Poner un breakpoint temporal (tbreak, se aplica una sola vez) en la función syscall() y explicar qué ocurre justo tras ejecutar la instrucción `int $0x30`. Usar, de ser necesario, el monitor de QEMU.
++```
++(gdb) tbreak syscall
++Punto de interrupción temporal 2 at 0x8009ed: file lib/syscall.c, line 23.
++(gdb) c
++Continuando.
++=> 0x8009ed <syscall+17>:	mov    0x8(%ebp),%ecx
++
++Temporary breakpoint 2, syscall (num=0, check=-289415544, a1=4005551752, 
++    a2=13, a3=0, a4=0, a5=0) at lib/syscall.c:23
++23		asm volatile("int %1\n"
++```
++
++Al ejecutar la instrucción `int $0x30` se genera una interrupción que es tomada por el `kernel`.
++
++La información de info registers es:
++
++```
++EAX=00000000 EBX=00000000 ECX=00000000 EDX=00000663
++ESI=00000000 EDI=00000000 EBP=00000000 ESP=00000000
++EIP=0000e062 EFL=00000002 [-------] CPL=0 II=0 A20=1 SMM=0 HLT=0
++ES =0000 00000000 0000ffff 00009300
++CS =f000 000f0000 0000ffff 00009b00
++```
++Observar que ahora tanto `ES` como `CS` (code segment) tienen sus últimos bits en 0, lo que significa que se está en el Ring 0 de privilegios (modo `kernel`).
++
++
++kern_idt
++--------
++
++1. ¿Cómo decidir si usar TRAPHANDLER o TRAPHANDLER_NOEC? ¿Qué pasaría si se usara solamente la primera?
++
++Para decidir si usar una u la otra, se debe analizar para cada excepción/interrupción, si para esta el CPU automáticamente hace un push al stack del código de error o no. Para el primer caso se debe utilizar la macro `TRAPHANDLER` y para el segundo `TRAPHANDLER_NOEC`. Si se utilizara solamente la primera, en los casos de excepciones/interrupciones donde el CPU no haga `push` del código de error, el stack basado en el trapframe estaría con un formato inválido, desencadenando en errores graves.
++
++2. ¿Qué cambia, en la invocación de handlers, el segundo parámetro (istrap) de la macro `SETGATE`? ¿Por qué se elegiría un comportamiento u otro durante un syscall?
++
++Con el valor `istrap = 0`, el CPU deshabilita las interrupciones cuando se está en modo kernel. Con `istrap = 1`, el CPU no las desactiva. En `JOS`, no se considerará que el CPU tome interripciones cuando se esté en modo kernel. Otros kernels más avanzados podrían ponerlo a 1.
++
++3. Leer `user/softint.c` y ejecutarlo con `make run-softint-nox`. ¿Qué excepción se genera? Si hay diferencias con la que invoca el programa… ¿por qué mecanismo ocurre eso, y por qué razones?
++
++
++Al ejecutar `make run-softint-nox` se obtiene lo siguiente por salida estándar:
++
++```
++[00000000] new env 00001000
++Incoming TRAP frame at 0xefffffbc
++TRAP frame at 0xf01c0000
++  edi  0x00000000
++  esi  0x00000000
++  ebp  0xeebfdfd0
++  oesp 0xefffffdc
++  ebx  0x00000000
++  edx  0x00000000
++  ecx  0x00000000
++  eax  0x00000000
++  es   0x----0023
++  ds   0x----0023
++  trap 0x0000000d General Protection
++  err  0x00000072
++  eip  0x00800036
++  cs   0x----001b
++  flag 0x00000082
++  esp  0xeebfdfd0
++  ss   0x----0023
++[00001000] free env 00001000
++Destroyed the only environment - nothing more to do!
++```
++
++Puede oservarse que el valor de `trap` es 0x0000000d que se corresponde con el decimal 13. El `trap` con dicho número es "General Protection" que es causado por "Any memory reference and other protection checks". Esto es diferente a la que se invocó en el programa (14 = page fault). Esto se debe a que en el llamado de la interrupción 14 en `softint.c` se tiene privilegios de modo usuario, mientras que dicha interrupción en el archivo `trap.c`, `SETGATE(idt[T_PGFLT], 0, GD_KT, trap_14, 0);` fue declarada con un nivel de privilegio 0 (el quinto argumento) lo que quiere decir que solo el kernel puede transferir la ejecución a esa interrupción. Si se intenta violar esta regla ocurre una excepción `General Protection` (13) que es justamente la que ocurre.
++
++
++user_evilhello
++--------------
++
++Tenemos la primer versión del programa `evihello.c`:
++```
++// evil hello world -- kernel pointer passed to kernel
++// kernel should destroy user environment in response
++
++#include <inc/lib.h>
++
++void
++umain(int argc, char **argv)
++{
++	// try to print the kernel entry point as a string!  mua ha ha!
++	sys_cputs((char*)0xf010000c, 100);
++}
++```
++Con el cual tenemos la siguiente salida:
++```
++[00000000] new env 00001000
++Incoming TRAP frame at 0xefffffbc
++f�rIncoming TRAP frame at 0xefffffbc
++[00001000] exiting gracefully
++[00001000] free env 00001000
++Destroyed the only environment - nothing more to do!
++```
++
++Mientras que con la siguiente versión:
++```
++#include <inc/lib.h>
++
++void
++umain(int argc, char **argv)
++{
++    char *entry = (char *) 0xf010000c;
++    char first = *entry;
++    sys_cputs(&first, 1);
++}
++```
++
++Tenemos la siguiente salida:
++```
++[00000000] new env 00001000
++Incoming TRAP frame at 0xefffffbc
++[00001000] user fault va f010000c ip 00800039
++TRAP frame at 0xf01c0000
++  edi  0x00000000
++  esi  0x00000000
++  ebp  0xeebfdfd0
++  oesp 0xefffffdc
++  ebx  0x00000000
++  edx  0x00000000
++  ecx  0x00000000
++  eax  0x00000000
++  es   0x----0023
++  ds   0x----0023
++  trap 0x0000000e Page Fault
++  cr2  0xf010000c
++  err  0x00000005 [user, read, protection]
++  eip  0x00800039
++  cs   0x----001b
++  flag 0x00000082
++  esp  0xeebfdfb0
++  ss   0x----0023
++[00001000] free env 00001000
++Destroyed the only environment - nothing more to do!
++```
++1. ¿En qué se diferencia el código de la versión en `evilhello.c` mostrada arriba?
++En la segunda versión primero se intenta acceder explícitamente a la dirección `0xf010000c` desde la aplicación de usuario. Dado que esta memoria pertenece al kernel, ocurre aquí el page fault.
++
++2. ¿En qué cambia el comportamiento durante la ejecución? ¿Por qué? ¿Cuál es el mecanismo?
++Como vemos para la segunda versión el proceso es destruído a causa del Page Fault. Pero para el primer caso simplemente se le pasa la dirección al kernel y dicha dirección será accedida en modo kernel dentro del handler de la syscall, por ello es que no ocurre ningún Page Fault y el programa termina correctamente. Por esto es necesario que el kernel valide los punteros que envía el usuario como argumentos de las syscalls.
++
++
+ 
+-...
+diff --git a/kern/env.c b/kern/env.c
+index 163d7d4..075e1e5 100644
+--- a/kern/env.c
++++ b/kern/env.c
+@@ -12,8 +12,11 @@
+ #include <kern/trap.h>
+ #include <kern/monitor.h>
+ 
+-struct Env *envs = NULL;           // All environments
+-struct Env *curenv = NULL;         // The current env
++// Arreglo de procesos (variable global, de longitud NENV).
++struct Env *envs = NULL;  // All environments
++// Proceso actualmente en ejecución (inicialmente NULL).
++struct Env *curenv = NULL;  // The current env
++// Lista enlazada de `struct Env` libres.
+ static struct Env *env_free_list;  // Free environment list
+                                    // (linked by Env->env_link)
+ 
+@@ -54,6 +57,7 @@ struct Segdesc gdt[] = {
+ 	[GD_TSS0 >> 3] = SEG_NULL
+ };
+ 
++// Pseudodesc es un struct que tiene limite y base
+ struct Pseudodesc gdt_pd = { sizeof(gdt) - 1, (unsigned long) gdt };
+ 
+ //
+@@ -113,6 +117,13 @@ env_init(void)
+ {
+ 	// Set up envs array
+ 	// LAB 3: Your code here.
++	for (int i = NENV - 1; i >= 0; i--) {
++		envs[i].env_link = env_free_list;
++		// envs[i].env_id = 0; // Hecho por memset
++		// envs[i].env_status = ENV_FREE // Hecho por memset
++		env_free_list = &envs[i];
++	}
++
+ 
+ 	// Per-CPU part of the initialization
+ 	env_init_percpu();
+@@ -177,6 +188,26 @@ env_setup_vm(struct Env *e)
+ 
+ 	// LAB 3: Your code here.
+ 
++	// page alloc aloca la página pero me devuelve un puntero a
++	// PageInfo que es metadata asociada a una página física
++	// Con page2pa obtengo la dirección física del comienzo de la página
++	// y con KADDR obtengo la Kernel Virtual Address (pde_t *)
++	// Podemos usar page2kva porque el arreglo de pages fue mapeado
++	// en la kernel virtual address
++	e->env_pgdir = (pde_t *) page2kva(p);
++	// Page alloc no incrementa pp_ref, esto debe hacerlo el caller
++	// en la siguiente línea incrementamos pp_ref de PageInfo
++	p->pp_ref++;
++	// Ahora se debe copiar el Page Directory del kernel (kern_pgdir)
++	// por encima de UTOP en el Page Directory del nuevo environment
++	// Se podría copiar desde kern_pgdir[PDX(UTOP)] hasta kern_pgdir[1023]
++	// Pero dado que no se hizo ningún mapeo por debajo de UTOP en
++	// kern_pgdir, todos los PDE de kern_pgdir por debajo de este punto
++	// están en 0 Por lo tanto se puede usar kern_pgdir como template y
++	// copiarlo tal cual está entero
++	memcpy(e->env_pgdir, kern_pgdir, PGSIZE);
++
++
+ 	// UVPT maps the env's own page table read-only.
+ 	// Permissions: kernel R, user R
+ 	e->env_pgdir[PDX(UVPT)] = PADDR(e->env_pgdir) | PTE_P | PTE_U;
+@@ -264,6 +295,27 @@ region_alloc(struct Env *e, void *va, size_t len)
+ 	//   'va' and 'len' values that are not page-aligned.
+ 	//   You should round va down, and round (va + len) up.
+ 	//   (Watch out for corner-cases!)
++
++	// Como pide, se redondea va hacia abajo y va+len hacia arriba
++	// a múltiplos de PGSIZE
++	uintptr_t r_va = ROUNDDOWN((uintptr_t) va, PGSIZE);
++	uintptr_t r_va_plus_len = ROUNDUP((uintptr_t)(va + len), PGSIZE);
++
++	// Cálculo de la cantidad de páginas a alocar
++	size_t pages_to_create = (r_va_plus_len - r_va) / PGSIZE;
++
++	while (pages_to_create) {
++		struct PageInfo *p = page_alloc(
++		        0);  // Indica explicitamente que no se deben poner a cero las paginas.
++		if (p == NULL) {
++			panic("region_alloc: Can't allocate page.\n");
++		}
++
++		// El bit de presencia ya es colocado por page_insert
++		page_insert(e->env_pgdir, p, (void *) r_va, PTE_W | PTE_U);
++		pages_to_create--;
++		r_va += PGSIZE;
++	}
+ }
+ 
+ //
+@@ -321,10 +373,51 @@ load_icode(struct Env *e, uint8_t *binary)
+ 
+ 	// LAB 3: Your code here.
+ 
++	// binary es un puntero a un binario Elf
++	struct Elf *elf = (struct Elf *) binary;
++
++	// Recupero información útil del Elf
++	uint32_t program_headers_offset =
++	        elf->e_phoff;  // Offset de los program headers dentro del Elf
++	uint32_t program_headers_num = elf->e_phnum;  // Cantidad de segmentos...
++
++	// Cambiamos la page directory seteada en el CPU a la page directory del
++	// environment a configurar. Esto es para poder utilizar memset y
++	// memcopy
++	lcr3(PADDR(e->env_pgdir));
++	for (int i = 0; i < program_headers_num; i++) {
++		// Recuperamos el program header
++		struct Proghdr *program_header =
++		        (struct Proghdr *) (binary + program_headers_offset +
++		                            (i * sizeof(struct Proghdr)));
++		// Si no es de tipo "ELF_PROG_LOAD" se debe descartar
++		if (program_header->p_type != ELF_PROG_LOAD)
++			continue;
++		// Reservamos memsz bytes de memoria con region_alloc() en la dirección va del segmento
++		region_alloc(e,
++		             (void *) program_header->p_va,
++		             program_header->p_memsz);
++		// Copiamos filesz bytes desde binary + offset a va
++		memcpy((void *) program_header->p_va,
++		       binary + program_header->p_offset,
++		       program_header->p_filesz);
++		// Escribimos en 0 el resto de bytes, desde va+filesz hasta va+memsz
++		memset((void *) (program_header->p_va + program_header->p_filesz),
++		       0,
++		       program_header->p_memsz - program_header->p_filesz);
++	}
++	// Restauramos en el CPU la page directory del kernel
++	lcr3(PADDR(kern_pgdir));
++
++	// Se debe, además, configurar el entry point del proceso.
++	e->env_tf.tf_eip = elf->e_entry;
++
+ 	// Now map one page for the program's initial stack
+ 	// at virtual address USTACKTOP - PGSIZE.
+ 
+ 	// LAB 3: Your code here.
++
++	region_alloc(e, (void *) (USTACKTOP - PGSIZE), PGSIZE);
+ }
+ 
+ //
+@@ -338,6 +431,23 @@ void
+ env_create(uint8_t *binary, enum EnvType type)
+ {
+ 	// LAB 3: Your code here.
++	struct Env *new_env = NULL;
++	int errcode;
++	// Alocamos un nuevo env con env_alloc
++	errcode = env_alloc(&new_env, 0);
++	if (errcode < 0) {
++		panic("env_create failed in 'env_alloc' with error code: %e\n",
++		      errcode);
++	}
++
++	// Cargamos el biario en el env con load_icode
++	load_icode(new_env, binary);
++
++	// Seteamos el env_type
++	new_env->env_type = type;
++
++	// Seteamos el parent ID
++	new_env->env_parent_id = 0;
+ }
+ 
+ //
+@@ -455,5 +565,29 @@ env_run(struct Env *e)
+ 
+ 	// LAB 3: Your code here.
+ 
+-	panic("env_run not yet implemented");
++	if ((curenv != NULL) && (curenv->env_status == ENV_RUNNING)) {
++		// Seteamos el curenv (si no es null) en ENV_RUNNABLE si es que estaba en ENV_RUNNING
++		curenv->env_status = ENV_RUNNABLE;
++	}
++
++	// Seteamos curenv al nuevo environment
++	curenv = e;
++
++	// Seteamos el estado del nuevo curenv como ENV_RUNNING
++	curenv->env_status = ENV_RUNNING;
++
++	// Actualizamos el contador env_runs del curenv
++	curenv->env_runs++;
++
++	// Seteamos el address space del nuevo proceso
++	// No volvemos a setear el address space del kernel pues luego de que
++	// termine Esta función ya se terminó el context switch y estaremos
++	// ejecutando Un proceso de usuario!
++	lcr3(PADDR(e->env_pgdir));
++
++	// Usamos env_pop_tf() para restaurar los registros del environment y
++	// volver al modo usuario (salir del modo kernel)
++	env_pop_tf(&(e->env_tf));
++
++	// panic("env_run not yet implemented");
+ }
+diff --git a/kern/pmap.c b/kern/pmap.c
+index 15e62ea..2728182 100644
+--- a/kern/pmap.c
++++ b/kern/pmap.c
+@@ -110,14 +110,14 @@ boot_alloc(uint32_t n)
+ 	// Están mapeados menos de 4 MB
+ 	// por lo que no podemos pedir
+ 	// más memoria que eso
+-	if ((uintptr_t)ROUNDUP(nextfree + n, PGSIZE) > (KERNBASE + (4 << 20))) {
++	if ((uintptr_t) ROUNDUP(nextfree + n, PGSIZE) > (KERNBASE + (4 << 20))) {
+ 		panic("boot_alloc: out of memory");
+ 	}
+ 
+ 	result = nextfree;
+ 
+ 	if (n > 0) {
+-		nextfree = ROUNDUP(nextfree + n, PGSIZE);	
++		nextfree = ROUNDUP(nextfree + n, PGSIZE);
+ 	}
+ 
+ 	return result;
+@@ -167,10 +167,12 @@ mem_init(void)
+ 
+ 	pages = (struct PageInfo *) boot_alloc(npages * sizeof(struct PageInfo));
+ 	memset(pages, 0, npages * sizeof(struct PageInfo));
+-		
++
+ 	//////////////////////////////////////////////////////////////////////
+ 	// Make 'envs' point to an array of size 'NENV' of 'struct Env'.
+ 	// LAB 3: Your code here.
++	envs = (struct Env *) boot_alloc(NENV * sizeof(struct Env));
++	memset(envs, 0, NENV * sizeof(struct Env));
+ 
+ 	//////////////////////////////////////////////////////////////////////
+ 	// Now that we've allocated the initial kernel data structures, we set
+@@ -187,7 +189,7 @@ mem_init(void)
+ 	// panic("mem_init: This function is not finished\n");
+ 
+ 	check_page();
+-	
++
+ 
+ 	//////////////////////////////////////////////////////////////////////
+ 	// Now we set up virtual memory
+@@ -203,9 +205,13 @@ mem_init(void)
+ 	// Mapeo en kern_pgdir, UVPT - UPAGES direcciones virtuales a partir de UPAGES
+ 	// a direcciones físicas a partir de donde comienza el struct page info pages.
+ 
+-	//page_insert    (pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
+-	//boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
+-	boot_map_region(kern_pgdir, UPAGES, ROUNDUP(npages * sizeof(struct PageInfo), PGSIZE), PADDR(pages), PTE_U | PTE_P);
++	// page_insert    (pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
++	// boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
++	boot_map_region(kern_pgdir,
++	                UPAGES,
++	                ROUNDUP(npages * sizeof(struct PageInfo), PGSIZE),
++	                PADDR(pages),
++	                PTE_U | PTE_P);
+ 
+ 	//////////////////////////////////////////////////////////////////////
+ 	// Map the 'envs' array read-only by the user at linear address UENVS
+@@ -214,6 +220,11 @@ mem_init(void)
+ 	//    - the new image at UENVS  -- kernel R, user R
+ 	//    - envs itself -- kernel RW, user NONE
+ 	// LAB 3: Your code here.
++	boot_map_region(kern_pgdir,
++	                UENVS,
++	                ROUNDUP(NENV * sizeof(struct Env), PGSIZE),
++	                PADDR(envs),
++	                PTE_U | PTE_P);
+ 
+ 	//////////////////////////////////////////////////////////////////////
+ 	// Use the physical memory that 'bootstack' refers to as the kernel
+@@ -226,7 +237,11 @@ mem_init(void)
+ 	//       overwrite memory.  Known as a "guard page".
+ 	//     Permissions: kernel RW, user NONE
+ 	// Your code goes here:
+-    boot_map_region(kern_pgdir, KSTACKTOP - KSTKSIZE, KSTKSIZE, PADDR(bootstack), PTE_W | PTE_P);
++	boot_map_region(kern_pgdir,
++	                KSTACKTOP - KSTKSIZE,
++	                KSTKSIZE,
++	                PADDR(bootstack),
++	                PTE_W | PTE_P);
+ 
+ 	//////////////////////////////////////////////////////////////////////
+ 	// Map all of physical memory at KERNBASE.
+@@ -236,7 +251,8 @@ mem_init(void)
+ 	// we just set up the mapping anyway.
+ 	// Permissions: kernel RW, user NONE
+ 	// Your code goes here:
+- 	boot_map_region(kern_pgdir, KERNBASE, 0xffffffff - KERNBASE + 1, 0, PTE_W | PTE_P);
++	boot_map_region(
++	        kern_pgdir, KERNBASE, 0xffffffff - KERNBASE + 1, 0, PTE_W | PTE_P);
+ 
+ 	// Check that the initial page directory has been set up correctly.
+ 	check_kern_pgdir();
+@@ -279,29 +295,29 @@ void
+ page_init(void)
+ {
+ 	// Hay paginas prohibidas y paginas libres.
+-	// Las páginas prohibidas son todas las que ya estan ocupadas hasta este punto.
+-	// Mas las que se indiquen en los comentarios en inglés de abajo.
++	// Las páginas prohibidas son todas las que ya estan ocupadas hasta este
++	// punto. Mas las que se indiquen en los comentarios en inglés de abajo.
+ 	// Las paginas prohibidas se ponen en 0 y en NULL
+ 	// En 0 porque si se intentan liberar tirará kernel panic
+ 	// Y en null porque no forman parte de la lista enlazada
+ 	// Entonces hay que enlazar todas las páginas menos las prohibidas
+ 	// Poniendolas en 0 (pues son libres) y enalzando los punteros
+ 	// Las ocupadas que habrá en el futuro si van a tener su valor en 1
+-	// Pero su puntero estará en NULL pues no formaran mas parte de la lista libre
+-	// Hasta que sean liberadas.
++	// Pero su puntero estará en NULL pues no formaran mas parte de la lista
++	// libre Hasta que sean liberadas.
+ 
+ 	// Rocomienda dato: Que el for que viene ya hecho, poner if (condicion) continue;
+ 	// y luego las lineas originales de la funcion. Esa condicion es la que me dice
+ 	// si es una página prohibida, osea if(prohibida)
+-	// Una manera muy facil es decir: 
++	// Una manera muy facil es decir:
+ 	/*
+-		physaddr_t addr = 0
+-		if (i = 1; i < npages; i++) { // i empieza en 1 para saltear la primera página
+-			if (addr >= boot_alloc(0) || addr < io_phys_mem) {
+-				entonces no es prohibida
+-			}
+-			addr += PGSIZE;
+-		}
++	        physaddr_t addr = 0
++	        if (i = 1; i < npages; i++) { // i empieza en 1 para saltear la primera página
++	                if (addr >= boot_alloc(0) || addr < io_phys_mem) {
++	                        entonces no es prohibida
++	                }
++	                addr += PGSIZE;
++	        }
+ 	*/
+ 	// The example code here marks all physical pages as free.
+ 	// However this is not truly the case.  What memory is free?
+@@ -317,7 +333,7 @@ page_init(void)
+ 	//     in physical memory?  Which pages are already in use for
+ 	//     page tables and other data structures?
+ 	// Aca empieza el kernel
+-	// Estan ocupadas todas las paginas 
++	// Estan ocupadas todas las paginas
+ 	// desde EXTPHYSMEM hasta boot_alloc(0)
+ 	//
+ 	// Change the code to reflect this.
+@@ -326,10 +342,11 @@ page_init(void)
+ 	physaddr_t paddr;
+ 	for (size_t i = 1; i < npages; i++) {
+ 		paddr = i * PGSIZE;
+-		if (paddr >= PADDR(boot_alloc(0)) || paddr < IOPHYSMEM) { // Si no es una dirección prohibida
++		if (paddr >= PADDR(boot_alloc(0)) ||
++		    paddr < IOPHYSMEM) {  // Si no es una dirección prohibida
+ 			// pages[i].pp_ref = 0; // Fue seteado con memset
+-		  pages[i].pp_link = page_free_list;
+-		  page_free_list = &pages[i];
++			pages[i].pp_link = page_free_list;
++			page_free_list = &pages[i];
+ 		}
+ 	}
+ }
+@@ -351,11 +368,11 @@ page_alloc(int alloc_flags)
+ {
+ 	// Fill this function in
+ 	if (page_free_list) {
+-		struct PageInfo * page = page_free_list;
+-	  page_free_list = page->pp_link;
+-	  page->pp_link = NULL;
++		struct PageInfo *page = page_free_list;
++		page_free_list = page->pp_link;
++		page->pp_link = NULL;
+ 
+-	  if (alloc_flags & ALLOC_ZERO) {
++		if (alloc_flags & ALLOC_ZERO) {
+ 			// Seteamos a cero la pagina fisica
+ 			// no el struct PageInfo
+ 			memset(page2kva(page), 0, PGSIZE);
+@@ -364,7 +381,7 @@ page_alloc(int alloc_flags)
+ 		return page;
+ 	}
+ 
+-	return NULL; // No free pages
++	return NULL;  // No free pages
+ }
+ 
+ //
+@@ -424,42 +441,43 @@ page_decref(struct PageInfo *pp)
+ //
+ 
+ /*
+-	Recibe siempre como parámetro un pde_t * que es un puntero a una tira de 1024 words de 4 bytes.
+-	pde_t * es accesible con corchetes [].
+-	Es una estructura que sirve de Page Directory. Cada entrada tiene 32 bits. Los 20 bits mas altos
+-	son una dirección física donde se ubica la Page Table en particular. Los 12 bits resntes son
+-	bits de presencia.
+-
+-	De la casilla saco la dirección física, la conveierto en virtual y con eso referencio la Page Table
+-	que quiero. 
+-
+-	Esta funcion es una funcion de soporte que permite llegar a la página que interesa.
+-	Hay que chequear si el bit de presencia esta a cero (en ese caso la entrada dell page
+-	directory no tendra nada). Si esta en cero y flag de create, hay que alocar un page table y asignarselo
+-	en esa posición con la dirección física de  la page table alocada y ponerle los bits que 
+-	corresponda. 
+-	Si aloca una pagina, hay que hacer pp_ref++ a cada 
+-
+-	Retorna un puntero (direccion virtual) a la page table
++        Recibe siempre como parámetro un pde_t * que es un puntero a una tira de
++   1024 words de 4 bytes. pde_t * es accesible con corchetes []. Es una
++   estructura que sirve de Page Directory. Cada entrada tiene 32 bits. Los 20
++   bits mas altos son una dirección física donde se ubica la Page Table en
++   particular. Los 12 bits resntes son bits de presencia.
++
++        De la casilla saco la dirección física, la conveierto en virtual y con
++   eso referencio la Page Table que quiero.
++
++        Esta funcion es una funcion de soporte que permite llegar a la página
++   que interesa. Hay que chequear si el bit de presencia esta a cero (en ese
++   caso la entrada dell page directory no tendra nada). Si esta en cero y flag
++   de create, hay que alocar un page table y asignarselo en esa posición con la
++   dirección física de  la page table alocada y ponerle los bits que
++        corresponda.
++        Si aloca una pagina, hay que hacer pp_ref++ a cada
++
++        Retorna un puntero (direccion virtual) a la page table
+ */
+ pte_t *
+ pgdir_walk(pde_t *pgdir, const void *va, int create)
+ {
+ 	// Obtengo la entrada en la PD sumando a pgdir el indice de la VA
+-	pde_t * pde = pgdir + PDX(va);
++	pde_t *pde = pgdir + PDX(va);
+ 
+ 	if ((*pde & PTE_P)) {
+ 		// Obtengo la direccion virtual del PT base register
+-		pte_t * ptbr = KADDR(PTE_ADDR(*pde));
++		pte_t *ptbr = KADDR(PTE_ADDR(*pde));
+ 
+ 		// Si ya existe retornamos el PTE correspondiente
+ 		return ptbr + PTX(va);
+ 	} else if (create) {
+ 		// Si la page table buscada no está presente y el flag de create esta activado
+-		struct PageInfo * new_pt_page = page_alloc(ALLOC_ZERO);
++		struct PageInfo *new_pt_page = page_alloc(ALLOC_ZERO);
+ 
+ 		if (!new_pt_page) {
+-			return NULL;	// Fallo el page alloc porque no había mas memoria
++			return NULL;  // Fallo el page alloc porque no había mas memoria
+ 		}
+ 
+ 		// Obtengo la direccion física de la entrada a la page table alocada
+@@ -472,15 +490,15 @@ pgdir_walk(pde_t *pgdir, const void *va, int create)
+ 		new_pt_page->pp_ref++;
+ 
+ 		// Obtengo la direccion virtual del PT base register
+-		pte_t * ptbr = KADDR(PTE_ADDR(*pde));
+-		
++		pte_t *ptbr = KADDR(PTE_ADDR(*pde));
++
+ 		// Devolvemos el puntero a PTE
+ 		return ptbr + PTX(va);
+ 	} else {
+-		// No está presente la page table 
++		// No está presente la page table
+ 		// buscada y el flag de create está desactivado
+-		return NULL; 
+-	}	
++		return NULL;
++	}
+ }
+ 
+ //
+@@ -500,23 +518,24 @@ pgdir_walk(pde_t *pgdir, const void *va, int create)
+ static void
+ boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
+ {
+-  #ifndef TP1_PSE
++#ifndef TP1_PSE
+ 	assert(va % PGSIZE == 0);
+ 	assert(pa % PGSIZE == 0);
+ 	assert(size % PGSIZE == 0);
+ 	assert(perm < (1 << PTXSHIFT));
+ 
+-	for (size_t i = 0; i < size/PGSIZE; i++, va+=PGSIZE, pa+=PGSIZE) {
+-		pte_t * pte = pgdir_walk(pgdir, (const void *) va, 1);
++	for (size_t i = 0; i < size / PGSIZE; i++, va += PGSIZE, pa += PGSIZE) {
++		pte_t *pte = pgdir_walk(pgdir, (const void *) va, 1);
+ 		*pte |= pa | perm | PTE_P;
+ 	}
+-	
+-  #else
++
++#else
+ 	if (va % PTSIZE == 0 && size % PTSIZE == 0 && pa % PTSIZE == 0) {
+ 		// Es una Large Page
+-		for (size_t i = 0; i < size/PTSIZE; i++, va += PTSIZE, pa += PTSIZE) {
++		for (size_t i = 0; i < size / PTSIZE;
++		     i++, va += PTSIZE, pa += PTSIZE) {
+ 			// Obtengo la PDE
+-			pde_t * pde = pgdir + PDX(va);
++			pde_t *pde = pgdir + PDX(va);
+ 			// Escribo la dirección física de la página larga en la PDE,
+ 			// seteando los flags perm, PTE_PS (large page) y PTE_P (present)
+ 			*pde = pa | perm | PTE_PS | PTE_P;
+@@ -528,13 +547,14 @@ boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm
+ 		assert(size % PGSIZE == 0);
+ 		assert(perm < (1 << PTXSHIFT));
+ 
+-		for (size_t i = 0; i < size/PGSIZE; i++, va+=PGSIZE, pa+=PGSIZE) {
+-			pte_t * pte = pgdir_walk(pgdir, (const void *) va, 1);
++		for (size_t i = 0; i < size / PGSIZE;
++		     i++, va += PGSIZE, pa += PGSIZE) {
++			pte_t *pte = pgdir_walk(pgdir, (const void *) va, 1);
+ 			*pte |= pa | perm | PTE_P;
+ 		}
+ 	}
+ 
+-  #endif
++#endif
+ }
+ 
+ //
+@@ -565,7 +585,7 @@ boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm
+ int
+ page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
+ {
+-	pte_t * pte = pgdir_walk(pgdir, va, 1);
++	pte_t *pte = pgdir_walk(pgdir, va, 1);
+ 
+ 	if (pte == NULL) {
+ 		// pgdir_walk pudo fallar por falta de memoria
+@@ -610,21 +630,21 @@ page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
+ //
+ 
+ /*
+-	Dada una dirección virtual nos da un PageInfo
+-	pgdir_walk(VA) = direccion virtual de la entrada a la página
+-	pte_t * p = pgdir_walk(va)
+-	phys f = PTE_ADR(*p)		// me da la dirección fisica 
+-	pa2page(f) -> Me retorna la página de la dirección física y retornamos esto
++        Dada una dirección virtual nos da un PageInfo
++        pgdir_walk(VA) = direccion virtual de la entrada a la página
++        pte_t * p = pgdir_walk(va)
++        phys f = PTE_ADR(*p)		// me da la dirección fisica
++        pa2page(f) -> Me retorna la página de la dirección física y retornamos esto
+ */
+ 
+ struct PageInfo *
+ page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
+ {
+-	pte_t * pte = pgdir_walk(pgdir, va, 0);
++	pte_t *pte = pgdir_walk(pgdir, va, 0);
+ 
+ 	if (pte == NULL || !(*pte & PTE_P)) {
+ 		// No hay pagina mapeada para va
+-		return NULL; 
++		return NULL;
+ 	}
+ 
+ 	if (pte_store) {
+@@ -653,18 +673,18 @@ page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
+ //
+ 
+ /*
+-	Recibe un VA y hace dos cosas:
+-	- decref(pagina) (es una función que ya esta implementada)
+-		decrementa el pageref y si queda en cero llama a free de la pagina automaticamente.
+-	- limpiar PTE (Pone la page table entry a cero)
++        Recibe un VA y hace dos cosas:
++        - decref(pagina) (es una función que ya esta implementada)
++                decrementa el pageref y si queda en cero llama a free de la pagina automaticamente.
++        - limpiar PTE (Pone la page table entry a cero)
+ */
+ void
+ page_remove(pde_t *pgdir, void *va)
+ {
+-	pte_t * pte;
++	pte_t *pte;
+ 
+ 	// Conseguimos el struct PageInfo asociado y guardamos su PTE
+-	struct PageInfo * page_to_remove = page_lookup(pgdir, va, &pte);
++	struct PageInfo *page_to_remove = page_lookup(pgdir, va, &pte);
+ 
+ 	// Decrementamos pp_ref y liberamos si es necesario
+ 	page_decref(page_to_remove);
+@@ -712,6 +732,39 @@ int
+ user_mem_check(struct Env *env, const void *va, size_t len, int perm)
+ {
+ 	// LAB 3: Your code here.
++	uintptr_t r_va = ROUNDDOWN((uintptr_t) va, PGSIZE);
++	uintptr_t r_va_plus_len = ROUNDUP((uintptr_t)(va + len), PGSIZE);
++
++	// Cálculo de la cantidad de paginas a checkear
++	size_t pages_to_check = (r_va_plus_len - r_va) / PGSIZE;
++
++	pte_t *pte;
++
++	while (pages_to_check) {
++		pte = pgdir_walk(env->env_pgdir, (void *) r_va, 0);
++		bool is_va_in_range = r_va < ULIM ? true : false;
++		bool valid_pde = (env->env_pgdir[PDX(r_va)] & (perm | PTE_P)) ==
++		                                 (perm | PTE_P)
++		                         ? true
++		                         : false;
++		bool valid_pte = ((*pte) & (perm | PTE_P)) == (perm | PTE_P)
++		                         ? true
++		                         : false;
++
++		if (is_va_in_range && valid_pde && valid_pte) {
++			pages_to_check--;
++			r_va += PGSIZE;
++		} else {  // Failed permissions
++			user_mem_check_addr = (uintptr_t) va;
++			if (user_mem_check_addr < r_va) {
++				// Por si fallamos en el primer checkeo
++				// tenemos el valor del ROUNDOWN y deberiamos
++				// devolver va en ese caso
++				user_mem_check_addr = r_va;
++			}
++			return -E_FAULT;
++		}
++	}
+ 
+ 	return 0;
+ }
+diff --git a/kern/syscall.c b/kern/syscall.c
+index 0ee6be0..5c51830 100644
+--- a/kern/syscall.c
++++ b/kern/syscall.c
+@@ -21,7 +21,7 @@ sys_cputs(const char *s, size_t len)
+ 	// Destroy the environment if not.
+ 
+ 	// LAB 3: Your code here.
+-
++	user_mem_assert(curenv, (const void *) s, len, PTE_U);
+ 	// Print the string supplied by the user.
+ 	cprintf("%.*s", len, s);
+ }
+@@ -69,10 +69,20 @@ syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4,
+ 	// Call the function corresponding to the 'syscallno' parameter.
+ 	// Return any appropriate return value.
+ 	// LAB 3: Your code here.
+-
+-	panic("syscall not implemented");
+-
+ 	switch (syscallno) {
++	case SYS_cputs: {
++		sys_cputs((const char *) a1, (size_t) a2);
++		return 0;
++	}
++	case SYS_cgetc: {
++		return (int32_t) sys_cgetc();
++	}
++	case SYS_getenvid: {
++		return (int32_t) sys_getenvid();
++	}
++	case SYS_env_destroy: {
++		return (int32_t) sys_env_destroy((envid_t) a1);
++	}
+ 	default:
+ 		return -E_INVAL;
+ 	}
+diff --git a/kern/trap.c b/kern/trap.c
+index 4e55d15..26f5bb9 100644
+--- a/kern/trap.c
++++ b/kern/trap.c
+@@ -23,6 +23,31 @@ static struct Trapframe *last_tf;
+ struct Gatedesc idt[256] = { { 0 } };
+ struct Pseudodesc idt_pd = { sizeof(idt) - 1, (uint32_t) idt };
+ 
++// Declaración de los prototipos de trap
++
++extern void trap_0();
++extern void trap_1();
++
++extern void trap_3();
++extern void trap_4();
++extern void trap_5();
++extern void trap_6();
++extern void trap_7();
++extern void trap_8();
++
++extern void trap_10();
++extern void trap_11();
++extern void trap_12();
++extern void trap_13();
++extern void trap_14();
++
++extern void trap_16();
++extern void trap_17();
++extern void trap_18();
++extern void trap_19();
++extern void trap_20();
++
++extern void trap_48();
+ 
+ static const char *
+ trapname(int trapno)
+@@ -65,6 +90,59 @@ trap_init(void)
+ 
+ 	// LAB 3: Your code here.
+ 
++	// Se debe configurar las interrupciones del vector IDT
++	// (Interruption Descriptor Table)
++	// Para eso utilizamos la macro SETGATE
++	// 1er parámetro: Gate. Ejemplo: idt[1]
++	// 2do parámetro: istrap?: En JOS va siempre 0 (para deshabilitar interrupciones
++	//                         dentro de la misma interrupción).
++	// 3er parámetro: selector de code segment para buscar el handler de la interrupción
++	//                En este caso será el text segment del kernel (macro GD_KT)
++	// 4to parámetro: offset dentro del code segment para buscar el handler
++	// 5to parámetro: Descriptor privilege level. En todo caso sera 0 (ring 0 para kernel)
++
++	// DIVIDE ERROR #DE
++	SETGATE(idt[T_DIVIDE], 0, GD_KT, trap_0, 0);
++	// DEBUG EXCEPTION
++	SETGATE(idt[T_DEBUG], 0, GD_KT, trap_1, 0);
++
++	// Breakpoint (En la tarea kern_interrupts se indica que debe
++	//				poder ser disparada por usuario RING 3)
++	SETGATE(idt[T_BRKPT], 0, GD_KT, trap_3, 3);
++	// Overflow
++	SETGATE(idt[T_OFLOW], 0, GD_KT, trap_4, 0);
++	// Bound Range Exceded
++	SETGATE(idt[T_BOUND], 0, GD_KT, trap_5, 0);
++	// Invalid Opcode
++	SETGATE(idt[T_ILLOP], 0, GD_KT, trap_6, 0);
++	// Device Not Available
++	SETGATE(idt[T_DEVICE], 0, GD_KT, trap_7, 0);
++	// Double Fault
++	SETGATE(idt[T_DBLFLT], 0, GD_KT, trap_8, 0);
++	// Invalid TSS
++	SETGATE(idt[T_TSS], 0, GD_KT, trap_10, 0);
++	// Segment Not Present
++	SETGATE(idt[T_SEGNP], 0, GD_KT, trap_11, 0);
++	// Stack-Segment Fault
++	SETGATE(idt[T_STACK], 0, GD_KT, trap_12, 0);
++	// General Protection
++	SETGATE(idt[T_GPFLT], 0, GD_KT, trap_13, 0);
++	// Page Fault
++	SETGATE(idt[T_PGFLT], 0, GD_KT, trap_14, 0);
++	// x87 FPU Floating-Point Error (Math Fault)
++	SETGATE(idt[T_FPERR], 0, GD_KT, trap_16, 0);
++	// Alignment Check
++	SETGATE(idt[T_ALIGN], 0, GD_KT, trap_17, 0);
++	// Machine ChecK
++	SETGATE(idt[T_MCHK], 0, GD_KT, trap_18, 0);
++	// SIMD Floating-Point Exception
++	SETGATE(idt[T_SIMDERR], 0, GD_KT, trap_19, 0);
++	// Virtualization Exception
++	SETGATE(idt[20], 0, GD_KT, trap_20, 0);
++
++	// SYSCALL interrupt
++	SETGATE(idt[48], 0, GD_KT, trap_48, 3);
++
+ 	// Per-CPU setup
+ 	trap_init_percpu();
+ }
+@@ -137,12 +215,51 @@ print_regs(struct PushRegs *regs)
+ 	cprintf("  eax  0x%08x\n", regs->reg_eax);
+ }
+ 
++
++/*
++trap_dispatch() va a tener un switch para cada excepcion posible:
++        switch (tf->tf_trapno) {
++                case t_syscall....
++        }
++
++En este switch vamos a tener manejadores para el T_BRKPT y para T_PGFLT
++(breakpoint y page fault), para el resto nose hará nada y se volverá al
++proceso original.
++
++Además, la excepción de breakpoint se debe poder lanzar desde programas de usuario.
++En general, esta excepción se usa para implementar el depurado de código.
++-> Para esto se debe modificar este gate en trap init.
++*/
+ static void
+ trap_dispatch(struct Trapframe *tf)
+ {
+ 	// Handle processor exceptions.
+ 	// LAB 3: Your code here.
+ 
++	switch (tf->tf_trapno) {
++	case T_BRKPT: {
++		monitor(tf);
++		return;
++	}
++	case T_PGFLT: {
++		page_fault_handler(tf);
++		return;
++	}
++	case T_SYSCALL: {
++		uint32_t ret = syscall(tf->tf_regs.reg_eax,  // Syscall number
++		                       tf->tf_regs.reg_edx,  // 1st argument
++		                       tf->tf_regs.reg_ecx,  // 2nd argument
++		                       tf->tf_regs.reg_ebx,  // 3rd argument
++		                       tf->tf_regs.reg_edi,  // 4th argument
++		                       tf->tf_regs.reg_esi   // 5th argument
++		);
++		tf->tf_regs.reg_eax = ret;  // Return value should be put in %eax
++		return;
++	}
++	default:
++		break;
++	}
++
+ 	// Unexpected trap: The user process or the kernel has a bug.
+ 	print_trapframe(tf);
+ 	if (tf->tf_cs == GD_KT)
+@@ -203,6 +320,12 @@ page_fault_handler(struct Trapframe *tf)
+ 	// Handle kernel-mode page faults.
+ 
+ 	// LAB 3: Your code here.
++	if (tf->tf_cs == GD_KT) {
++		panic("[%08x] kernel fault va %08x ip %08x\n",
++		      curenv->env_id,
++		      fault_va,
++		      tf->tf_eip);
++	}
+ 
+ 	// We've already handled kernel-mode exceptions, so if we get here,
+ 	// the page fault happened in user mode.
+diff --git a/kern/trapentry.S b/kern/trapentry.S
+index 22fc640..87bae65 100644
+--- a/kern/trapentry.S
++++ b/kern/trapentry.S
+@@ -47,9 +47,64 @@
+  * Lab 3: Your code here for generating entry points for the different traps.
+  */
+ 
++TRAPHANDLER_NOEC(trap_0, T_DIVIDE)
++TRAPHANDLER_NOEC(trap_1, T_DEBUG)
++
++TRAPHANDLER_NOEC(trap_3, T_BRKPT)
++TRAPHANDLER_NOEC(trap_4, T_OFLOW)
++TRAPHANDLER_NOEC(trap_5, T_BOUND)
++TRAPHANDLER_NOEC(trap_6, T_ILLOP)
++TRAPHANDLER_NOEC(trap_7, T_DEVICE)
++TRAPHANDLER(trap_8, T_DBLFLT)
++
++TRAPHANDLER(trap_10, T_TSS)
++TRAPHANDLER(trap_11, T_SEGNP)
++TRAPHANDLER(trap_12, T_STACK)
++TRAPHANDLER(trap_13, T_GPFLT)
++TRAPHANDLER(trap_14, T_PGFLT)
++
++TRAPHANDLER_NOEC(trap_16, T_PGFLT)
++TRAPHANDLER(trap_17, T_ALIGN)
++TRAPHANDLER_NOEC(trap_18, T_MCHK)
++TRAPHANDLER_NOEC(trap_19, T_SIMDERR)
++TRAPHANDLER_NOEC(trap_20, 20)
++TRAPHANDLER_NOEC(trap_48, T_SYSCALL)
+ 
+ 
+ /*
+  * Lab 3: Your code here for _alltraps
+  */
+ 
++_alltraps:
++	/* push values to make the stack look like a struct Trapframe */
++	/* Tener en cuenta que el CPU al recibir una interrupción con cambio de privilegios
++	   automáticamente hace un push al stack de SS, ESP, EFLAGS, CS, EIP y Error Code 
++	   En el TRAPHANDLER, antes de llamar a _alltraps, se hizo push de trapno
++	   Por lo tanto hay que pushear en este orden: ds, es y los registros de proposito general */
++	
++	pushl	%ds
++	pushl	%es
++	pushal		/* Lo contrario al popal de env_pop_tf */
++
++	/* load GD_KD into %ds and %es 
++	Ayuda: cargar GD_KD en %ds y %es mediante un registro intermedio de 16 bits 
++	(por ejemplo, %ax). Considerar, además, que GD_KD es una constante numérica, 
++	no una dirección de memoria (‘mov $GD_KD’ vs ‘mov GD_KD’).	
++	*/
++
++	mov $GD_KT, %ax
++	mov %ax, %ds
++	mov %ax, %es
++
++	/* pushl %esp to pass a pointer to the Trapframe as an argument to trap() */
++
++	pushl %esp
++
++	/* call trap */
++	call trap
++	
++
++	
++
++	
++
diff --git a/grade-lab4 b/grade-lab4
new file mode 100755
index 0000000..91e52b4
--- /dev/null
+++ b/grade-lab4
@@ -0,0 +1,240 @@
+#!/usr/bin/env python3
+
+import re
+from gradelib import *
+
+r = Runner(save("jos.out"),
+           stop_breakpoint("readline"))
+
+def E(s, trim=False):
+    """Expand $En in s to the environment ID of the n'th user
+    environment."""
+
+    tmpl = "%x" if trim else "%08x"
+    return re.sub(r"\$E([0-9]+)",
+                  lambda m: tmpl % (0x1000 + int(m.group(1))-1), s)
+
+@test(1)
+def test_helloinit():
+    r.user_test("hello")
+    r.match(E(".00000000. new env $E1"),
+            "hello, world",
+            E(".$E1. exiting gracefully"),
+            E(".$E1. free env $E1"))
+
+end_part("0")
+
+@test(1)
+def test_yield():
+    r.user_test("yield")
+    r.match(E(".00000000. new env $E1"),
+            E(".00000000. new env $E2"),
+            E("Hello, I am environment $E1"),
+            E("Hello, I am environment $E2"),
+            E("Back in environment $E1, iteration 1"),
+            E("Back in environment $E2, iteration 1"),
+            E("Back in environment $E1, iteration 4"),
+            E("Back in environment $E2, iteration 4"),
+            E(".$E1. exiting gracefully"),
+            E(".$E2. exiting gracefully"))
+
+@test(1)
+def test_spin0():
+    r.user_test("spin0", timeout=0.5)
+    r.match(E(".00000000. new env $E1"),
+            E(".00000000. new env $E2"),
+            E("I am $E1 and my spin will go on #1"),
+            E("I am $E1 and my spin will go on #99"),
+            E("I am $E2 and I like my interrupt #1"),
+            E("I am $E2 and I like my interrupt #4"))
+
+end_part("1")
+
+@test(1)
+def test_dumbfork():
+    r.user_test("dumbfork")
+    r.match(E(".00000000. new env $E1"),
+            E(".$E1. new env $E2"),
+            "0: I am the parent.",
+            "9: I am the parent.",
+            "0: I am the child.",
+            "9: I am the child.",
+            "19: I am the child.",
+            E(".$E1. exiting gracefully"),
+            E(".$E1. free env $E1"),
+            E(".$E2. exiting gracefully"),
+            E(".$E2. free env $E2"))
+
+@test(1)
+def test_forktree():
+    r.user_test("forktree")
+    r.match("....: I am .0.",
+            "....: I am .1.",
+            "....: I am .000.",
+            "....: I am .100.",
+            "....: I am .110.",
+            "....: I am .111.",
+            "....: I am .011.",
+            "....: I am .001.",
+            E(".$E1. exiting gracefully"),
+            E(".$E2. exiting gracefully"),
+            ".0000200.. exiting gracefully",
+            ".0000200.. free env 0000200.")
+
+@test(1)
+def test_spin():
+    r.user_test("spin")
+    r.match(E(".00000000. new env $E1"),
+            "I am the parent.  Forking the child...",
+            E(".$E1. new env $E2"),
+            "I am the parent.  Running the child...",
+            "I am the child.  Spinning...",
+            "I am the parent.  Killing the child...",
+            E(".$E1. destroying $E2"),
+            E(".$E1. free env $E2"),
+            E(".$E1. exiting gracefully"),
+            E(".$E1. free env $E1"))
+
+end_part("2")
+
+@test(1)
+def test_yield2():
+    r.user_test("yield", make_args=["CPUS=2"])
+    r.match(E(".00000000. new env $E1"),
+            E(".00000000. new env $E2"),
+            "Hello, I am environment 0000100., cpu 0",
+            "Hello, I am environment 0000100., cpu 1",
+            "Back in environment 0000100., iteration 4, cpu 0",
+            "Back in environment 0000100., iteration 4, cpu 1",
+            E(".$E1. exiting gracefully"),
+            E(".$E2. exiting gracefully"))
+
+@test(1)
+def test_stresssched():
+    r.user_test("stresssched", make_args=["CPUS=4"])
+    r.match(".000010... stresssched on CPU 0",
+            ".000010... stresssched on CPU 1",
+            ".000010... stresssched on CPU 2",
+            ".000010... stresssched on CPU 3",
+            no=[".*ran on two CPUs at once"])
+
+end_part("3")
+
+@test(1)
+def test_sendpage():
+    r.user_test("sendpage", make_args=["CPUS=2"])
+    r.match(".00000000. new env 00001000",
+            E(".00000000. new env $E1"),
+            E(".$E1. new env $E2"),
+            E("$E2 got message from $E1: hello child environment! how are you?", trim=True),
+            E("child received correct message", trim=True),
+            E("$E1 got message from $E2: hello parent environment! I'm good", trim=True),
+            E("parent received correct message", trim=True),
+            E(".$E1. exiting gracefully"),
+            E(".$E1. free env $E1"),
+            E(".$E2. exiting gracefully"),
+            E(".$E2. free env $E2"))
+
+@test(1)
+def test_pingpong():
+    r.user_test("pingpong", make_args=["CPUS=4"])
+    r.match(E(".00000000. new env $E1"),
+            E(".$E1. new env $E2"),
+            E("send 0 from $E1 to $E2", trim=True),
+            E("$E2 got 0 from $E1", trim=True),
+            E("$E1 got 1 from $E2", trim=True),
+            E("$E2 got 8 from $E1", trim=True),
+            E("$E1 got 9 from $E2", trim=True),
+            E("$E2 got 10 from $E1", trim=True),
+            E(".$E1. exiting gracefully"),
+            E(".$E1. free env $E1"),
+            E(".$E2. exiting gracefully"),
+            E(".$E2. free env $E2"))
+
+@test(1)
+def test_primes():
+    r.user_test("primes", stop_on_line("CPU .: 1877"), stop_on_line(".*panic"),
+                make_args=["CPUS=4"], timeout=60)
+    r.match(E(".00000000. new env $E1"),
+            E(".$E1. new env $E2"),
+            E("CPU .: 2 .$E2. new env $E3"),
+            E("CPU .: 3 .$E3. new env $E4"),
+            E("CPU .: 5 .$E4. new env $E5"),
+            E("CPU .: 7 .$E5. new env $E6"),
+            E("CPU .: 11 .$E6. new env $E7"),
+            E("CPU .: 1877 .$E289. new env $E290"))
+
+end_part("4")
+
+@test(1)
+def test_faultread():
+    r.user_test("faultread")
+    r.match(E(".$E1. user fault va 00000000 ip 008....."),
+            "TRAP frame at 0xf....... from CPU .",
+            "  trap 0x0000000e Page Fault",
+            "  err  0x00000004.*",
+            E(".$E1. free env $E1"),
+            no=["I read ........ from location 0."])
+
+@test(1)
+def test_faultwrite():
+    r.user_test("faultwrite")
+    r.match(E(".$E1. user fault va 00000000 ip 008....."),
+            "TRAP frame at 0xf....... from CPU .",
+            "  trap 0x0000000e Page Fault",
+            "  err  0x00000006.*",
+            E(".$E1. free env $E1"))
+
+@test(1)
+def test_faultdie():
+    r.user_test("faultdie")
+    r.match("i faulted at va deadbeef, err 6",
+            E(".$E1. exiting gracefully"),
+            E(".$E1. free env $E1"))
+
+@test(1)
+def test_faultregs():
+    r.user_test("faultregs")
+    r.match("Registers in UTrapframe OK",
+            "Registers after page-fault OK",
+            no=["Registers in UTrapframe MISMATCH",
+                "Registers after page-fault MISMATCH"])
+
+@test(1)
+def test_faultalloc():
+    r.user_test("faultalloc")
+    r.match("fault deadbeef",
+            "this string was faulted in at deadbeef",
+            "fault cafebffe",
+            "fault cafec000",
+            "this string was faulted in at cafebffe",
+            E(".$E1. exiting gracefully"),
+            E(".$E1. free env $E1"))
+
+@test(1)
+def test_faultallocbad():
+    r.user_test("faultallocbad")
+    r.match(E(".$E1. user_mem_check assertion failure for va deadbeef"),
+            E(".$E1. free env $E1"))
+
+@test(1)
+def test_faultnostack():
+    r.user_test("faultnostack")
+    r.match(E(".$E1. user_mem_check assertion failure for va eebff..."),
+            E(".$E1. free env $E1"))
+
+@test(1)
+def test_faultbadhandler():
+    r.user_test("faultbadhandler")
+    r.match(E(".$E1. user_mem_check assertion failure for va (deadb|eebfe)..."),
+            E(".$E1. free env $E1"))
+
+@test(1)
+def test_faultevilhandler():
+    r.user_test("faultevilhandler")
+    r.match(E(".$E1. user_mem_check assertion failure for va (f0100|eebfe)..."),
+            E(".$E1. free env $E1"))
+
+end_part("5")
+
+run_tests()
diff --git a/inc/env.h b/inc/env.h
index 503f7b9..cda5008 100644
--- a/inc/env.h
+++ b/inc/env.h
@@ -51,9 +51,20 @@ struct Env {
 	enum EnvType env_type;		// Indicates special system environments
 	unsigned env_status;		// Status of the environment
 	uint32_t env_runs;		// Number of times environment has run
+	int env_cpunum;			// The CPU that the env is running on
 
 	// Address space
 	pde_t *env_pgdir;		// Kernel virtual address of page dir
+
+	// Exception handling
+	void *env_pgfault_upcall;	// Page fault upcall entry point
+
+	// Lab 4 IPC
+	bool env_ipc_recving;		// Env is blocked receiving
+	void *env_ipc_dstva;		// VA at which to map received page
+	uint32_t env_ipc_value;		// Data value sent to us
+	envid_t env_ipc_from;		// envid of the sender
+	int env_ipc_perm;		// Perm of page mapping received
 };
 
 #endif // !JOS_INC_ENV_H
diff --git a/inc/error.h b/inc/error.h
index 1bd522c..51baef0 100644
--- a/inc/error.h
+++ b/inc/error.h
@@ -14,6 +14,9 @@ enum {
 				// the maximum allowed
 	E_FAULT		,	// Memory fault
 
+	E_IPC_NOT_RECV	,	// Attempt to send to env that is not recving
+	E_EOF		,	// Unexpected end of file
+
 	MAXERROR
 };
 
diff --git a/inc/lib.h b/inc/lib.h
index 611a57d..bff3fe1 100644
--- a/inc/lib.h
+++ b/inc/lib.h
@@ -16,6 +16,7 @@
 #include <inc/env.h>
 #include <inc/memlayout.h>
 #include <inc/syscall.h>
+#include <inc/trap.h>
 
 #define USED(x)		(void)(x)
 
@@ -31,6 +32,9 @@ extern const volatile struct PageInfo pages[];
 // exit.c
 void	exit(void);
 
+// pgfault.c
+void	set_pgfault_handler(void (*handler)(struct UTrapframe *utf));
+
 // readline.c
 char*	readline(const char *buf);
 
@@ -39,6 +43,37 @@ void	sys_cputs(const char *string, size_t len);
 int	sys_cgetc(void);
 envid_t	sys_getenvid(void);
 int	sys_env_destroy(envid_t);
+void	sys_yield(void);
+static envid_t sys_exofork(void);
+int	sys_env_set_status(envid_t env, int status);
+int	sys_env_set_pgfault_upcall(envid_t env, void *upcall);
+int	sys_page_alloc(envid_t env, void *pg, int perm);
+int	sys_page_map(envid_t src_env, void *src_pg,
+		     envid_t dst_env, void *dst_pg, int perm);
+int	sys_page_unmap(envid_t env, void *pg);
+int	sys_ipc_try_send(envid_t to_env, uint32_t value, void *pg, int perm);
+int	sys_ipc_recv(void *rcv_pg);
+
+// This must be inlined.  Exercise for reader: why?
+static inline envid_t __attribute__((always_inline))
+sys_exofork(void)
+{
+	envid_t ret;
+	asm volatile("int %2"
+		     : "=a" (ret)
+		     : "a" (SYS_exofork), "i" (T_SYSCALL));
+	return ret;
+}
+
+// ipc.c
+void	ipc_send(envid_t to_env, uint32_t value, void *pg, int perm);
+int32_t ipc_recv(envid_t *from_env_store, void *pg, int *perm_store);
+envid_t	ipc_find_env(enum EnvType type);
+
+// fork.c
+#define	PTE_SHARE	0x400
+envid_t	fork(void);
+envid_t	sfork(void);	// Challenge!
 
 
 
diff --git a/inc/memlayout.h b/inc/memlayout.h
index a537b15..9b4f3c4 100644
--- a/inc/memlayout.h
+++ b/inc/memlayout.h
@@ -138,6 +138,9 @@
 // The location of the user-level STABS data structure
 #define USTABDATA	(PTSIZE / 2)
 
+// Physical address of startup code for non-boot CPUs (APs)
+#define MPENTRY_PADDR	0x7000
+
 #ifndef __ASSEMBLER__
 
 typedef uint32_t pte_t;
diff --git a/inc/syscall.h b/inc/syscall.h
index fd8df06..71b3512 100644
--- a/inc/syscall.h
+++ b/inc/syscall.h
@@ -7,6 +7,15 @@ enum {
 	SYS_cgetc,
 	SYS_getenvid,
 	SYS_env_destroy,
+	SYS_page_alloc,
+	SYS_page_map,
+	SYS_page_unmap,
+	SYS_exofork,
+	SYS_env_set_status,
+	SYS_env_set_pgfault_upcall,
+	SYS_yield,
+	SYS_ipc_try_send,
+	SYS_ipc_recv,
 	NSYSCALLS
 };
 
diff --git a/inc/trap.h b/inc/trap.h
index c3437af..b36aae3 100644
--- a/inc/trap.h
+++ b/inc/trap.h
@@ -74,6 +74,17 @@ struct Trapframe {
 	uint16_t tf_padding4;
 } __attribute__((packed));
 
+struct UTrapframe {
+	/* information about the fault */
+	uint32_t utf_fault_va;	/* va for T_PGFLT, 0 otherwise */
+	uint32_t utf_err;
+	/* trap-time return state */
+	struct PushRegs utf_regs;
+	uintptr_t utf_eip;
+	uint32_t utf_eflags;
+	/* the trap-time stack to return to */
+	uintptr_t utf_esp;
+} __attribute__((packed));
 
 #endif /* !__ASSEMBLER__ */
 
diff --git a/jos.out b/jos.out
index a5fc801..f7558ae 100644
--- a/jos.out
+++ b/jos.out
@@ -1,11 +1,36 @@
-*** Now run 'make gdb'.
-***
++ ld obj/kern/kernel
++ mk obj/kern/kernel.img
 6828 decimal is 15254 octal!
 Physical memory: 131072K available, base = 640K, extended = 130432K
+check_page_free_list() succeeded!
 check_page_alloc() succeeded!
 check_page() succeeded!
 check_kern_pgdir() succeeded!
+check_page_free_list() succeeded!
 check_page_installed_pgdir() succeeded!
+SMP: CPU 0 found 1 CPU(s)
+enabled interrupts: 1 2
+[00000000] new env 00001000
+1000: I am ''
+[00001000] user panic in <unknown> at lib/fork.c:81: fork not implemented
 Welcome to the JOS kernel monitor!
 Type 'help' for a list of commands.
-qemu-system-i386: terminating on signal 15 from pid 13489 (make)
+TRAP frame at 0xf02b9000 from CPU 0
+  edi  0x00000000
+  esi  0x00800f56
+  ebp  0xeebfdf50
+  oesp 0xefffffdc
+  ebx  0xeebfdf64
+  edx  0xeebfde08
+  ecx  0x00000001
+  eax  0x00000001
+  es   0x----0023
+  ds   0x----0023
+  trap 0x00000003 Breakpoint
+  err  0x00000000
+  eip  0x00800ce2
+  cs   0x----001b
+  flag 0x00000286
+  esp  0xeebfdf48
+  ss   0x----0023
+qemu-system-i386: terminating on signal 15 from pid 723 (make)
diff --git a/kern/Makefrag b/kern/Makefrag
index b39cff2..904659a 100644
--- a/kern/Makefrag
+++ b/kern/Makefrag
@@ -32,6 +32,12 @@ KERN_SRCFILES :=	kern/entry.S \
 			lib/readline.c \
 			lib/string.c
 
+# Source files for LAB4
+KERN_SRCFILES +=	kern/mpentry.S \
+			kern/mpconfig.c \
+			kern/lapic.c \
+			kern/spinlock.c
+
 # Only build files if they exist.
 KERN_SRCFILES := $(wildcard $(KERN_SRCFILES))
 
@@ -51,6 +57,26 @@ KERN_BINFILES :=	user/hello \
 			user/faultwrite \
 			user/faultwritekernel
 
+# Binary files for LAB4
+KERN_BINFILES +=	user/idle \
+			user/yield \
+			user/dumbfork \
+			user/stresssched \
+			user/faultdie \
+			user/faultregs \
+			user/faultalloc \
+			user/faultallocbad \
+			user/faultnostack \
+			user/faultbadhandler \
+			user/faultevilhandler \
+			user/forktree \
+			user/sendpage \
+			user/spin \
+                        user/spin0 \
+			user/fairness \
+			user/pingpong \
+			user/pingpongs \
+			user/primes
 KERN_OBJFILES := $(patsubst %.c, $(OBJDIR)/%.o, $(KERN_SRCFILES))
 KERN_OBJFILES := $(patsubst %.S, $(OBJDIR)/%.o, $(KERN_OBJFILES))
 KERN_OBJFILES := $(patsubst $(OBJDIR)/lib/%, $(OBJDIR)/kern/%, $(KERN_OBJFILES))
diff --git a/kern/console.c b/kern/console.c
index 7d312a7..88869ea 100644
--- a/kern/console.c
+++ b/kern/console.c
@@ -7,6 +7,8 @@
 #include <inc/assert.h>
 
 #include <kern/console.h>
+#include <kern/trap.h>
+#include <kern/picirq.h>
 
 static void cons_intr(int (*proc)(void));
 static void cons_putc(int c);
@@ -373,6 +375,9 @@ kbd_intr(void)
 static void
 kbd_init(void)
 {
+	// Drain the kbd buffer so that QEMU generates interrupts.
+	kbd_intr();
+	irq_setmask_8259A(irq_mask_8259A & ~(1<<IRQ_KBD));
 }
 
 
diff --git a/kern/cpu.h b/kern/cpu.h
new file mode 100644
index 0000000..c3c58c5
--- /dev/null
+++ b/kern/cpu.h
@@ -0,0 +1,46 @@
+
+#ifndef JOS_INC_CPU_H
+#define JOS_INC_CPU_H
+
+#include <inc/types.h>
+#include <inc/memlayout.h>
+#include <inc/mmu.h>
+#include <inc/env.h>
+
+// Maximum number of CPUs
+#define NCPU  8
+
+// Values of status in struct Cpu
+enum {
+	CPU_UNUSED = 0,
+	CPU_STARTED,
+	CPU_HALTED,
+};
+
+// Per-CPU state
+struct CpuInfo {
+	uint8_t cpu_id;                 // Local APIC ID; index into cpus[] below
+	volatile unsigned cpu_status;   // The status of the CPU
+	struct Env *cpu_env;            // The currently-running environment.
+	struct Taskstate cpu_ts;        // Used by x86 to find stack for interrupt
+};
+
+// Initialized in mpconfig.c
+extern struct CpuInfo cpus[NCPU];
+extern int ncpu;                    // Total number of CPUs in the system
+extern struct CpuInfo *bootcpu;     // The boot-strap processor (BSP)
+extern physaddr_t lapicaddr;        // Physical MMIO address of the local APIC
+
+// Per-CPU kernel stacks
+extern unsigned char percpu_kstacks[NCPU][KSTKSIZE];
+
+int cpunum(void);
+#define thiscpu (&cpus[cpunum()])
+
+void mp_init(void);
+void lapic_init(void);
+void lapic_startap(uint8_t apicid, uint32_t addr);
+void lapic_eoi(void);
+void lapic_ipi(int vector);
+
+#endif
diff --git a/kern/env.c b/kern/env.c
index 163d7d4..3869190 100644
--- a/kern/env.c
+++ b/kern/env.c
@@ -11,9 +11,13 @@
 #include <kern/pmap.h>
 #include <kern/trap.h>
 #include <kern/monitor.h>
+#include <kern/sched.h>
+#include <kern/cpu.h>
+#include <kern/spinlock.h>
 
-struct Env *envs = NULL;           // All environments
-struct Env *curenv = NULL;         // The current env
+// Arreglo de procesos (variable global, de longitud NENV).
+struct Env *envs = NULL;  // All environments
+// Lista enlazada de `struct Env` libres.
 static struct Env *env_free_list;  // Free environment list
                                    // (linked by Env->env_link)
 
@@ -34,7 +38,7 @@ static struct Env *env_free_list;  // Free environment list
 // definition of gdt specifies the Descriptor Privilege Level (DPL)
 // of that descriptor: 0 for kernel and 3 for user.
 //
-struct Segdesc gdt[] = {
+struct Segdesc gdt[NCPU + 5] = {
 	// 0x0 - unused (always faults -- for trapping NULL far pointers)
 	SEG_NULL,
 
@@ -50,10 +54,12 @@ struct Segdesc gdt[] = {
 	// 0x20 - user data segment
 	[GD_UD >> 3] = SEG(STA_W, 0x0, 0xffffffff, 3),
 
-	// 0x28 - tss, initialized in trap_init_percpu()
+	// Per-CPU TSS descriptors (starting from GD_TSS0) are initialized
+	// in trap_init_percpu()
 	[GD_TSS0 >> 3] = SEG_NULL
 };
 
+// Pseudodesc es un struct que tiene limite y base
 struct Pseudodesc gdt_pd = { sizeof(gdt) - 1, (unsigned long) gdt };
 
 //
@@ -113,6 +119,13 @@ env_init(void)
 {
 	// Set up envs array
 	// LAB 3: Your code here.
+	for (int i = NENV - 1; i >= 0; i--) {
+		envs[i].env_link = env_free_list;
+		// envs[i].env_id = 0; // Hecho por memset
+		// envs[i].env_status = ENV_FREE // Hecho por memset
+		env_free_list = &envs[i];
+	}
+
 
 	// Per-CPU part of the initialization
 	env_init_percpu();
@@ -177,6 +190,26 @@ env_setup_vm(struct Env *e)
 
 	// LAB 3: Your code here.
 
+	// page alloc aloca la página pero me devuelve un puntero a
+	// PageInfo que es metadata asociada a una página física
+	// Con page2pa obtengo la dirección física del comienzo de la página
+	// y con KADDR obtengo la Kernel Virtual Address (pde_t *)
+	// Podemos usar page2kva porque el arreglo de pages fue mapeado
+	// en la kernel virtual address
+	e->env_pgdir = (pde_t *) page2kva(p);
+	// Page alloc no incrementa pp_ref, esto debe hacerlo el caller
+	// en la siguiente línea incrementamos pp_ref de PageInfo
+	p->pp_ref++;
+	// Ahora se debe copiar el Page Directory del kernel (kern_pgdir)
+	// por encima de UTOP en el Page Directory del nuevo environment
+	// Se podría copiar desde kern_pgdir[PDX(UTOP)] hasta kern_pgdir[1023]
+	// Pero dado que no se hizo ningún mapeo por debajo de UTOP en
+	// kern_pgdir, todos los PDE de kern_pgdir por debajo de este punto
+	// están en 0 Por lo tanto se puede usar kern_pgdir como template y
+	// copiarlo tal cual está entero
+	memcpy(e->env_pgdir, kern_pgdir, PGSIZE);
+
+
 	// UVPT maps the env's own page table read-only.
 	// Permissions: kernel R, user R
 	e->env_pgdir[PDX(UVPT)] = PADDR(e->env_pgdir) | PTE_P | PTE_U;
@@ -239,6 +272,16 @@ env_alloc(struct Env **newenv_store, envid_t parent_id)
 	e->env_tf.tf_cs = GD_UT | 3;
 	// You will set e->env_tf.tf_eip later.
 
+	// Enable interrupts while in user mode.
+	// LAB 4: Your code here.
+	e->env_tf.tf_eflags |= FL_IF;
+
+	// Clear the page fault handler until user installs one.
+	e->env_pgfault_upcall = 0;
+
+	// Also clear the IPC receiving flag.
+	e->env_ipc_recving = 0;
+
 	// commit the allocation
 	env_free_list = e->env_link;
 	*newenv_store = e;
@@ -264,6 +307,27 @@ region_alloc(struct Env *e, void *va, size_t len)
 	//   'va' and 'len' values that are not page-aligned.
 	//   You should round va down, and round (va + len) up.
 	//   (Watch out for corner-cases!)
+
+	// Como pide, se redondea va hacia abajo y va+len hacia arriba
+	// a múltiplos de PGSIZE
+	uintptr_t r_va = ROUNDDOWN((uintptr_t) va, PGSIZE);
+	uintptr_t r_va_plus_len = ROUNDUP((uintptr_t)(va + len), PGSIZE);
+
+	// Cálculo de la cantidad de páginas a alocar
+	size_t pages_to_create = (r_va_plus_len - r_va) / PGSIZE;
+
+	while (pages_to_create) {
+		struct PageInfo *p = page_alloc(
+		        0);  // Indica explicitamente que no se deben poner a cero las paginas.
+		if (p == NULL) {
+			panic("region_alloc: Can't allocate page.\n");
+		}
+
+		// El bit de presencia ya es colocado por page_insert
+		page_insert(e->env_pgdir, p, (void *) r_va, PTE_W | PTE_U);
+		pages_to_create--;
+		r_va += PGSIZE;
+	}
 }
 
 //
@@ -293,7 +357,7 @@ load_icode(struct Env *e, uint8_t *binary)
 {
 	// Hints:
 	//  Load each program segment into virtual memory
-	//  at the address specified in the ELF section header.
+	//  at the address specified in the ELF segment header.
 	//  You should only load segments with ph->p_type == ELF_PROG_LOAD.
 	//  Each segment's virtual address can be found in ph->p_va
 	//  and its size in memory can be found in ph->p_memsz.
@@ -321,10 +385,51 @@ load_icode(struct Env *e, uint8_t *binary)
 
 	// LAB 3: Your code here.
 
+	// binary es un puntero a un binario Elf
+	struct Elf *elf = (struct Elf *) binary;
+
+	// Recupero información útil del Elf
+	uint32_t program_headers_offset =
+	        elf->e_phoff;  // Offset de los program headers dentro del Elf
+	uint32_t program_headers_num = elf->e_phnum;  // Cantidad de segmentos...
+
+	// Cambiamos la page directory seteada en el CPU a la page directory del
+	// environment a configurar. Esto es para poder utilizar memset y
+	// memcopy
+	lcr3(PADDR(e->env_pgdir));
+	for (int i = 0; i < program_headers_num; i++) {
+		// Recuperamos el program header
+		struct Proghdr *program_header =
+		        (struct Proghdr *) (binary + program_headers_offset +
+		                            (i * sizeof(struct Proghdr)));
+		// Si no es de tipo "ELF_PROG_LOAD" se debe descartar
+		if (program_header->p_type != ELF_PROG_LOAD)
+			continue;
+		// Reservamos memsz bytes de memoria con region_alloc() en la dirección va del segmento
+		region_alloc(e,
+		             (void *) program_header->p_va,
+		             program_header->p_memsz);
+		// Copiamos filesz bytes desde binary + offset a va
+		memcpy((void *) program_header->p_va,
+		       binary + program_header->p_offset,
+		       program_header->p_filesz);
+		// Escribimos en 0 el resto de bytes, desde va+filesz hasta va+memsz
+		memset((void *) (program_header->p_va + program_header->p_filesz),
+		       0,
+		       program_header->p_memsz - program_header->p_filesz);
+	}
+	// Restauramos en el CPU la page directory del kernel
+	lcr3(PADDR(kern_pgdir));
+
+	// Se debe, además, configurar el entry point del proceso.
+	e->env_tf.tf_eip = elf->e_entry;
+
 	// Now map one page for the program's initial stack
 	// at virtual address USTACKTOP - PGSIZE.
 
 	// LAB 3: Your code here.
+
+	region_alloc(e, (void *) (USTACKTOP - PGSIZE), PGSIZE);
 }
 
 //
@@ -338,6 +443,23 @@ void
 env_create(uint8_t *binary, enum EnvType type)
 {
 	// LAB 3: Your code here.
+	struct Env *new_env = NULL;
+	int errcode;
+	// Alocamos un nuevo env con env_alloc
+	errcode = env_alloc(&new_env, 0);
+	if (errcode < 0) {
+		panic("env_create failed in 'env_alloc' with error code: %e\n",
+		      errcode);
+	}
+
+	// Cargamos el biario en el env con load_icode
+	load_icode(new_env, binary);
+
+	// Seteamos el env_type
+	new_env->env_type = type;
+
+	// Seteamos el parent ID
+	new_env->env_parent_id = 0;
 }
 
 //
@@ -394,15 +516,26 @@ env_free(struct Env *e)
 
 //
 // Frees environment e.
+// If e was the current env, then runs a new environment (and does not return
+// to the caller).
 //
 void
 env_destroy(struct Env *e)
 {
+	// If e is currently running on other CPUs, we change its state to
+	// ENV_DYING. A zombie environment will be freed the next time
+	// it traps to the kernel.
+	if (e->env_status == ENV_RUNNING && curenv != e) {
+		e->env_status = ENV_DYING;
+		return;
+	}
+
 	env_free(e);
 
-	cprintf("Destroyed the only environment - nothing more to do!\n");
-	while (1)
-		monitor(NULL);
+	if (curenv == e) {
+		curenv = NULL;
+		sched_yield();
+	}
 }
 
 
@@ -415,6 +548,9 @@ env_destroy(struct Env *e)
 void
 env_pop_tf(struct Trapframe *tf)
 {
+	// Record the CPU we are running on for user-space debugging
+	curenv->env_cpunum = cpunum();
+
 	asm volatile("\tmovl %0,%%esp\n"
 	             "\tpopal\n"
 	             "\tpopl %%es\n"
@@ -455,5 +591,32 @@ env_run(struct Env *e)
 
 	// LAB 3: Your code here.
 
-	panic("env_run not yet implemented");
+	if ((curenv != NULL) && (curenv->env_status == ENV_RUNNING)) {
+		// Seteamos el curenv (si no es null) en ENV_RUNNABLE si es que estaba en ENV_RUNNING
+		curenv->env_status = ENV_RUNNABLE;
+	}
+
+	// Seteamos curenv al nuevo environment
+	curenv = e;
+
+	// Seteamos el estado del nuevo curenv como ENV_RUNNING
+	curenv->env_status = ENV_RUNNING;
+
+	// Actualizamos el contador env_runs del curenv
+	curenv->env_runs++;
+
+	// Seteamos el address space del nuevo proceso
+	// No volvemos a setear el address space del kernel pues luego de que
+	// termine Esta función ya se terminó el context switch y estaremos
+	// ejecutando Un proceso de usuario!
+	lcr3(PADDR(e->env_pgdir));
+
+	// Con env_pop_tf pasamos instantaneamente al modo usuario, antes hacemos unlock del kernel
+	unlock_kernel();
+
+	// Usamos env_pop_tf() para restaurar los registros del environment y
+	// volver al modo usuario (salir del modo kernel)
+	env_pop_tf(&(e->env_tf));
+
+	// panic("env_run not yet implemented");
 }
diff --git a/kern/env.h b/kern/env.h
index 9c574c1..286ece7 100644
--- a/kern/env.h
+++ b/kern/env.h
@@ -4,9 +4,10 @@
 #define JOS_KERN_ENV_H
 
 #include <inc/env.h>
+#include <kern/cpu.h>
 
 extern struct Env *envs;		// All environments
-extern struct Env *curenv;		// Current environment
+#define curenv (thiscpu->cpu_env)		// Current environment
 extern struct Segdesc gdt[];
 
 void	env_init(void);
diff --git a/kern/init.c b/kern/init.c
index 1f48649..f1cad9a 100644
--- a/kern/init.c
+++ b/kern/init.c
@@ -10,6 +10,12 @@
 #include <kern/kclock.h>
 #include <kern/env.h>
 #include <kern/trap.h>
+#include <kern/sched.h>
+#include <kern/picirq.h>
+#include <kern/cpu.h>
+#include <kern/spinlock.h>
+
+static void boot_aps(void);
 
 
 void
@@ -35,18 +41,97 @@ i386_init(void)
 	env_init();
 	trap_init();
 
+	// Lab 4 multiprocessor initialization functions
+	mp_init();
+	lapic_init();
+
+	// Lab 4 multitasking initialization functions
+	pic_init();
+
+	// Acquire the big kernel lock before waking up APs
+	// Your code here:
+	lock_kernel();
+	// Starting non-boot CPUs
+	boot_aps();
+
 #if defined(TEST)
 	// Don't touch -- used by grading script!
 	ENV_CREATE(TEST, ENV_TYPE_USER);
+
+	// Hack horrible mal para la corrección de la parte 1.
+	// -d
+	#define STRING(x) STRNG_(x)
+	#define STRNG_(x) #x
+	#define TESTED(x) (__builtin_strcmp(#x, STRING(TEST)) == 0)
+
+	if (TESTED(user_yield) || TESTED(user_spin0))
+		ENV_CREATE(TEST, ENV_TYPE_USER);
 #else
 	// Touch all you want.
-	ENV_CREATE(user_hello, ENV_TYPE_USER);
+	ENV_CREATE(user_yield, ENV_TYPE_USER);
+	ENV_CREATE(user_yield, ENV_TYPE_USER);
+	ENV_CREATE(user_yield, ENV_TYPE_USER);
 #endif // TEST*
 
-	// We only have one user environment for now, so just run it.
-	env_run(&envs[0]);
+	// Schedule and run the first user environment!
+	sched_yield();
 }
 
+// While boot_aps is booting a given CPU, it communicates the per-core
+// stack pointer that should be loaded by mpentry.S to that CPU in
+// this variable.
+void *mpentry_kstack;
+
+// Start the non-boot (AP) processors.
+static void
+boot_aps(void)
+{
+	extern unsigned char mpentry_start[], mpentry_end[];
+	void *code;
+	struct CpuInfo *c;
+
+	// Write entry code to unused memory at MPENTRY_PADDR
+	code = KADDR(MPENTRY_PADDR);
+	memmove(code, mpentry_start, mpentry_end - mpentry_start);
+
+	// Boot each AP one at a time
+	for (c = cpus; c < cpus + ncpu; c++) {
+		if (c == cpus + cpunum())  // We've started already.
+			continue;
+
+		// Tell mpentry.S what stack to use 
+		mpentry_kstack = percpu_kstacks[c - cpus] + KSTKSIZE;
+		// Start the CPU at mpentry_start
+		lapic_startap(c->cpu_id, PADDR(code));
+		// Wait for the CPU to finish some basic setup in mp_main()
+		while(c->cpu_status != CPU_STARTED)
+			;
+	}
+}
+
+// Setup code for APs
+void
+mp_main(void)
+{
+	// We are in high EIP now, safe to switch to kern_pgdir 
+	lcr3(PADDR(kern_pgdir));
+	cprintf("SMP: CPU %d starting\n", cpunum());
+
+	lapic_init();
+	env_init_percpu();
+	trap_init_percpu();
+	xchg(&thiscpu->cpu_status, CPU_STARTED); // tell boot_aps() we're up
+
+	// Now that we have finished some basic setup, call sched_yield()
+	// to start running processes on this CPU.  But make sure that
+	// only one CPU can enter the scheduler at a time!
+	//
+	// Your code here:
+	lock_kernel();
+	sched_yield();
+	// Remove this after you finish Exercise 4
+	// for (;;);
+}
 
 /*
  * Variable panicstr contains argument to first call to panic; used as flag
@@ -71,7 +156,7 @@ _panic(const char *file, int line, const char *fmt,...)
 	asm volatile("cli; cld");
 
 	va_start(ap, fmt);
-	cprintf(">>>\n>>> kernel panic at %s:%d: ", file, line);
+	cprintf(">>>\n>>> kernel panic on CPU %d at %s:%d: ", cpunum(), file, line);
 	vcprintf(fmt, ap);
 	cprintf("\n>>>\n");
 	va_end(ap);
diff --git a/kern/kdebug.c b/kern/kdebug.c
index 4a2df81..5eee110 100644
--- a/kern/kdebug.c
+++ b/kern/kdebug.c
@@ -146,6 +146,8 @@ debuginfo_eip(uintptr_t addr, struct Eipdebuginfo *info)
 		// Make sure this memory is valid.
 		// Return -1 if it is not.  Hint: Call user_mem_check.
 		// LAB 3: Your code here.
+		if (user_mem_check(curenv, usd, sizeof(struct UserStabData), 0))
+			return -1;
 
 		stabs = usd->stabs;
 		stab_end = usd->stab_end;
@@ -154,6 +156,9 @@ debuginfo_eip(uintptr_t addr, struct Eipdebuginfo *info)
 
 		// Make sure the STABS and string table memory is valid.
 		// LAB 3: Your code here.
+		if (user_mem_check(curenv, stabs, stab_end - stabs, 0) ||
+		    user_mem_check(curenv, stabstr, stabstr_end - stabstr, 0))
+			return -1;
 	}
 
 	// String table validity checks
diff --git a/kern/lapic.c b/kern/lapic.c
new file mode 100644
index 0000000..dc05777
--- /dev/null
+++ b/kern/lapic.c
@@ -0,0 +1,182 @@
+// The local APIC manages internal (non-I/O) interrupts.
+// See Chapter 8 & Appendix C of Intel processor manual volume 3.
+
+#include <inc/types.h>
+#include <inc/memlayout.h>
+#include <inc/trap.h>
+#include <inc/mmu.h>
+#include <inc/stdio.h>
+#include <inc/x86.h>
+#include <kern/pmap.h>
+#include <kern/cpu.h>
+
+// Local APIC registers, divided by 4 for use as uint32_t[] indices.
+#define ID      (0x0020/4)   // ID
+#define VER     (0x0030/4)   // Version
+#define TPR     (0x0080/4)   // Task Priority
+#define EOI     (0x00B0/4)   // EOI
+#define SVR     (0x00F0/4)   // Spurious Interrupt Vector
+	#define ENABLE     0x00000100   // Unit Enable
+#define ESR     (0x0280/4)   // Error Status
+#define ICRLO   (0x0300/4)   // Interrupt Command
+	#define INIT       0x00000500   // INIT/RESET
+	#define STARTUP    0x00000600   // Startup IPI
+	#define DELIVS     0x00001000   // Delivery status
+	#define ASSERT     0x00004000   // Assert interrupt (vs deassert)
+	#define DEASSERT   0x00000000
+	#define LEVEL      0x00008000   // Level triggered
+	#define BCAST      0x00080000   // Send to all APICs, including self.
+	#define OTHERS     0x000C0000   // Send to all APICs, excluding self.
+	#define BUSY       0x00001000
+	#define FIXED      0x00000000
+#define ICRHI   (0x0310/4)   // Interrupt Command [63:32]
+#define TIMER   (0x0320/4)   // Local Vector Table 0 (TIMER)
+	#define X1         0x0000000B   // divide counts by 1
+	#define PERIODIC   0x00020000   // Periodic
+#define PCINT   (0x0340/4)   // Performance Counter LVT
+#define LINT0   (0x0350/4)   // Local Vector Table 1 (LINT0)
+#define LINT1   (0x0360/4)   // Local Vector Table 2 (LINT1)
+#define ERROR   (0x0370/4)   // Local Vector Table 3 (ERROR)
+	#define MASKED     0x00010000   // Interrupt masked
+#define TICR    (0x0380/4)   // Timer Initial Count
+#define TCCR    (0x0390/4)   // Timer Current Count
+#define TDCR    (0x03E0/4)   // Timer Divide Configuration
+
+physaddr_t lapicaddr;        // Initialized in mpconfig.c
+volatile uint32_t *lapic;
+
+static void
+lapicw(int index, int value)
+{
+	lapic[index] = value;
+	lapic[ID];  // wait for write to finish, by reading
+}
+
+void
+lapic_init(void)
+{
+	if (!lapicaddr)
+		return;
+
+	// lapicaddr is the physical address of the LAPIC's 4K MMIO
+	// region.  Map it in to virtual memory so we can access it.
+	lapic = mmio_map_region(lapicaddr, 4096);
+
+	// Enable local APIC; set spurious interrupt vector.
+	lapicw(SVR, ENABLE | (IRQ_OFFSET + IRQ_SPURIOUS));
+
+	// The timer repeatedly counts down at bus frequency
+	// from lapic[TICR] and then issues an interrupt.  
+	// If we cared more about precise timekeeping,
+	// TICR would be calibrated using an external time source.
+	lapicw(TDCR, X1);
+	lapicw(TIMER, PERIODIC | (IRQ_OFFSET + IRQ_TIMER));
+	lapicw(TICR, 10000000); 
+
+	// Leave LINT0 of the BSP enabled so that it can get
+	// interrupts from the 8259A chip.
+	//
+	// According to Intel MP Specification, the BIOS should initialize
+	// BSP's local APIC in Virtual Wire Mode, in which 8259A's
+	// INTR is virtually connected to BSP's LINTIN0. In this mode,
+	// we do not need to program the IOAPIC.
+	if (thiscpu != bootcpu)
+		lapicw(LINT0, MASKED);
+
+	// Disable NMI (LINT1) on all CPUs
+	lapicw(LINT1, MASKED);
+
+	// Disable performance counter overflow interrupts
+	// on machines that provide that interrupt entry.
+	if (((lapic[VER]>>16) & 0xFF) >= 4)
+		lapicw(PCINT, MASKED);
+
+	// Map error interrupt to IRQ_ERROR.
+	lapicw(ERROR, IRQ_OFFSET + IRQ_ERROR);
+
+	// Clear error status register (requires back-to-back writes).
+	lapicw(ESR, 0);
+	lapicw(ESR, 0);
+
+	// Ack any outstanding interrupts.
+	lapicw(EOI, 0);
+
+	// Send an Init Level De-Assert to synchronize arbitration ID's.
+	lapicw(ICRHI, 0);
+	lapicw(ICRLO, BCAST | INIT | LEVEL);
+	while(lapic[ICRLO] & DELIVS)
+		;
+
+	// Enable interrupts on the APIC (but not on the processor).
+	lapicw(TPR, 0);
+}
+
+int
+cpunum(void)
+{
+	if (lapic)
+		return lapic[ID] >> 24;
+	return 0;
+}
+
+// Acknowledge interrupt.
+void
+lapic_eoi(void)
+{
+	if (lapic)
+		lapicw(EOI, 0);
+}
+
+// Spin for a given number of microseconds.
+// On real hardware would want to tune this dynamically.
+static void
+microdelay(int us)
+{
+}
+
+#define IO_RTC  0x70
+
+// Start additional processor running entry code at addr.
+// See Appendix B of MultiProcessor Specification.
+void
+lapic_startap(uint8_t apicid, uint32_t addr)
+{
+	int i;
+	uint16_t *wrv;
+
+	// "The BSP must initialize CMOS shutdown code to 0AH
+	// and the warm reset vector (DWORD based at 40:67) to point at
+	// the AP startup code prior to the [universal startup algorithm]."
+	outb(IO_RTC, 0xF);  // offset 0xF is shutdown code
+	outb(IO_RTC+1, 0x0A);
+	wrv = (uint16_t *)KADDR((0x40 << 4 | 0x67));  // Warm reset vector
+	wrv[0] = 0;
+	wrv[1] = addr >> 4;
+
+	// "Universal startup algorithm."
+	// Send INIT (level-triggered) interrupt to reset other CPU.
+	lapicw(ICRHI, apicid << 24);
+	lapicw(ICRLO, INIT | LEVEL | ASSERT);
+	microdelay(200);
+	lapicw(ICRLO, INIT | LEVEL);
+	microdelay(100);    // should be 10ms, but too slow in Bochs!
+
+	// Send startup IPI (twice!) to enter code.
+	// Regular hardware is supposed to only accept a STARTUP
+	// when it is in the halted state due to an INIT.  So the second
+	// should be ignored, but it is part of the official Intel algorithm.
+	// Bochs complains about the second one.  Too bad for Bochs.
+	for (i = 0; i < 2; i++) {
+		lapicw(ICRHI, apicid << 24);
+		lapicw(ICRLO, STARTUP | (addr >> 12));
+		microdelay(200);
+	}
+}
+
+void
+lapic_ipi(int vector)
+{
+	lapicw(ICRLO, OTHERS | FIXED | vector);
+	while (lapic[ICRLO] & DELIVS)
+		;
+}
diff --git a/kern/mpconfig.c b/kern/mpconfig.c
new file mode 100644
index 0000000..dbca4fd
--- /dev/null
+++ b/kern/mpconfig.c
@@ -0,0 +1,225 @@
+// Search for and parse the multiprocessor configuration table
+// See http://developer.intel.com/design/pentium/datashts/24201606.pdf
+
+#include <inc/types.h>
+#include <inc/string.h>
+#include <inc/memlayout.h>
+#include <inc/x86.h>
+#include <inc/mmu.h>
+#include <inc/env.h>
+#include <kern/cpu.h>
+#include <kern/pmap.h>
+
+struct CpuInfo cpus[NCPU];
+struct CpuInfo *bootcpu;
+int ismp;
+int ncpu;
+
+// Per-CPU kernel stacks
+unsigned char percpu_kstacks[NCPU][KSTKSIZE]
+__attribute__ ((aligned(PGSIZE)));
+
+
+// See MultiProcessor Specification Version 1.[14]
+
+struct mp {             // floating pointer [MP 4.1]
+	uint8_t signature[4];           // "_MP_"
+	physaddr_t physaddr;            // phys addr of MP config table
+	uint8_t length;                 // 1
+	uint8_t specrev;                // [14]
+	uint8_t checksum;               // all bytes must add up to 0
+	uint8_t type;                   // MP system config type
+	uint8_t imcrp;
+	uint8_t reserved[3];
+} __attribute__((__packed__));
+
+struct mpconf {         // configuration table header [MP 4.2]
+	uint8_t signature[4];           // "PCMP"
+	uint16_t length;                // total table length
+	uint8_t version;                // [14]
+	uint8_t checksum;               // all bytes must add up to 0
+	uint8_t product[20];            // product id
+	physaddr_t oemtable;            // OEM table pointer
+	uint16_t oemlength;             // OEM table length
+	uint16_t entry;                 // entry count
+	physaddr_t lapicaddr;           // address of local APIC
+	uint16_t xlength;               // extended table length
+	uint8_t xchecksum;              // extended table checksum
+	uint8_t reserved;
+	uint8_t entries[0];             // table entries
+} __attribute__((__packed__));
+
+struct mpproc {         // processor table entry [MP 4.3.1]
+	uint8_t type;                   // entry type (0)
+	uint8_t apicid;                 // local APIC id
+	uint8_t version;                // local APIC version
+	uint8_t flags;                  // CPU flags
+	uint8_t signature[4];           // CPU signature
+	uint32_t feature;               // feature flags from CPUID instruction
+	uint8_t reserved[8];
+} __attribute__((__packed__));
+
+// mpproc flags
+#define MPPROC_BOOT 0x02                // This mpproc is the bootstrap processor
+
+// Table entry types
+#define MPPROC    0x00  // One per processor
+#define MPBUS     0x01  // One per bus
+#define MPIOAPIC  0x02  // One per I/O APIC
+#define MPIOINTR  0x03  // One per bus interrupt source
+#define MPLINTR   0x04  // One per system interrupt source
+
+static uint8_t
+sum(void *addr, int len)
+{
+	int i, sum;
+
+	sum = 0;
+	for (i = 0; i < len; i++)
+		sum += ((uint8_t *)addr)[i];
+	return sum;
+}
+
+// Look for an MP structure in the len bytes at physical address addr.
+static struct mp *
+mpsearch1(physaddr_t a, int len)
+{
+	struct mp *mp = KADDR(a), *end = KADDR(a + len);
+
+	for (; mp < end; mp++)
+		if (memcmp(mp->signature, "_MP_", 4) == 0 &&
+		    sum(mp, sizeof(*mp)) == 0)
+			return mp;
+	return NULL;
+}
+
+// Search for the MP Floating Pointer Structure, which according to
+// [MP 4] is in one of the following three locations:
+// 1) in the first KB of the EBDA;
+// 2) if there is no EBDA, in the last KB of system base memory;
+// 3) in the BIOS ROM between 0xE0000 and 0xFFFFF.
+static struct mp *
+mpsearch(void)
+{
+	uint8_t *bda;
+	uint32_t p;
+	struct mp *mp;
+
+	static_assert(sizeof(*mp) == 16);
+
+	// The BIOS data area lives in 16-bit segment 0x40.
+	bda = (uint8_t *) KADDR(0x40 << 4);
+
+	// [MP 4] The 16-bit segment of the EBDA is in the two bytes
+	// starting at byte 0x0E of the BDA.  0 if not present.
+	if ((p = *(uint16_t *) (bda + 0x0E))) {
+		p <<= 4;	// Translate from segment to PA
+		if ((mp = mpsearch1(p, 1024)))
+			return mp;
+	} else {
+		// The size of base memory, in KB is in the two bytes
+		// starting at 0x13 of the BDA.
+		p = *(uint16_t *) (bda + 0x13) * 1024;
+		if ((mp = mpsearch1(p - 1024, 1024)))
+			return mp;
+	}
+	return mpsearch1(0xF0000, 0x10000);
+}
+
+// Search for an MP configuration table.  For now, don't accept the
+// default configurations (physaddr == 0).
+// Check for the correct signature, checksum, and version.
+static struct mpconf *
+mpconfig(struct mp **pmp)
+{
+	struct mpconf *conf;
+	struct mp *mp;
+
+	if ((mp = mpsearch()) == 0)
+		return NULL;
+	if (mp->physaddr == 0 || mp->type != 0) {
+		cprintf("SMP: Default configurations not implemented\n");
+		return NULL;
+	}
+	conf = (struct mpconf *) KADDR(mp->physaddr);
+	if (memcmp(conf, "PCMP", 4) != 0) {
+		cprintf("SMP: Incorrect MP configuration table signature\n");
+		return NULL;
+	}
+	if (sum(conf, conf->length) != 0) {
+		cprintf("SMP: Bad MP configuration checksum\n");
+		return NULL;
+	}
+	if (conf->version != 1 && conf->version != 4) {
+		cprintf("SMP: Unsupported MP version %d\n", conf->version);
+		return NULL;
+	}
+	if ((sum((uint8_t *)conf + conf->length, conf->xlength) + conf->xchecksum) & 0xff) {
+		cprintf("SMP: Bad MP configuration extended checksum\n");
+		return NULL;
+	}
+	*pmp = mp;
+	return conf;
+}
+
+void
+mp_init(void)
+{
+	struct mp *mp;
+	struct mpconf *conf;
+	struct mpproc *proc;
+	uint8_t *p;
+	unsigned int i;
+
+	bootcpu = &cpus[0];
+	if ((conf = mpconfig(&mp)) == 0)
+		return;
+	ismp = 1;
+	lapicaddr = conf->lapicaddr;
+
+	for (p = conf->entries, i = 0; i < conf->entry; i++) {
+		switch (*p) {
+		case MPPROC:
+			proc = (struct mpproc *)p;
+			if (proc->flags & MPPROC_BOOT)
+				bootcpu = &cpus[ncpu];
+			if (ncpu < NCPU) {
+				cpus[ncpu].cpu_id = ncpu;
+				ncpu++;
+			} else {
+				cprintf("SMP: too many CPUs, CPU %d disabled\n",
+					proc->apicid);
+			}
+			p += sizeof(struct mpproc);
+			continue;
+		case MPBUS:
+		case MPIOAPIC:
+		case MPIOINTR:
+		case MPLINTR:
+			p += 8;
+			continue;
+		default:
+			cprintf("mpinit: unknown config type %x\n", *p);
+			ismp = 0;
+			i = conf->entry;
+		}
+	}
+
+	bootcpu->cpu_status = CPU_STARTED;
+	if (!ismp) {
+		// Didn't like what we found; fall back to no MP.
+		ncpu = 1;
+		lapicaddr = 0;
+		cprintf("SMP: configuration not found, SMP disabled\n");
+		return;
+	}
+	cprintf("SMP: CPU %d found %d CPU(s)\n", bootcpu->cpu_id,  ncpu);
+
+	if (mp->imcrp) {
+		// [MP 3.2.6.1] If the hardware implements PIC mode,
+		// switch to getting interrupts from the LAPIC.
+		cprintf("SMP: Setting IMCR to switch from PIC mode to symmetric I/O mode\n");
+		outb(0x22, 0x70);   // Select IMCR
+		outb(0x23, inb(0x23) | 1);  // Mask external interrupts.
+	}
+}
diff --git a/kern/mpentry.S b/kern/mpentry.S
new file mode 100644
index 0000000..0c892ea
--- /dev/null
+++ b/kern/mpentry.S
@@ -0,0 +1,103 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/mmu.h>
+#include <inc/memlayout.h>
+
+###################################################################
+# entry point for APs
+###################################################################
+
+# Each non-boot CPU ("AP") is started up in response to a STARTUP
+# IPI from the boot CPU.  Section B.4.2 of the Multi-Processor
+# Specification says that the AP will start in real mode with CS:IP
+# set to XY00:0000, where XY is an 8-bit value sent with the
+# STARTUP. Thus this code must start at a 4096-byte boundary.
+#
+# Because this code sets DS to zero, it must run from an address in
+# the low 2^16 bytes of physical memory.
+#
+# boot_aps() (in init.c) copies this code to MPENTRY_PADDR (which
+# satisfies the above restrictions).  Then, for each AP, it stores the
+# address of the pre-allocated per-core stack in mpentry_kstack, sends
+# the STARTUP IPI, and waits for this code to acknowledge that it has
+# started (which happens in mp_main in init.c).
+#
+# This code is similar to boot/boot.S except that
+#    - it does not need to enable A20
+#    - it uses MPBOOTPHYS to calculate absolute addresses of its
+#      symbols, rather than relying on the linker to fill them
+
+#define RELOC(x) ((x) - KERNBASE)
+#define MPBOOTPHYS(s) ((s) - mpentry_start + MPENTRY_PADDR)
+
+.set PROT_MODE_CSEG, 0x8	# kernel code segment selector
+.set PROT_MODE_DSEG, 0x10	# kernel data segment selector
+
+.code16           
+.globl mpentry_start
+mpentry_start:
+	cli            
+
+	xorw    %ax, %ax
+	movw    %ax, %ds
+	movw    %ax, %es
+	movw    %ax, %ss
+
+	lgdt    MPBOOTPHYS(gdtdesc)
+	movl    %cr0, %eax
+	orl     $CR0_PE, %eax
+	movl    %eax, %cr0
+
+	ljmpl   $(PROT_MODE_CSEG), $(MPBOOTPHYS(start32))
+
+.code32
+start32:
+	movw    $(PROT_MODE_DSEG), %ax
+	movw    %ax, %ds
+	movw    %ax, %es
+	movw    %ax, %ss
+	movw    $0, %ax
+	movw    %ax, %fs
+	movw    %ax, %gs
+
+	# Set up initial page table. We cannot use kern_pgdir yet because
+	# we are still running at a low EIP.
+	movl    $(RELOC(entry_pgdir)), %eax
+	movl    %eax, %cr3
+
+	# Soporte para Large Pages
+	movl %cr4, %eax
+	orl $(CR4_PSE), %eax
+	movl %eax, %cr4		
+
+	# Turn on paging.
+	movl    %cr0, %eax
+	orl     $(CR0_PE|CR0_PG|CR0_WP), %eax
+	movl    %eax, %cr0
+
+	# Switch to the per-cpu stack allocated in boot_aps()
+	movl    mpentry_kstack, %esp
+	movl    $0x0, %ebp       # nuke frame pointer
+
+	# Call mp_main().  (Exercise for the reader: why the indirect call?)
+	movl    $mp_main, %eax
+	call    *%eax
+
+	# If mp_main returns (it shouldn't), loop.
+spin:
+	jmp     spin
+
+# Bootstrap GDT
+.p2align 2					# force 4 byte alignment
+gdt:
+	SEG_NULL				# null seg
+	SEG(STA_X|STA_R, 0x0, 0xffffffff)	# code seg
+	SEG(STA_W, 0x0, 0xffffffff)		# data seg
+
+gdtdesc:
+	.word   0x17				# sizeof(gdt) - 1
+	.long   MPBOOTPHYS(gdt)			# address gdt
+
+.globl mpentry_end
+mpentry_end:
+	nop
diff --git a/kern/picirq.c b/kern/picirq.c
new file mode 100644
index 0000000..8cb3e62
--- /dev/null
+++ b/kern/picirq.c
@@ -0,0 +1,86 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/assert.h>
+#include <inc/trap.h>
+
+#include <kern/picirq.h>
+
+
+// Current IRQ mask.
+// Initial IRQ mask has interrupt 2 enabled (for slave 8259A).
+uint16_t irq_mask_8259A = 0xFFFF & ~(1<<IRQ_SLAVE);
+static bool didinit;
+
+/* Initialize the 8259A interrupt controllers. */
+void
+pic_init(void)
+{
+	didinit = 1;
+
+	// mask all interrupts
+	outb(IO_PIC1+1, 0xFF);
+	outb(IO_PIC2+1, 0xFF);
+
+	// Set up master (8259A-1)
+
+	// ICW1:  0001g0hi
+	//    g:  0 = edge triggering, 1 = level triggering
+	//    h:  0 = cascaded PICs, 1 = master only
+	//    i:  0 = no ICW4, 1 = ICW4 required
+	outb(IO_PIC1, 0x11);
+
+	// ICW2:  Vector offset
+	outb(IO_PIC1+1, IRQ_OFFSET);
+
+	// ICW3:  bit mask of IR lines connected to slave PICs (master PIC),
+	//        3-bit No of IR line at which slave connects to master(slave PIC).
+	outb(IO_PIC1+1, 1<<IRQ_SLAVE);
+
+	// ICW4:  000nbmap
+	//    n:  1 = special fully nested mode
+	//    b:  1 = buffered mode
+	//    m:  0 = slave PIC, 1 = master PIC
+	//	  (ignored when b is 0, as the master/slave role
+	//	  can be hardwired).
+	//    a:  1 = Automatic EOI mode
+	//    p:  0 = MCS-80/85 mode, 1 = intel x86 mode
+	outb(IO_PIC1+1, 0x3);
+
+	// Set up slave (8259A-2)
+	outb(IO_PIC2, 0x11);			// ICW1
+	outb(IO_PIC2+1, IRQ_OFFSET + 8);	// ICW2
+	outb(IO_PIC2+1, IRQ_SLAVE);		// ICW3
+	// NB Automatic EOI mode doesn't tend to work on the slave.
+	// Linux source code says it's "to be investigated".
+	outb(IO_PIC2+1, 0x01);			// ICW4
+
+	// OCW3:  0ef01prs
+	//   ef:  0x = NOP, 10 = clear specific mask, 11 = set specific mask
+	//    p:  0 = no polling, 1 = polling mode
+	//   rs:  0x = NOP, 10 = read IRR, 11 = read ISR
+	outb(IO_PIC1, 0x68);             /* clear specific mask */
+	outb(IO_PIC1, 0x0a);             /* read IRR by default */
+
+	outb(IO_PIC2, 0x68);               /* OCW3 */
+	outb(IO_PIC2, 0x0a);               /* OCW3 */
+
+	if (irq_mask_8259A != 0xFFFF)
+		irq_setmask_8259A(irq_mask_8259A);
+}
+
+void
+irq_setmask_8259A(uint16_t mask)
+{
+	int i;
+	irq_mask_8259A = mask;
+	if (!didinit)
+		return;
+	outb(IO_PIC1+1, (char)mask);
+	outb(IO_PIC2+1, (char)(mask >> 8));
+	cprintf("enabled interrupts:");
+	for (i = 0; i < 16; i++)
+		if (~mask & (1<<i))
+			cprintf(" %d", i);
+	cprintf("\n");
+}
+
diff --git a/kern/picirq.h b/kern/picirq.h
new file mode 100644
index 0000000..4734889
--- /dev/null
+++ b/kern/picirq.h
@@ -0,0 +1,28 @@
+/* See COPYRIGHT for copyright information. */
+
+#ifndef JOS_KERN_PICIRQ_H
+#define JOS_KERN_PICIRQ_H
+#ifndef JOS_KERNEL
+# error "This is a JOS kernel header; user programs should not #include it"
+#endif
+
+#define MAX_IRQS	16	// Number of IRQs
+
+// I/O Addresses of the two 8259A programmable interrupt controllers
+#define IO_PIC1		0x20	// Master (IRQs 0-7)
+#define IO_PIC2		0xA0	// Slave (IRQs 8-15)
+
+#define IRQ_SLAVE	2	// IRQ at which slave connects to master
+
+
+#ifndef __ASSEMBLER__
+
+#include <inc/types.h>
+#include <inc/x86.h>
+
+extern uint16_t irq_mask_8259A;
+void pic_init(void);
+void irq_setmask_8259A(uint16_t mask);
+#endif // !__ASSEMBLER__
+
+#endif // !JOS_KERN_PICIRQ_H
diff --git a/kern/pmap.c b/kern/pmap.c
index 15e62ea..70b26c0 100644
--- a/kern/pmap.c
+++ b/kern/pmap.c
@@ -9,6 +9,7 @@
 #include <kern/pmap.h>
 #include <kern/kclock.h>
 #include <kern/env.h>
+#include <kern/cpu.h>
 
 // These variables are set by i386_detect_memory()
 size_t npages;                 // Amount of physical memory (in pages)
@@ -64,6 +65,7 @@ i386_detect_memory(void)
 // Set up memory mappings above UTOP.
 // --------------------------------------------------------------
 
+static void mem_init_mp(void);
 static void
 boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm);
 static void check_page_free_list(bool only_low_memory);
@@ -110,14 +112,14 @@ boot_alloc(uint32_t n)
 	// Están mapeados menos de 4 MB
 	// por lo que no podemos pedir
 	// más memoria que eso
-	if ((uintptr_t)ROUNDUP(nextfree + n, PGSIZE) > (KERNBASE + (4 << 20))) {
+	if ((uintptr_t) ROUNDUP(nextfree + n, PGSIZE) > (KERNBASE + (4 << 20))) {
 		panic("boot_alloc: out of memory");
 	}
 
 	result = nextfree;
 
 	if (n > 0) {
-		nextfree = ROUNDUP(nextfree + n, PGSIZE);	
+		nextfree = ROUNDUP(nextfree + n, PGSIZE);
 	}
 
 	return result;
@@ -167,10 +169,12 @@ mem_init(void)
 
 	pages = (struct PageInfo *) boot_alloc(npages * sizeof(struct PageInfo));
 	memset(pages, 0, npages * sizeof(struct PageInfo));
-		
+
 	//////////////////////////////////////////////////////////////////////
 	// Make 'envs' point to an array of size 'NENV' of 'struct Env'.
 	// LAB 3: Your code here.
+	envs = (struct Env *) boot_alloc(NENV * sizeof(struct Env));
+	memset(envs, 0, NENV * sizeof(struct Env));
 
 	//////////////////////////////////////////////////////////////////////
 	// Now that we've allocated the initial kernel data structures, we set
@@ -187,7 +191,7 @@ mem_init(void)
 	// panic("mem_init: This function is not finished\n");
 
 	check_page();
-	
+
 
 	//////////////////////////////////////////////////////////////////////
 	// Now we set up virtual memory
@@ -203,9 +207,13 @@ mem_init(void)
 	// Mapeo en kern_pgdir, UVPT - UPAGES direcciones virtuales a partir de UPAGES
 	// a direcciones físicas a partir de donde comienza el struct page info pages.
 
-	//page_insert    (pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
-	//boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
-	boot_map_region(kern_pgdir, UPAGES, ROUNDUP(npages * sizeof(struct PageInfo), PGSIZE), PADDR(pages), PTE_U | PTE_P);
+	// page_insert    (pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
+	// boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
+	boot_map_region(kern_pgdir,
+	                UPAGES,
+	                ROUNDUP(npages * sizeof(struct PageInfo), PGSIZE),
+	                PADDR(pages),
+	                PTE_U | PTE_P);
 
 	//////////////////////////////////////////////////////////////////////
 	// Map the 'envs' array read-only by the user at linear address UENVS
@@ -214,6 +222,11 @@ mem_init(void)
 	//    - the new image at UENVS  -- kernel R, user R
 	//    - envs itself -- kernel RW, user NONE
 	// LAB 3: Your code here.
+	boot_map_region(kern_pgdir,
+	                UENVS,
+	                ROUNDUP(NENV * sizeof(struct Env), PGSIZE),
+	                PADDR(envs),
+	                PTE_U | PTE_P);
 
 	//////////////////////////////////////////////////////////////////////
 	// Use the physical memory that 'bootstack' refers to as the kernel
@@ -226,7 +239,11 @@ mem_init(void)
 	//       overwrite memory.  Known as a "guard page".
 	//     Permissions: kernel RW, user NONE
 	// Your code goes here:
-    boot_map_region(kern_pgdir, KSTACKTOP - KSTKSIZE, KSTKSIZE, PADDR(bootstack), PTE_W | PTE_P);
+	boot_map_region(kern_pgdir,
+	                KSTACKTOP - KSTKSIZE,
+	                KSTKSIZE,
+	                PADDR(bootstack),
+	                PTE_W | PTE_P);
 
 	//////////////////////////////////////////////////////////////////////
 	// Map all of physical memory at KERNBASE.
@@ -236,7 +253,11 @@ mem_init(void)
 	// we just set up the mapping anyway.
 	// Permissions: kernel RW, user NONE
 	// Your code goes here:
- 	boot_map_region(kern_pgdir, KERNBASE, 0xffffffff - KERNBASE + 1, 0, PTE_W | PTE_P);
+	boot_map_region(
+	        kern_pgdir, KERNBASE, 0xffffffff - KERNBASE + 1, 0, PTE_W | PTE_P);
+
+	// Initialize the SMP-related parts of the memory map
+	mem_init_mp();
 
 	// Check that the initial page directory has been set up correctly.
 	check_kern_pgdir();
@@ -263,6 +284,47 @@ mem_init(void)
 	check_page_installed_pgdir();
 }
 
+// Modify mappings in kern_pgdir to support SMP
+//   - Map the per-CPU stacks in the region [KSTACKTOP-PTSIZE, KSTACKTOP)
+//
+static void
+mem_init_mp(void)
+{
+	// Map per-CPU stacks starting at KSTACKTOP, for up to 'NCPU' CPUs.
+	//
+	// For CPU i, use the physical memory that 'percpu_kstacks[i]' refers
+	// to as its kernel stack. CPU i's kernel stack grows down from virtual
+	// address kstacktop_i = KSTACKTOP - i * (KSTKSIZE + KSTKGAP), and is
+	// divided into two pieces, just like the single stack you set up in
+	// mem_init:
+	//     * [kstacktop_i - KSTKSIZE, kstacktop_i)
+	//          -- backed by physical memory
+	//     * [kstacktop_i - (KSTKSIZE + KSTKGAP), kstacktop_i - KSTKSIZE)
+	//          -- not backed; so if the kernel overflows its stack,
+	//             it will fault rather than overwrite another CPU's stack.
+	//             Known as a "guard page".
+	//     Permissions: kernel RW, user NONE
+	//
+	// LAB 4: Your code here:
+	uintptr_t kstacktop_i;
+	for (size_t i = 0 ; i < NCPU ; i++) {
+		// kstacktop_i tendra la direccion de memoria virtual
+		// del TOPE del stack del CPU i. Recordar que el stack
+		// crece a direcciones de memoria virtual mas bajas,
+		// con lo cual el limite del stack_i estara en 
+		// kstacktop_i + KSTKSIZE. Ver memlayout.h
+		// para mas informacion.
+		kstacktop_i = KSTACKTOP - i * (KSTKSIZE + KSTKGAP);
+		boot_map_region(
+			kern_pgdir, 
+			kstacktop_i - KSTKSIZE, 
+			KSTKSIZE, 
+			PADDR(percpu_kstacks[i]), // Usamos la PA indicada
+			PTE_W | PTE_P
+		);
+	}
+}
+
 // --------------------------------------------------------------
 // Tracking of physical pages.
 // The 'pages' array has one 'struct PageInfo' entry per physical page.
@@ -279,30 +341,36 @@ void
 page_init(void)
 {
 	// Hay paginas prohibidas y paginas libres.
-	// Las páginas prohibidas son todas las que ya estan ocupadas hasta este punto.
-	// Mas las que se indiquen en los comentarios en inglés de abajo.
+	// Las páginas prohibidas son todas las que ya estan ocupadas hasta este
+	// punto. Mas las que se indiquen en los comentarios en inglés de abajo.
 	// Las paginas prohibidas se ponen en 0 y en NULL
 	// En 0 porque si se intentan liberar tirará kernel panic
 	// Y en null porque no forman parte de la lista enlazada
 	// Entonces hay que enlazar todas las páginas menos las prohibidas
 	// Poniendolas en 0 (pues son libres) y enalzando los punteros
 	// Las ocupadas que habrá en el futuro si van a tener su valor en 1
-	// Pero su puntero estará en NULL pues no formaran mas parte de la lista libre
-	// Hasta que sean liberadas.
+	// Pero su puntero estará en NULL pues no formaran mas parte de la lista
+	// libre Hasta que sean liberadas.
 
 	// Rocomienda dato: Que el for que viene ya hecho, poner if (condicion) continue;
 	// y luego las lineas originales de la funcion. Esa condicion es la que me dice
 	// si es una página prohibida, osea if(prohibida)
-	// Una manera muy facil es decir: 
+	// Una manera muy facil es decir:
 	/*
-		physaddr_t addr = 0
-		if (i = 1; i < npages; i++) { // i empieza en 1 para saltear la primera página
-			if (addr >= boot_alloc(0) || addr < io_phys_mem) {
-				entonces no es prohibida
-			}
-			addr += PGSIZE;
-		}
+	        physaddr_t addr = 0
+	        if (i = 1; i < npages; i++) { // i empieza en 1 para saltear la primera página
+	                if (addr >= boot_alloc(0) || addr < io_phys_mem) {
+	                        entonces no es prohibida
+	                }
+	                addr += PGSIZE;
+	        }
 	*/
+	// LAB 4:
+	// Change your code to mark the physical page at MPENTRY_PADDR
+	// as in use
+	_Static_assert(MPENTRY_PADDR % PGSIZE == 0,
+               "MPENTRY_PADDR is not page-aligned");
+
 	// The example code here marks all physical pages as free.
 	// However this is not truly the case.  What memory is free?
 	//  1) Mark physical page 0 as in use.
@@ -317,7 +385,7 @@ page_init(void)
 	//     in physical memory?  Which pages are already in use for
 	//     page tables and other data structures?
 	// Aca empieza el kernel
-	// Estan ocupadas todas las paginas 
+	// Estan ocupadas todas las paginas
 	// desde EXTPHYSMEM hasta boot_alloc(0)
 	//
 	// Change the code to reflect this.
@@ -326,8 +394,12 @@ page_init(void)
 	physaddr_t paddr;
 	for (size_t i = 1; i < npages; i++) {
 		paddr = i * PGSIZE;
-		if (paddr >= PADDR(boot_alloc(0)) || paddr < IOPHYSMEM) { // Si no es una dirección prohibida
-			// pages[i].pp_ref = 0; // Fue seteado con memset
+		if (paddr == MPENTRY_PADDR) {
+			continue;
+		}
+		if (paddr >= PADDR(boot_alloc(0)) || paddr < IOPHYSMEM) { 
+		// Si no es una dirección prohibida
+		// pages[i].pp_ref = 0; // Fue seteado con memset
 		  pages[i].pp_link = page_free_list;
 		  page_free_list = &pages[i];
 		}
@@ -351,11 +423,11 @@ page_alloc(int alloc_flags)
 {
 	// Fill this function in
 	if (page_free_list) {
-		struct PageInfo * page = page_free_list;
-	  page_free_list = page->pp_link;
-	  page->pp_link = NULL;
+		struct PageInfo *page = page_free_list;
+		page_free_list = page->pp_link;
+		page->pp_link = NULL;
 
-	  if (alloc_flags & ALLOC_ZERO) {
+		if (alloc_flags & ALLOC_ZERO) {
 			// Seteamos a cero la pagina fisica
 			// no el struct PageInfo
 			memset(page2kva(page), 0, PGSIZE);
@@ -364,7 +436,7 @@ page_alloc(int alloc_flags)
 		return page;
 	}
 
-	return NULL; // No free pages
+	return NULL;  // No free pages
 }
 
 //
@@ -424,42 +496,43 @@ page_decref(struct PageInfo *pp)
 //
 
 /*
-	Recibe siempre como parámetro un pde_t * que es un puntero a una tira de 1024 words de 4 bytes.
-	pde_t * es accesible con corchetes [].
-	Es una estructura que sirve de Page Directory. Cada entrada tiene 32 bits. Los 20 bits mas altos
-	son una dirección física donde se ubica la Page Table en particular. Los 12 bits resntes son
-	bits de presencia.
-
-	De la casilla saco la dirección física, la conveierto en virtual y con eso referencio la Page Table
-	que quiero. 
-
-	Esta funcion es una funcion de soporte que permite llegar a la página que interesa.
-	Hay que chequear si el bit de presencia esta a cero (en ese caso la entrada dell page
-	directory no tendra nada). Si esta en cero y flag de create, hay que alocar un page table y asignarselo
-	en esa posición con la dirección física de  la page table alocada y ponerle los bits que 
-	corresponda. 
-	Si aloca una pagina, hay que hacer pp_ref++ a cada 
-
-	Retorna un puntero (direccion virtual) a la page table
+        Recibe siempre como parámetro un pde_t * que es un puntero a una tira de
+   1024 words de 4 bytes. pde_t * es accesible con corchetes []. Es una
+   estructura que sirve de Page Directory. Cada entrada tiene 32 bits. Los 20
+   bits mas altos son una dirección física donde se ubica la Page Table en
+   particular. Los 12 bits resntes son bits de presencia.
+
+        De la casilla saco la dirección física, la conveierto en virtual y con
+   eso referencio la Page Table que quiero.
+
+        Esta funcion es una funcion de soporte que permite llegar a la página
+   que interesa. Hay que chequear si el bit de presencia esta a cero (en ese
+   caso la entrada dell page directory no tendra nada). Si esta en cero y flag
+   de create, hay que alocar un page table y asignarselo en esa posición con la
+   dirección física de  la page table alocada y ponerle los bits que
+        corresponda.
+        Si aloca una pagina, hay que hacer pp_ref++ a cada
+
+        Retorna un puntero (direccion virtual) a la page table
 */
 pte_t *
 pgdir_walk(pde_t *pgdir, const void *va, int create)
 {
 	// Obtengo la entrada en la PD sumando a pgdir el indice de la VA
-	pde_t * pde = pgdir + PDX(va);
+	pde_t *pde = pgdir + PDX(va);
 
 	if ((*pde & PTE_P)) {
 		// Obtengo la direccion virtual del PT base register
-		pte_t * ptbr = KADDR(PTE_ADDR(*pde));
+		pte_t *ptbr = KADDR(PTE_ADDR(*pde));
 
 		// Si ya existe retornamos el PTE correspondiente
 		return ptbr + PTX(va);
 	} else if (create) {
 		// Si la page table buscada no está presente y el flag de create esta activado
-		struct PageInfo * new_pt_page = page_alloc(ALLOC_ZERO);
+		struct PageInfo *new_pt_page = page_alloc(ALLOC_ZERO);
 
 		if (!new_pt_page) {
-			return NULL;	// Fallo el page alloc porque no había mas memoria
+			return NULL;  // Fallo el page alloc porque no había mas memoria
 		}
 
 		// Obtengo la direccion física de la entrada a la page table alocada
@@ -472,15 +545,15 @@ pgdir_walk(pde_t *pgdir, const void *va, int create)
 		new_pt_page->pp_ref++;
 
 		// Obtengo la direccion virtual del PT base register
-		pte_t * ptbr = KADDR(PTE_ADDR(*pde));
-		
+		pte_t *ptbr = KADDR(PTE_ADDR(*pde));
+
 		// Devolvemos el puntero a PTE
 		return ptbr + PTX(va);
 	} else {
-		// No está presente la page table 
+		// No está presente la page table
 		// buscada y el flag de create está desactivado
-		return NULL; 
-	}	
+		return NULL;
+	}
 }
 
 //
@@ -500,23 +573,24 @@ pgdir_walk(pde_t *pgdir, const void *va, int create)
 static void
 boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
 {
-  #ifndef TP1_PSE
+#ifndef TP1_PSE
 	assert(va % PGSIZE == 0);
 	assert(pa % PGSIZE == 0);
 	assert(size % PGSIZE == 0);
 	assert(perm < (1 << PTXSHIFT));
 
-	for (size_t i = 0; i < size/PGSIZE; i++, va+=PGSIZE, pa+=PGSIZE) {
-		pte_t * pte = pgdir_walk(pgdir, (const void *) va, 1);
-		*pte |= pa | perm | PTE_P;
+	for (size_t i = 0; i < size / PGSIZE; i++, va += PGSIZE, pa += PGSIZE) {
+		pte_t *pte = pgdir_walk(pgdir, (const void *) va, 1);
+		*pte = pa | perm | PTE_P;
 	}
-	
-  #else
+
+#else
 	if (va % PTSIZE == 0 && size % PTSIZE == 0 && pa % PTSIZE == 0) {
 		// Es una Large Page
-		for (size_t i = 0; i < size/PTSIZE; i++, va += PTSIZE, pa += PTSIZE) {
+		for (size_t i = 0; i < size / PTSIZE;
+		     i++, va += PTSIZE, pa += PTSIZE) {
 			// Obtengo la PDE
-			pde_t * pde = pgdir + PDX(va);
+			pde_t *pde = pgdir + PDX(va);
 			// Escribo la dirección física de la página larga en la PDE,
 			// seteando los flags perm, PTE_PS (large page) y PTE_P (present)
 			*pde = pa | perm | PTE_PS | PTE_P;
@@ -528,13 +602,14 @@ boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm
 		assert(size % PGSIZE == 0);
 		assert(perm < (1 << PTXSHIFT));
 
-		for (size_t i = 0; i < size/PGSIZE; i++, va+=PGSIZE, pa+=PGSIZE) {
-			pte_t * pte = pgdir_walk(pgdir, (const void *) va, 1);
+		for (size_t i = 0; i < size / PGSIZE;
+		     i++, va += PGSIZE, pa += PGSIZE) {
+			pte_t *pte = pgdir_walk(pgdir, (const void *) va, 1);
 			*pte |= pa | perm | PTE_P;
 		}
 	}
 
-  #endif
+#endif
 }
 
 //
@@ -565,7 +640,7 @@ boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm
 int
 page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
 {
-	pte_t * pte = pgdir_walk(pgdir, va, 1);
+	pte_t *pte = pgdir_walk(pgdir, va, 1);
 
 	if (pte == NULL) {
 		// pgdir_walk pudo fallar por falta de memoria
@@ -610,21 +685,21 @@ page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
 //
 
 /*
-	Dada una dirección virtual nos da un PageInfo
-	pgdir_walk(VA) = direccion virtual de la entrada a la página
-	pte_t * p = pgdir_walk(va)
-	phys f = PTE_ADR(*p)		// me da la dirección fisica 
-	pa2page(f) -> Me retorna la página de la dirección física y retornamos esto
+        Dada una dirección virtual nos da un PageInfo
+        pgdir_walk(VA) = direccion virtual de la entrada a la página
+        pte_t * p = pgdir_walk(va)
+        phys f = PTE_ADR(*p)		// me da la dirección fisica
+        pa2page(f) -> Me retorna la página de la dirección física y retornamos esto
 */
 
 struct PageInfo *
 page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
 {
-	pte_t * pte = pgdir_walk(pgdir, va, 0);
+	pte_t *pte = pgdir_walk(pgdir, va, 0);
 
 	if (pte == NULL || !(*pte & PTE_P)) {
 		// No hay pagina mapeada para va
-		return NULL; 
+		return NULL;
 	}
 
 	if (pte_store) {
@@ -653,18 +728,18 @@ page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
 //
 
 /*
-	Recibe un VA y hace dos cosas:
-	- decref(pagina) (es una función que ya esta implementada)
-		decrementa el pageref y si queda en cero llama a free de la pagina automaticamente.
-	- limpiar PTE (Pone la page table entry a cero)
+        Recibe un VA y hace dos cosas:
+        - decref(pagina) (es una función que ya esta implementada)
+                decrementa el pageref y si queda en cero llama a free de la pagina automaticamente.
+        - limpiar PTE (Pone la page table entry a cero)
 */
 void
 page_remove(pde_t *pgdir, void *va)
 {
-	pte_t * pte;
+	pte_t *pte;
 
 	// Conseguimos el struct PageInfo asociado y guardamos su PTE
-	struct PageInfo * page_to_remove = page_lookup(pgdir, va, &pte);
+	struct PageInfo *page_to_remove = page_lookup(pgdir, va, &pte);
 
 	// Decrementamos pp_ref y liberamos si es necesario
 	page_decref(page_to_remove);
@@ -684,8 +759,59 @@ void
 tlb_invalidate(pde_t *pgdir, void *va)
 {
 	// Flush the entry only if we're modifying the current address space.
-	// For now, there is only one address space, so always invalidate.
-	invlpg(va);
+	if (!curenv || curenv->env_pgdir == pgdir)
+		invlpg(va);
+}
+
+//
+// Reserve size bytes in the MMIO region and map [pa,pa+size) at this
+// location.  Return the base of the reserved region.  size does *not*
+// have to be multiple of PGSIZE.
+//
+void *
+mmio_map_region(physaddr_t pa, size_t size)
+{
+	// Where to start the next region.  Initially, this is the
+	// beginning of the MMIO region.  Because this is static, its
+	// value will be preserved between calls to mmio_map_region
+	// (just like nextfree in boot_alloc).
+	static uintptr_t base = MMIOBASE;
+
+	// Reserve size bytes of virtual memory starting at base and
+	// map physical pages [pa,pa+size) to virtual addresses
+	// [base,base+size).  Since this is device memory and not
+	// regular DRAM, you'll have to tell the CPU that it isn't
+	// safe to cache access to this memory.  Luckily, the page
+	// tables provide bits for this purpose; simply create the
+	// mapping with PTE_PCD|PTE_PWT (cache-disable and
+	// write-through) in addition to PTE_W.  (If you're interested
+	// in more details on this, see section 10.5 of IA32 volume
+	// 3A.)
+	//
+	// Be sure to round size up to a multiple of PGSIZE and to
+	// handle if this reservation would overflow MMIOLIM (it's
+	// okay to simply panic if this happens).
+	//
+	// Hint: The staff solution uses boot_map_region.
+	//
+	// Your code here:
+	// Redondeamos size para arriba a un multiplo de PGSIZE
+	size = ROUNDUP(size, PGSIZE);
+
+	// Checkeamos que no nos excedamos del limite
+	if (base + size > MMIOLIM) {
+		panic("mmio_map_region overflow MMIOLIM");
+	}
+
+	// Mapeamos con la funcion boot_map_region utilizando los permisos
+	// indicados para que el CPU no cachee los accesos a estas zonas de mem.
+	boot_map_region(kern_pgdir, base, size, pa, PTE_PCD | PTE_PWT | PTE_W);
+
+	// Guardamos la base mapeada para ser retornada
+	// Actualizamos la variable base (estatica)
+	uintptr_t ret = base;
+	base += size;
+	return (void*)ret;
 }
 
 static uintptr_t user_mem_check_addr;
@@ -712,6 +838,39 @@ int
 user_mem_check(struct Env *env, const void *va, size_t len, int perm)
 {
 	// LAB 3: Your code here.
+	uintptr_t r_va = ROUNDDOWN((uintptr_t) va, PGSIZE);
+	uintptr_t r_va_plus_len = ROUNDUP((uintptr_t)(va + len), PGSIZE);
+
+	// Cálculo de la cantidad de paginas a checkear
+	size_t pages_to_check = (r_va_plus_len - r_va) / PGSIZE;
+
+	pte_t *pte;
+
+	while (pages_to_check) {
+		pte = pgdir_walk(env->env_pgdir, (void *) r_va, 0);
+		bool is_va_in_range = r_va < ULIM ? true : false;
+		bool valid_pde = (env->env_pgdir[PDX(r_va)] & (perm | PTE_P)) ==
+		                                 (perm | PTE_P)
+		                         ? true
+		                         : false;
+		bool valid_pte = ((*pte) & (perm | PTE_P)) == (perm | PTE_P)
+		                         ? true
+		                         : false;
+
+		if (is_va_in_range && valid_pde && valid_pte) {
+			pages_to_check--;
+			r_va += PGSIZE;
+		} else {  // Failed permissions
+			user_mem_check_addr = (uintptr_t) va;
+			if (user_mem_check_addr < r_va) {
+				// Por si fallamos en el primer checkeo
+				// tenemos el valor del ROUNDOWN y deberiamos
+				// devolver va en ese caso
+				user_mem_check_addr = r_va;
+			}
+			return -E_FAULT;
+		}
+	}
 
 	return 0;
 }
@@ -789,6 +948,8 @@ check_page_free_list(bool only_low_memory)
 		assert(page2pa(pp) != EXTPHYSMEM);
 		assert(page2pa(pp) < EXTPHYSMEM ||
 		       (char *) page2kva(pp) >= first_free_page);
+		// (new test for lab 4)
+		assert(page2pa(pp) != MPENTRY_PADDR);
 
 		if (page2pa(pp) < EXTPHYSMEM)
 			++nfree_basemem;
@@ -798,6 +959,8 @@ check_page_free_list(bool only_low_memory)
 
 	assert(nfree_basemem > 0);
 	assert(nfree_extmem > 0);
+
+	cprintf("check_page_free_list() succeeded!\n");
 }
 
 //
@@ -909,10 +1072,15 @@ check_kern_pgdir(void)
 		assert(check_va2pa(pgdir, KERNBASE + i) == i);
 
 	// check kernel stack
-	for (i = 0; i < KSTKSIZE; i += PGSIZE)
-		assert(check_va2pa(pgdir, KSTACKTOP - KSTKSIZE + i) ==
-		       PADDR(bootstack) + i);
-	assert(check_va2pa(pgdir, KSTACKTOP - PTSIZE) == ~0);
+	// (updated in lab 4 to check per-CPU kernel stacks)
+	for (n = 0; n < NCPU; n++) {
+		uint32_t base = KSTACKTOP - (KSTKSIZE + KSTKGAP) * (n + 1);
+		for (i = 0; i < KSTKSIZE; i += PGSIZE)
+			assert(check_va2pa(pgdir, base + KSTKGAP + i) ==
+			       PADDR(percpu_kstacks[n]) + i);
+		for (i = 0; i < KSTKGAP; i += PGSIZE)
+			assert(check_va2pa(pgdir, base + i) == ~0);
+	}
 
 	// check PDE permissions
 	for (i = 0; i < NPDENTRIES; i++) {
@@ -921,6 +1089,7 @@ check_kern_pgdir(void)
 		case PDX(KSTACKTOP - 1):
 		case PDX(UPAGES):
 		case PDX(UENVS):
+		case PDX(MMIOBASE):
 			assert(pgdir[i] & PTE_P);
 			break;
 		default:
@@ -974,6 +1143,7 @@ check_page(void)
 	struct PageInfo *fl;
 	pte_t *ptep, *ptep1;
 	void *va;
+	uintptr_t mm1, mm2;
 	int i;
 	extern pde_t entry_pgdir[];
 	// should be able to allocate three pages
@@ -1117,6 +1287,30 @@ check_page(void)
 	page_free(pp1);
 	page_free(pp2);
 
+	// test mmio_map_region
+	mm1 = (uintptr_t) mmio_map_region(0, 4097);
+	mm2 = (uintptr_t) mmio_map_region(0, 4096);
+	// check that they're in the right region
+	assert(mm1 >= MMIOBASE && mm1 + 8096 < MMIOLIM);
+	assert(mm2 >= MMIOBASE && mm2 + 8096 < MMIOLIM);
+	// check that they're page-aligned
+	assert(mm1 % PGSIZE == 0 && mm2 % PGSIZE == 0);
+	// check that they don't overlap
+	assert(mm1 + 8096 <= mm2);
+	// check page mappings
+	assert(check_va2pa(kern_pgdir, mm1) == 0);
+	assert(check_va2pa(kern_pgdir, mm1 + PGSIZE) == PGSIZE);
+	assert(check_va2pa(kern_pgdir, mm2) == 0);
+	assert(check_va2pa(kern_pgdir, mm2 + PGSIZE) == ~0);
+	// check permissions
+	assert(*pgdir_walk(kern_pgdir, (void *) mm1, 0) &
+	       (PTE_W | PTE_PWT | PTE_PCD));
+	assert(!(*pgdir_walk(kern_pgdir, (void *) mm1, 0) & PTE_U));
+	// clear the mappings
+	*pgdir_walk(kern_pgdir, (void *) mm1, 0) = 0;
+	*pgdir_walk(kern_pgdir, (void *) mm1 + PGSIZE, 0) = 0;
+	*pgdir_walk(kern_pgdir, (void *) mm2, 0) = 0;
+
 	cprintf("check_page() succeeded!\n");
 }
 
diff --git a/kern/pmap.h b/kern/pmap.h
index ab0bee9..428087e 100644
--- a/kern/pmap.h
+++ b/kern/pmap.h
@@ -63,6 +63,8 @@ void	page_decref(struct PageInfo *pp);
 
 void	tlb_invalidate(pde_t *pgdir, void *va);
 
+void *	mmio_map_region(physaddr_t pa, size_t size);
+
 int	user_mem_check(struct Env *env, const void *va, size_t len, int perm);
 void	user_mem_assert(struct Env *env, const void *va, size_t len, int perm);
 
diff --git a/kern/sched.c b/kern/sched.c
new file mode 100644
index 0000000..10bae84
--- /dev/null
+++ b/kern/sched.c
@@ -0,0 +1,105 @@
+#include <inc/assert.h>
+#include <inc/x86.h>
+#include <kern/spinlock.h>
+#include <kern/env.h>
+#include <kern/pmap.h>
+#include <kern/monitor.h>
+
+void sched_halt(void);
+
+// Choose a user environment to run and run it.
+void
+sched_yield(void)
+{
+	struct Env *idle;
+
+	// Implement simple round-robin scheduling.
+	//
+	// Search through 'envs' for an ENV_RUNNABLE environment in
+	// circular fashion starting just after the env this CPU was
+	// last running.  Switch to the first such environment found.
+	//
+	// If no envs are runnable, but the environment previously
+	// running on this CPU is still ENV_RUNNING, it's okay to
+	// choose that environment.
+	//
+	// Never choose an environment that's currently running on
+	// another CPU (env_status == ENV_RUNNING). If there are
+	// no runnable environments, simply drop through to the code
+	// below to halt the cpu.
+
+	// LAB 4: Your code here.
+	size_t curenv_idx = 0;
+
+	// Checkeamos si curenv no es NULL si es asi arrancamos
+	// por el indice 0 del arreglo envs
+	if (curenv) {
+		curenv_idx = ENVX(curenv->env_id);
+	}
+
+	// Recorremos circularmente el arreglo envs
+	for (size_t i = 0 ; i < NENV ; i++) {
+		// Tomamos el modulo para hacer el recorrido circular
+		idle = envs + ((curenv_idx + i) % NENV);
+		// Checkeamos el primer proceso en RUNNABLE
+		if (idle->env_status == ENV_RUNNABLE) {
+			env_run(idle);
+		}
+	}
+
+	// Si no habia ningun proceso runnable checkeamos
+	// por el proceso actual si es que existe
+	if (curenv && curenv->env_status == ENV_RUNNING) {
+		env_run(curenv);
+	}
+
+	// sched_halt never returns
+	sched_halt();
+}
+
+// Halt this CPU when there is nothing to do. Wait until the
+// timer interrupt wakes it up. This function never returns.
+//
+void
+sched_halt(void)
+{
+	int i;
+
+	// For debugging and testing purposes, if there are no runnable
+	// environments in the system, then drop into the kernel monitor.
+	for (i = 0; i < NENV; i++) {
+		if ((envs[i].env_status == ENV_RUNNABLE ||
+		     envs[i].env_status == ENV_RUNNING ||
+		     envs[i].env_status == ENV_DYING))
+			break;
+	}
+	if (i == NENV) {
+		cprintf("No runnable environments in the system!\n");
+		while (1)
+			monitor(NULL);
+	}
+
+	// Mark that no environment is running on this CPU
+	curenv = NULL;
+	lcr3(PADDR(kern_pgdir));
+
+	// Mark that this CPU is in the HALT state, so that when
+	// timer interupts come in, we know we should re-acquire the
+	// big kernel lock
+	xchg(&thiscpu->cpu_status, CPU_HALTED);
+
+	// Release the big kernel lock as if we were "leaving" the kernel
+	unlock_kernel();
+
+	// Reset stack pointer, enable interrupts and then halt.
+	asm volatile("movl $0, %%ebp\n"
+	             "movl %0, %%esp\n"
+	             "pushl $0\n"
+	             "pushl $0\n"
+	             "sti\n"
+	             "1:\n"
+	             "hlt\n"
+	             "jmp 1b\n"
+	             :
+	             : "a"(thiscpu->cpu_ts.ts_esp0));
+}
diff --git a/kern/sched.h b/kern/sched.h
new file mode 100644
index 0000000..754f6a0
--- /dev/null
+++ b/kern/sched.h
@@ -0,0 +1,12 @@
+/* See COPYRIGHT for copyright information. */
+
+#ifndef JOS_KERN_SCHED_H
+#define JOS_KERN_SCHED_H
+#ifndef JOS_KERNEL
+# error "This is a JOS kernel header; user programs should not #include it"
+#endif
+
+// This function does not return.
+void sched_yield(void) __attribute__((noreturn));
+
+#endif	// !JOS_KERN_SCHED_H
diff --git a/kern/spinlock.c b/kern/spinlock.c
new file mode 100644
index 0000000..bf4d2d2
--- /dev/null
+++ b/kern/spinlock.c
@@ -0,0 +1,116 @@
+// Mutual exclusion spin locks.
+
+#include <inc/types.h>
+#include <inc/assert.h>
+#include <inc/x86.h>
+#include <inc/memlayout.h>
+#include <inc/string.h>
+#include <kern/cpu.h>
+#include <kern/spinlock.h>
+#include <kern/kdebug.h>
+
+// The big kernel lock
+struct spinlock kernel_lock = {
+#ifdef DEBUG_SPINLOCK
+	.name = "kernel_lock"
+#endif
+};
+
+#ifdef DEBUG_SPINLOCK
+// Record the current call stack in pcs[] by following the %ebp chain.
+static void
+get_caller_pcs(uint32_t pcs[])
+{
+	uint32_t *ebp;
+	int i;
+
+	ebp = (uint32_t *)read_ebp();
+	for (i = 0; i < 10; i++){
+		if (ebp == 0 || ebp < (uint32_t *)ULIM)
+			break;
+		pcs[i] = ebp[1];          // saved %eip
+		ebp = (uint32_t *)ebp[0]; // saved %ebp
+	}
+	for (; i < 10; i++)
+		pcs[i] = 0;
+}
+
+// Check whether this CPU is holding the lock.
+static int
+holding(struct spinlock *lock)
+{
+	return lock->locked && lock->cpu == thiscpu;
+}
+#endif
+
+void
+__spin_initlock(struct spinlock *lk, char *name)
+{
+	lk->locked = 0;
+#ifdef DEBUG_SPINLOCK
+	lk->name = name;
+	lk->cpu = 0;
+#endif
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+// Holding a lock for a long time may cause
+// other CPUs to waste time spinning to acquire it.
+void
+spin_lock(struct spinlock *lk)
+{
+#ifdef DEBUG_SPINLOCK
+	if (holding(lk))
+		panic("CPU %d cannot acquire %s: already holding", cpunum(), lk->name);
+#endif
+
+	// The xchg is atomic.
+	// It also serializes, so that reads after acquire are not
+	// reordered before it. 
+	while (xchg(&lk->locked, 1) != 0)
+		asm volatile ("pause");
+
+	// Record info about lock acquisition for debugging.
+#ifdef DEBUG_SPINLOCK
+	lk->cpu = thiscpu;
+	get_caller_pcs(lk->pcs);
+#endif
+}
+
+// Release the lock.
+void
+spin_unlock(struct spinlock *lk)
+{
+#ifdef DEBUG_SPINLOCK
+	if (!holding(lk)) {
+		int i;
+		uint32_t pcs[10];
+		// Nab the acquiring EIP chain before it gets released
+		memmove(pcs, lk->pcs, sizeof pcs);
+		cprintf("CPU %d cannot release %s: held by CPU %d\nAcquired at:", 
+			cpunum(), lk->name, lk->cpu->cpu_id);
+		for (i = 0; i < 10 && pcs[i]; i++) {
+			struct Eipdebuginfo info;
+			if (debuginfo_eip(pcs[i], &info) >= 0)
+				cprintf("  %08x %s:%d: %.*s+%x\n", pcs[i],
+					info.eip_file, info.eip_line,
+					info.eip_fn_namelen, info.eip_fn_name,
+					pcs[i] - info.eip_fn_addr);
+			else
+				cprintf("  %08x\n", pcs[i]);
+		}
+		panic("spin_unlock");
+	}
+
+	lk->pcs[0] = 0;
+	lk->cpu = 0;
+#endif
+
+	// The xchg instruction is atomic (i.e. uses the "lock" prefix) with
+	// respect to any other instruction which references the same memory.
+	// x86 CPUs will not reorder loads/stores across locked instructions
+	// (vol 3, 8.2.2). Because xchg() is implemented using asm volatile,
+	// gcc will not reorder C statements across the xchg.
+	xchg(&lk->locked, 0);
+}
diff --git a/kern/spinlock.h b/kern/spinlock.h
new file mode 100644
index 0000000..52d20b4
--- /dev/null
+++ b/kern/spinlock.h
@@ -0,0 +1,48 @@
+#ifndef JOS_INC_SPINLOCK_H
+#define JOS_INC_SPINLOCK_H
+
+#include <inc/types.h>
+
+// Comment this to disable spinlock debugging
+#define DEBUG_SPINLOCK
+
+// Mutual exclusion lock.
+struct spinlock {
+	unsigned locked;       // Is the lock held?
+
+#ifdef DEBUG_SPINLOCK
+	// For debugging:
+	char *name;            // Name of lock.
+	struct CpuInfo *cpu;   // The CPU holding the lock.
+	uintptr_t pcs[10];     // The call stack (an array of program counters)
+	                       // that locked the lock.
+#endif
+};
+
+void __spin_initlock(struct spinlock *lk, char *name);
+void spin_lock(struct spinlock *lk);
+void spin_unlock(struct spinlock *lk);
+
+#define spin_initlock(lock)   __spin_initlock(lock, #lock)
+
+extern struct spinlock kernel_lock;
+
+static inline void
+lock_kernel(void)
+{
+	spin_lock(&kernel_lock);
+}
+
+static inline void
+unlock_kernel(void)
+{
+	spin_unlock(&kernel_lock);
+
+	// Normally we wouldn't need to do this, but QEMU only runs
+	// one CPU at a time and has a long time-slice.  Without the
+	// pause, this CPU is likely to reacquire the lock before
+	// another CPU has even been given a chance to acquire it.
+	asm volatile("pause");
+}
+
+#endif
diff --git a/kern/syscall.c b/kern/syscall.c
index 0ee6be0..b36e73d 100644
--- a/kern/syscall.c
+++ b/kern/syscall.c
@@ -10,6 +10,28 @@
 #include <kern/trap.h>
 #include <kern/syscall.h>
 #include <kern/console.h>
+#include <kern/sched.h>
+
+
+
+
+// Funcion propia para validar direcciones
+// de memoria virtual pasadas a la syscall
+static int
+check_va(const void * va) {
+	uintptr_t casted = (uintptr_t)va;
+	if (PGOFF(casted) || casted >= UTOP) return -E_INVAL;
+	else return 0;
+}
+
+// Funcion propia para validar los permisos
+// Primero comprobamos que no tengan permisos invalidos
+// Segundo comprobamos que los mandatorios esten seteados
+static int
+check_permissions(int perm) {
+	if (perm & ~PTE_SYSCALL || ((perm & (PTE_U | PTE_P)) != (PTE_U | PTE_P))) return -E_INVAL;
+	else return 0;
+}
 
 // Print a string to the system console.
 // The string is exactly 'len' characters long.
@@ -21,7 +43,7 @@ sys_cputs(const char *s, size_t len)
 	// Destroy the environment if not.
 
 	// LAB 3: Your code here.
-
+	user_mem_assert(curenv, (const void *) s, len, PTE_U);
 	// Print the string supplied by the user.
 	cprintf("%.*s", len, s);
 }
@@ -62,6 +84,417 @@ sys_env_destroy(envid_t envid)
 	return 0;
 }
 
+// Deschedule current environment and pick a different one to run.
+static void
+sys_yield(void)
+{
+	sched_yield();
+}
+
+// Allocate a new environment.
+// Returns envid of new environment, or < 0 on error.  Errors are:
+//	-E_NO_FREE_ENV if no free environment is available.
+//	-E_NO_MEM on memory exhaustion.
+static envid_t
+sys_exofork(void)
+{
+	// Create the new environment with env_alloc(), from kern/env.c.
+	// It should be left as env_alloc created it, except that
+	// status is set to ENV_NOT_RUNNABLE, and the register set is copied
+	// from the current environment -- but tweaked so sys_exofork
+	// will appear to return 0.
+
+	// LAB 4: Your code here.
+	struct Env * new_env;
+	// Creamos un nuevo proceso y el padre sera el proceso actual
+	int ret = env_alloc(&new_env, curenv->env_id);
+	// Comprobamos errores de env_alloc
+	if (ret < 0) return (envid_t)ret;
+	// Actualizamos el estado del nuevo proceso
+	new_env->env_status = ENV_NOT_RUNNABLE;
+	// Copiamos el trap frame del padre
+	memcpy(&new_env->env_tf, &curenv->env_tf, sizeof(struct Trapframe));
+	// Forzamos 0 en EAX del hijo asi quien llama a exofork
+	// puede diferenciar entre hijo y padre (pues en EAX esta
+	// lo que devuelve la syscall)
+	new_env->env_tf.tf_regs.reg_eax = 0;
+	// Retornamos el env_id del proceso creado
+	return new_env->env_id;
+}
+
+// Set envid's env_status to status, which must be ENV_RUNNABLE
+// or ENV_NOT_RUNNABLE.
+//
+// Returns 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist,
+//		or the caller doesn't have permission to change envid.
+//	-E_INVAL if status is not a valid status for an environment.
+static int
+sys_env_set_status(envid_t envid, int status)
+{
+	// Hint: Use the 'envid2env' function from kern/env.c to translate an
+	// envid to a struct Env.
+	// You should set envid2env's third argument to 1, which will
+	// check whether the current environment has permission to set
+	// envid's status.
+
+	// LAB 4: Your code here.
+	struct Env * env;
+
+	// Pasamos envid a struct Env
+	// Ponemos el checkeo de permisos en true
+	// que comprueba que el envid pasado
+	// corresponde a currenv o a un hijo 
+	// inmediato de currenv.
+	int ret = envid2env(envid, &env, true);
+
+	// Comprobamos errores
+
+	if (ret < 0) return ret;
+
+	// Comprobamos status a setear validos
+	if (status != ENV_RUNNABLE && status != ENV_NOT_RUNNABLE) return -E_INVAL;
+
+	// Si pasamos las validaciones seteamos el status y retornamos
+	env->env_status = status;
+
+	return 0;
+}
+
+// Set the page fault upcall for 'envid' by modifying the corresponding struct
+// Env's 'env_pgfault_upcall' field.  When 'envid' causes a page fault, the
+// kernel will push a fault record onto the exception stack, then branch to
+// 'func'.
+//
+// Returns 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist,
+//		or the caller doesn't have permission to change envid.
+static int
+sys_env_set_pgfault_upcall(envid_t envid, void *func)
+{
+	// LAB 4: Your code here.
+
+	//Chequeamos errores
+	struct Env * env;
+	if (envid2env(envid, &env, true) < 0) {
+		return -E_BAD_ENV;
+	}
+
+	// Seteamos el handler del usuario para un pgfault del proceso envid
+	env->env_pgfault_upcall = func;
+
+	return 0;
+}
+
+// Allocate a page of memory and map it at 'va' with permission
+// 'perm' in the address space of 'envid'.
+// The page's contents are set to 0.
+// If a page is already mapped at 'va', that page is unmapped as a
+// side effect.
+//
+// perm -- PTE_U | PTE_P must be set, PTE_AVAIL | PTE_W may or may not be set,
+//         but no other bits may be set.  See PTE_SYSCALL in inc/mmu.h.
+//
+// Return 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist,
+//		or the caller doesn't have permission to change envid.
+//	-E_INVAL if va >= UTOP, or va is not page-aligned.
+//	-E_INVAL if perm is inappropriate (see above).
+//	-E_NO_MEM if there's no memory to allocate the new page,
+//		or to allocate any necessary page tables.
+static int
+sys_page_alloc(envid_t envid, void *va, int perm)
+{
+	// Hint: This function is a wrapper around page_alloc() and
+	//   page_insert() from kern/pmap.c.
+	//   Most of the new code you write should be to check the
+	//   parameters for correctness.
+	//   If page_insert() fails, remember to free the page you
+	//   allocated!
+
+	// LAB 4: Your code here.
+	// Variables
+	struct Env * env;
+	struct PageInfo * page;
+
+	// Pasamos envid a struct Env
+	// Y comprobamos de igual manera 
+	// que en sys_env_set_status
+	int error = envid2env(envid, &env, true);
+
+	// Comprobamos errores
+	if (error) return error; // -E_BAD_ENV
+
+	// Validamos va
+	error = check_va(va);
+	if (error) return error;
+	
+	// Validamos permisos
+	error = check_permissions(perm);
+	if (error) return error;
+
+	// Alocamos la pagina y validamos que haya memoria
+	page = page_alloc(ALLOC_ZERO);
+	if (page == NULL) return -E_NO_MEM;
+
+	// Mapeamos la pagina y validamos errores
+	error = page_insert(env->env_pgdir, page, va, perm);
+	if (error) {
+		page_free(page); // Liberamos la pagina (nunca se incremento pp_ref)
+		return error; 	 // -E_NO_MEM
+	}
+
+	// Success
+	return 0;
+}
+
+// Map the page of memory at 'srcva' in srcenvid's address space
+// at 'dstva' in dstenvid's address space with permission 'perm'.
+// Perm has the same restrictions as in sys_page_alloc, except
+// that it also must not grant write access to a read-only
+// page.
+//
+// Return 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if srcenvid and/or dstenvid doesn't currently exist,
+//		or the caller doesn't have permission to change one of them.
+//	-E_INVAL if srcva >= UTOP or srcva is not page-aligned,
+//		or dstva >= UTOP or dstva is not page-aligned.
+//	-E_INVAL is srcva is not mapped in srcenvid's address space.
+//	-E_INVAL if perm is inappropriate (see sys_page_alloc).
+//	-E_INVAL if (perm & PTE_W), but srcva is read-only in srcenvid's
+//		address space.
+//	-E_NO_MEM if there's no memory to allocate any necessary page tables.
+static int
+sys_page_map(envid_t srcenvid, void *srcva, envid_t dstenvid, void *dstva, int perm)
+{
+	// Hint: This function is a wrapper around page_lookup() and
+	//   page_insert() from kern/pmap.c.
+	//   Again, most of the new code you write should be to check the
+	//   parameters for correctness.
+	//   Use the third argument to page_lookup() to
+	//   check the current permissions on the page.
+
+	// LAB 4: Your code here.
+	// Variables
+	struct Env *src_env, *dst_env;
+	struct PageInfo * page;
+	pte_t * pte;
+	int error = 0;
+
+	// Pasamos envid's a struct Env's
+	// Y comprobamos de igual manera 
+	// que en sys_env_set_status
+	error = envid2env(srcenvid, &src_env, true);
+	if (error) return error;
+	error = envid2env(dstenvid, &dst_env, true);
+	if (error) return error;
+
+	// Validamos va's
+	error = check_va(srcva);
+	if (error) return error;
+	error = check_va(dstva);
+	if (error) return error;
+
+	// Validamos que srcva este mapeado en src_env Address Space
+	page = page_lookup(src_env->env_pgdir, srcva, &pte);
+	if (page == NULL) return -E_INVAL;
+
+	// Validamos permisos
+	// Idem page alloc
+	// Validamos permisos
+	error = check_permissions(perm);
+	if (error) return error;
+
+	// Verificamos que no sea una pagina de solo lectura
+	// y se la este intentando mapear con permisos de escritura
+	if (((*pte & PTE_W) == 0) && (perm & PTE_W)) return -E_INVAL;
+
+	// Mapeamos la pagina y validamos errores
+	error = page_insert(dst_env->env_pgdir, page, dstva, perm);
+	if (error) return error; 	 // -E_NO_MEM
+	
+	return 0;
+}
+
+// Unmap the page of memory at 'va' in the address space of 'envid'.
+// If no page is mapped, the function silently succeeds.
+//
+// Return 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist,
+//		or the caller doesn't have permission to change envid.
+//	-E_INVAL if va >= UTOP, or va is not page-aligned.
+static int
+sys_page_unmap(envid_t envid, void *va)
+{
+	// Hint: This function is a wrapper around page_remove().
+
+	// LAB 4: Your code here.
+	// Variables
+	struct Env * env;
+	struct PageInfo * page;
+	int error = 0;
+	error = envid2env(envid, &env, true);
+	if (error) return error;
+
+	// Validamos va
+	error = check_va(va);
+	if (error) return error;
+
+	// Validamos que haya pagina mapeada sino
+	// page_remove podria fallar en page_decref.
+	page = page_lookup(env->env_pgdir, va, NULL);
+	if (page == NULL) return 0; // "silently succeeds"
+
+	// Removemos la pagina
+	page_remove(env->env_pgdir, va);
+
+	return 0;
+}
+
+// Try to send 'value' to the target env 'envid'.
+// If srcva < UTOP, then also send page currently mapped at 'srcva',
+// so that receiver gets a duplicate mapping of the same page.
+//
+// The send fails with a return value of -E_IPC_NOT_RECV if the
+// target is not blocked, waiting for an IPC.
+//
+// The send also can fail for the other reasons listed below.
+//
+// Otherwise, the send succeeds, and the target's ipc fields are
+// updated as follows:
+//    env_ipc_recving is set to 0 to block future sends;
+//    env_ipc_from is set to the sending envid;
+//    env_ipc_value is set to the 'value' parameter;
+//    env_ipc_perm is set to 'perm' if a page was transferred, 0 otherwise.
+// The target environment is marked runnable again, returning 0
+// from the paused sys_ipc_recv system call.  (Hint: does the
+// sys_ipc_recv function ever actually return?)
+//
+// If the sender wants to send a page but the receiver isn't asking for one,
+// then no page mapping is transferred, but no error occurs.
+// The ipc only happens when no errors occur.
+//
+// Returns 0 on success, < 0 on error.
+// Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist.
+//		(No need to check permissions.)
+//	-E_IPC_NOT_RECV if envid is not currently blocked in sys_ipc_recv,
+//		or another environment managed to send first.
+//	-E_INVAL if srcva < UTOP but srcva is not page-aligned.
+//	-E_INVAL if srcva < UTOP and perm is inappropriate
+//		(see sys_page_alloc).
+//	-E_INVAL if srcva < UTOP but srcva is not mapped in the caller's
+//		address space.
+//	-E_INVAL if (perm & PTE_W), but srcva is read-only in the
+//		current environment's address space.
+//	-E_NO_MEM if there's not enough memory to map srcva in envid's
+//		address space.
+static int
+sys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, unsigned perm)
+{
+	// LAB 4: Your code here.
+	struct Env * to_env;
+	bool trans_page = false;
+	int ret = envid2env(envid, &to_env, false);
+	if (ret < 0) {
+		// return -E_BAD_ENV if environment envid doesn't currently exist
+		return -E_BAD_ENV;
+	}
+
+	// The send fails with a return value of -E_IPC_NOT_RECV if the
+	// target is not blocked, waiting for an IPC.
+	if (!to_env->env_ipc_recving) {
+		return -E_IPC_NOT_RECV;
+	}
+
+	if ((uintptr_t)srcva < UTOP || (uintptr_t)to_env->env_ipc_dstva < UTOP) {
+		//-E_INVAL if srcva < UTOP but srcva is not page-aligned.
+		if (((uintptr_t)srcva % PGSIZE) != 0) {
+			return -E_INVAL;
+		}
+		//-E_INVAL if srcva < UTOP and perm is inappropriate
+		ret = check_permissions(perm);
+		if (ret) return -E_INVAL;
+
+		//	-E_INVAL if srcva < UTOP but srcva is not mapped in the caller's
+		pte_t * pte;
+		struct PageInfo * page;
+		if (!(page = page_lookup(curenv->env_pgdir, srcva, &pte))) {
+			return -E_INVAL;
+		}
+		// -E_INVAL if (perm & PTE_W), but srcva is read-only in the current environment's address space.
+		if ((perm & PTE_W) && !(*pte & PTE_W)) {
+			return -E_INVAL;
+		}
+
+		if (page_insert(to_env->env_pgdir, page, to_env->env_ipc_dstva, perm) < 0) {
+			//-E_NO_MEM if there's not enough memory to map srcva in envid's address space.
+			return -E_NO_MEM;
+		}
+
+		trans_page = true;
+	} 
+
+	// Otherwise, the send succeeds, and the target's ipc fields are
+	// updated as follows:
+
+	//    env_ipc_recving is set to 0 to block future sends;
+	to_env->env_ipc_recving = 0;
+	//    env_ipc_from is set to the sending envid;
+	to_env->env_ipc_from = curenv->env_id;
+	//    env_ipc_value is set to the 'value' parameter;
+	to_env->env_ipc_value = value;
+	//    env_ipc_perm is set to 'perm' if a page was transferred, 0 otherwise.
+	if (trans_page) to_env->env_ipc_perm = perm;
+	else to_env->env_ipc_perm = 0;
+	
+	// The target environment is marked runnable again
+	to_env->env_status = ENV_RUNNABLE;
+
+	return 0;
+}
+
+// Block until a value is ready.  Record that you want to receive
+// using the env_ipc_recving and env_ipc_dstva fields of struct Env,
+// mark yourself not runnable, and then give up the CPU.
+//
+// If 'dstva' is < UTOP, then you are willing to receive a page of data.
+// 'dstva' is the virtual address at which the sent page should be mapped.
+//
+// This function only returns on error, but the system call will eventually
+// return 0 on success.
+// Return < 0 on error.  Errors are:
+//	-E_INVAL if dstva < UTOP but dstva is not page-aligned.
+static int
+sys_ipc_recv(void *dstva)
+{
+	// LAB 4: Your code here.
+
+	// Si dstva es < UTOP => Esperamos recibir una página,
+	// En ese caso, validamos que la dirección esté alineada
+	if ((uintptr_t)dstva < UTOP) {
+		if (PGOFF(dstva)) return -E_INVAL;
+	}
+
+	// Indicamos donde queremos recibir la pagina de dato
+	curenv->env_ipc_dstva = dstva;
+
+	// Seteamos el proceso como ENV_NOT_RUNNABLE
+	curenv->env_status = ENV_NOT_RUNNABLE;
+
+	// Ponemos a true el flag env_ipc_recving
+	curenv->env_ipc_recving = true;
+
+	// Como sys_yield() desaloja este proceso y no se llegará a la línea de return 0
+	// Escribimos 0 (éxito) en eax, registro de valor de retorno de esta syscall
+	curenv->env_tf.tf_regs.reg_eax = 0;
+
+	// Salimos de la CPU, no se volverá a entrar hasta que se reciba el mensaje
+	sys_yield();
+	// No retorna
+	return 0;
+}
+
 // Dispatches to the correct kernel function, passing the arguments.
 int32_t
 syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5)
@@ -69,10 +502,50 @@ syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4,
 	// Call the function corresponding to the 'syscallno' parameter.
 	// Return any appropriate return value.
 	// LAB 3: Your code here.
+	switch (syscallno) {
+	case SYS_cputs: {
+		sys_cputs((const char *) a1, (size_t) a2);
+		return 0;
+	}
+	case SYS_cgetc: {
+		return (int32_t) sys_cgetc();
+	}
+	case SYS_getenvid: {
+		return (int32_t) sys_getenvid();
+	}
+	case SYS_env_destroy: {
+		return (int32_t) sys_env_destroy((envid_t) a1);
+	}
+	case SYS_yield: {
+		sys_yield();
+		return 0;
+	}
+	case SYS_exofork: {
+		return (int32_t) sys_exofork();
+	}
+	case SYS_env_set_status: {
+		return (int32_t) sys_env_set_status((envid_t)a1, (int)a2);
+	}
+	case SYS_page_alloc: {
+		return (int32_t) sys_page_alloc((envid_t)a1, (void *)a2, (int)a3);
+	}
+	case SYS_page_map: {
+		return (int32_t) sys_page_map((envid_t)a1, (void *)a2, (envid_t)a3, (void *)a4, (int)a5);
+	}
+	case SYS_page_unmap: {
+		return (int32_t) sys_page_unmap((envid_t)a1, (void *)a2);
+	}
+	case SYS_ipc_recv: {
+		return (int) sys_ipc_recv((void *)a1);
+	}
+	case SYS_ipc_try_send: {
+		return (int) sys_ipc_try_send((envid_t)a1, (uint32_t)a2, (void *)a3, (unsigned)a4);
+	}
 
-	panic("syscall not implemented");
+	case SYS_env_set_pgfault_upcall: {
+		return (int) sys_env_set_pgfault_upcall((envid_t)a1, (void *)a2);
+	}
 
-	switch (syscallno) {
 	default:
 		return -E_INVAL;
 	}
diff --git a/kern/trap.c b/kern/trap.c
index 4e55d15..5c2cc11 100644
--- a/kern/trap.c
+++ b/kern/trap.c
@@ -8,6 +8,11 @@
 #include <kern/monitor.h>
 #include <kern/env.h>
 #include <kern/syscall.h>
+#include <kern/sched.h>
+#include <kern/kclock.h>
+#include <kern/picirq.h>
+#include <kern/cpu.h>
+#include <kern/spinlock.h>
 
 static struct Taskstate ts;
 
@@ -23,6 +28,33 @@ static struct Trapframe *last_tf;
 struct Gatedesc idt[256] = { { 0 } };
 struct Pseudodesc idt_pd = { sizeof(idt) - 1, (uint32_t) idt };
 
+// Declaración de los prototipos de trap
+
+extern void trap_0();
+extern void trap_1();
+
+extern void trap_3();
+extern void trap_4();
+extern void trap_5();
+extern void trap_6();
+extern void trap_7();
+extern void trap_8();
+
+extern void trap_10();
+extern void trap_11();
+extern void trap_12();
+extern void trap_13();
+extern void trap_14();
+
+extern void trap_16();
+extern void trap_17();
+extern void trap_18();
+extern void trap_19();
+extern void trap_20();
+
+extern void trap_32();
+
+extern void trap_48();
 
 static const char *
 trapname(int trapno)
@@ -54,6 +86,8 @@ trapname(int trapno)
 		return excnames[trapno];
 	if (trapno == T_SYSCALL)
 		return "System call";
+	if (trapno >= IRQ_OFFSET && trapno < IRQ_OFFSET + 16)
+		return "Hardware Interrupt";
 	return "(unknown trap)";
 }
 
@@ -65,6 +99,62 @@ trap_init(void)
 
 	// LAB 3: Your code here.
 
+	// Se debe configurar las interrupciones del vector IDT
+	// (Interruption Descriptor Table)
+	// Para eso utilizamos la macro SETGATE
+	// 1er parámetro: Gate. Ejemplo: idt[1]
+	// 2do parámetro: istrap?: En JOS va siempre 0 (para deshabilitar interrupciones
+	//                         dentro de la misma interrupción).
+	// 3er parámetro: selector de code segment para buscar el handler de la interrupción
+	//                En este caso será el text segment del kernel (macro GD_KT)
+	// 4to parámetro: offset dentro del code segment para buscar el handler
+	// 5to parámetro: Descriptor privilege level. En todo caso sera 0 (ring 0 para kernel)
+
+	// DIVIDE ERROR #DE
+	SETGATE(idt[T_DIVIDE], 0, GD_KT, trap_0, 0);
+	// DEBUG EXCEPTION
+	SETGATE(idt[T_DEBUG], 0, GD_KT, trap_1, 0);
+
+	// Breakpoint (En la tarea kern_interrupts se indica que debe
+	//				poder ser disparada por usuario RING 3)
+	SETGATE(idt[T_BRKPT], 0, GD_KT, trap_3, 3);
+	// Overflow
+	SETGATE(idt[T_OFLOW], 0, GD_KT, trap_4, 0);
+	// Bound Range Exceded
+	SETGATE(idt[T_BOUND], 0, GD_KT, trap_5, 0);
+	// Invalid Opcode
+	SETGATE(idt[T_ILLOP], 0, GD_KT, trap_6, 0);
+	// Device Not Available
+	SETGATE(idt[T_DEVICE], 0, GD_KT, trap_7, 0);
+	// Double Fault
+	SETGATE(idt[T_DBLFLT], 0, GD_KT, trap_8, 0);
+	// Invalid TSS
+	SETGATE(idt[T_TSS], 0, GD_KT, trap_10, 0);
+	// Segment Not Present
+	SETGATE(idt[T_SEGNP], 0, GD_KT, trap_11, 0);
+	// Stack-Segment Fault
+	SETGATE(idt[T_STACK], 0, GD_KT, trap_12, 0);
+	// General Protection
+	SETGATE(idt[T_GPFLT], 0, GD_KT, trap_13, 0);
+	// Page Fault
+	SETGATE(idt[T_PGFLT], 0, GD_KT, trap_14, 0);
+	// x87 FPU Floating-Point Error (Math Fault)
+	SETGATE(idt[T_FPERR], 0, GD_KT, trap_16, 0);
+	// Alignment Check
+	SETGATE(idt[T_ALIGN], 0, GD_KT, trap_17, 0);
+	// Machine ChecK
+	SETGATE(idt[T_MCHK], 0, GD_KT, trap_18, 0);
+	// SIMD Floating-Point Exception
+	SETGATE(idt[T_SIMDERR], 0, GD_KT, trap_19, 0);
+	// Virtualization Exception
+	SETGATE(idt[20], 0, GD_KT, trap_20, 0);
+
+	// Timer interruption
+	SETGATE(idt[IRQ_OFFSET + IRQ_TIMER], 0, GD_KT, trap_32, 0);
+
+	// SYSCALL interrupt
+	SETGATE(idt[48], 0, GD_KT, trap_48, 3);
+
 	// Per-CPU setup
 	trap_init_percpu();
 }
@@ -73,28 +163,86 @@ trap_init(void)
 void
 trap_init_percpu(void)
 {
+	// The example code here sets up the Task State Segment (TSS) and
+	// the TSS descriptor for CPU 0. But it is incorrect if we are
+	// running on other CPUs because each CPU has its own kernel stack.
+	// Fix the code so that it works for all CPUs.
+	//
+	// Hints:
+	//   - The macro "thiscpu" always refers to the current CPU's
+	//     struct CpuInfo;
+	//   - The ID of the current CPU is given by cpunum() or
+	//     thiscpu->cpu_id;
+	//   - Use "thiscpu->cpu_ts" as the TSS for the current CPU,
+	//     rather than the global "ts" variable;
+	//   - Use gdt[(GD_TSS0 >> 3) + i] for CPU i's TSS descriptor;
+	//   - You mapped the per-CPU kernel stacks in mem_init_mp()
+	//
+	// ltr sets a 'busy' flag in the TSS selector, so if you
+	// accidentally load the same TSS on more than one CPU, you'll
+	// get a triple fault.  If you set up an individual CPU's TSS
+	// wrong, you may not get a fault until you try to return from
+	// user space on that CPU.
+	//
+	// LAB 4: Your code here:
+
+	// Obtenemos el cpunum (0 para cpu 1, 1 para cpu 2, etc...)
+	int cpuid = cpunum();
+	// Obtenenemos el struct cpuinfo del cpu en cuestión
+	struct CpuInfo * curcpu = &(cpus[cpuid]);
+	// De dicho cpu obtenemos la estructura Taskstate (que representa la TSS)
+	struct Taskstate * curts = &(curcpu->cpu_ts);
+
+	// Calculamos el indice del task segment del core en cuestión
+	uint16_t idx = (GD_TSS0 >> 3) + cpuid;
+	// Caklculamos el segmento del core en cuestión
+	uint16_t seg = idx << 3;
+
+	// El campo ts->ts_ss0 seguirá apuntando a GD_KD
+	curts->ts_ss0 = GD_KD;
+
+	// Al igual que en mem_init_mp() calculamos la dirección virtual del stack del cpu en cuestión
+	uintptr_t kstacktop_i = KSTACKTOP - cpuid * (KSTKSIZE + KSTKGAP);
+
+	// ts->ts_esp0 deberá inicializarse de manera dinámica según el valor de cpunum()
+	curts->ts_esp0 = kstacktop_i;
+
+	// Adecuación al nuevo esquema:
+
+	curts->ts_iomb = sizeof(struct Taskstate);
+
+	gdt[idx] = SEG16(STS_T32A, (uint32_t)(curts), sizeof(struct Taskstate) - 1, 0);
+
+	gdt[idx].sd_s = 0;
+
+
+	ltr(seg);
+
+	lidt(&idt_pd);
+
 	// Setup a TSS so that we get the right stack
 	// when we trap to the kernel.
-	ts.ts_esp0 = KSTACKTOP;
-	ts.ts_ss0 = GD_KD;
+	// ts.ts_esp0 = KSTACKTOP;
+	// ts.ts_ss0 = GD_KD;
+	// ts.ts_iomb = sizeof(struct Taskstate);
 
 	// Initialize the TSS slot of the gdt.
-	gdt[GD_TSS0 >> 3] =
-	        SEG16(STS_T32A, (uint32_t)(&ts), sizeof(struct Taskstate) - 1, 0);
-	gdt[GD_TSS0 >> 3].sd_s = 0;
+	// gdt[GD_TSS0 >> 3] =
+	//        SEG16(STS_T32A, (uint32_t)(&ts), sizeof(struct Taskstate) - 1, 0);
+	// gdt[GD_TSS0 >> 3].sd_s = 0;
 
 	// Load the TSS selector (like other segment selectors, the
 	// bottom three bits are special; we leave them 0)
-	ltr(GD_TSS0);
+	//ltr(GD_TSS0);
 
 	// Load the IDT
-	lidt(&idt_pd);
+	//lidt(&idt_pd);
 }
 
 void
 print_trapframe(struct Trapframe *tf)
 {
-	cprintf("TRAP frame at %p\n", tf);
+	cprintf("TRAP frame at %p from CPU %d\n", tf, cpunum());
 	print_regs(&tf->tf_regs);
 	cprintf("  es   0x----%04x\n", tf->tf_es);
 	cprintf("  ds   0x----%04x\n", tf->tf_ds);
@@ -137,12 +285,68 @@ print_regs(struct PushRegs *regs)
 	cprintf("  eax  0x%08x\n", regs->reg_eax);
 }
 
+
+/*
+trap_dispatch() va a tener un switch para cada excepcion posible:
+        switch (tf->tf_trapno) {
+                case t_syscall....
+        }
+
+En este switch vamos a tener manejadores para el T_BRKPT y para T_PGFLT
+(breakpoint y page fault), para el resto nose hará nada y se volverá al
+proceso original.
+
+Además, la excepción de breakpoint se debe poder lanzar desde programas de usuario.
+En general, esta excepción se usa para implementar el depurado de código.
+-> Para esto se debe modificar este gate en trap init.
+*/
 static void
 trap_dispatch(struct Trapframe *tf)
 {
 	// Handle processor exceptions.
 	// LAB 3: Your code here.
 
+	switch (tf->tf_trapno) {
+	case T_BRKPT: {
+		monitor(tf);
+		return;
+	}
+	case T_PGFLT: {
+		page_fault_handler(tf);
+		return;
+	}
+	case IRQ_OFFSET + IRQ_TIMER: {
+		lapic_eoi(); 		// Avisamos al hardware que atrapamos la interrupcion
+		sched_yield(); 	// Actuamos en consecuencia de la interrupcion (round-robin)
+		return;
+	}
+	case T_SYSCALL: {
+		uint32_t ret = syscall(tf->tf_regs.reg_eax,  // Syscall number
+		                       tf->tf_regs.reg_edx,  // 1st argument
+		                       tf->tf_regs.reg_ecx,  // 2nd argument
+		                       tf->tf_regs.reg_ebx,  // 3rd argument
+		                       tf->tf_regs.reg_edi,  // 4th argument
+		                       tf->tf_regs.reg_esi   // 5th argument
+		);
+		tf->tf_regs.reg_eax = ret;  // Return value should be put in %eax
+		return;
+	}
+	default:
+		break;
+	}
+	// Handle spurious interrupts
+	// The hardware sometimes raises these because of noise on the
+	// IRQ line or other reasons. We don't care.
+	if (tf->tf_trapno == IRQ_OFFSET + IRQ_SPURIOUS) {
+		cprintf("Spurious interrupt on irq 7\n");
+		print_trapframe(tf);
+		return;
+	}
+
+	// Handle clock interrupts. Don't forget to acknowledge the
+	// interrupt using lapic_eoi() before calling the scheduler!
+	// LAB 4: Your code here.
+
 	// Unexpected trap: The user process or the kernel has a bug.
 	print_trapframe(tf);
 	if (tf->tf_cs == GD_KT)
@@ -160,17 +364,35 @@ trap(struct Trapframe *tf)
 	// of GCC rely on DF being clear
 	asm volatile("cld" ::: "cc");
 
+	// Halt the CPU if some other CPU has called panic()
+	extern char *panicstr;
+	if (panicstr)
+		asm volatile("hlt");
+
+	// Re-acquire the big kernel lock if we were halted in
+	// sched_yield()
+	if (xchg(&thiscpu->cpu_status, CPU_STARTED) == CPU_HALTED)
+		lock_kernel();
 	// Check that interrupts are disabled.  If this assertion
 	// fails, DO NOT be tempted to fix it by inserting a "cli" in
 	// the interrupt path.
 	assert(!(read_eflags() & FL_IF));
 
-	cprintf("Incoming TRAP frame at %p\n", tf);
-
 	if ((tf->tf_cs & 3) == 3) {
 		// Trapped from user mode.
+		// Acquire the big kernel lock before doing any
+		// serious kernel work.
+		// LAB 4: Your code here.
+		lock_kernel();
 		assert(curenv);
 
+		// Garbage collect if current enviroment is a zombie
+		if (curenv->env_status == ENV_DYING) {
+			env_free(curenv);
+			curenv = NULL;
+			sched_yield();
+		}
+
 		// Copy trap frame (which is currently on the stack)
 		// into 'curenv->env_tf', so that running the environment
 		// will restart at the trap point.
@@ -186,9 +408,13 @@ trap(struct Trapframe *tf)
 	// Dispatch based on what type of trap occurred
 	trap_dispatch(tf);
 
-	// Return to the current environment, which should be running.
-	assert(curenv && curenv->env_status == ENV_RUNNING);
-	env_run(curenv);
+	// If we made it to this point, then no other environment was
+	// scheduled, so we should return to the current environment
+	// if doing so makes sense.
+	if (curenv && curenv->env_status == ENV_RUNNING)
+		env_run(curenv);
+	else
+		sched_yield();
 }
 
 
@@ -203,10 +429,93 @@ page_fault_handler(struct Trapframe *tf)
 	// Handle kernel-mode page faults.
 
 	// LAB 3: Your code here.
+	if (tf->tf_cs == GD_KT) {
+		panic("[%08x] kernel fault va %08x ip %08x\n",
+		      curenv->env_id,
+		      fault_va,
+		      tf->tf_eip);
+	}
 
 	// We've already handled kernel-mode exceptions, so if we get here,
 	// the page fault happened in user mode.
 
+	// Call the environment's page fault upcall, if one exists.  Set up a
+	// page fault stack frame on the user exception stack (below
+	// UXSTACKTOP), then branch to curenv->env_pgfault_upcall.
+	//
+	// The page fault upcall might cause another page fault, in which case
+	// we branch to the page fault upcall recursively, pushing another
+	// page fault stack frame on top of the user exception stack.
+	//
+	// The trap handler needs one word of scratch space at the top of the
+	// trap-time stack in order to return.  In the non-recursive case, we
+	// don't have to worry about this because the top of the regular user
+	// stack is free.  In the recursive case, this means we have to leave
+	// an extra word between the current top of the exception stack and
+	// the new stack frame because the exception stack _is_ the trap-time
+	// stack.
+	//
+	// If there's no page fault upcall, the environment didn't allocate a
+	// page for its exception stack or can't write to it, or the exception
+	// stack overflows, then destroy the environment that caused the fault.
+	// Note that the grade script assumes you will first check for the page
+	// fault upcall and print the "user fault va" message below if there is
+	// none.  The remaining three checks can be combined into a single test.
+	//
+	// Hints:
+	//   user_mem_assert() and env_run() are useful here.
+	//   To change what the user environment runs, modify 'curenv->env_tf'
+	//   (the 'tf' variable points at 'curenv->env_tf').
+
+	// LAB 4: Your code here.
+
+	// Si el environment tenia configurado un handler de Page Fault...
+	if (curenv->env_pgfault_upcall) {
+		struct UTrapframe *u;
+
+		// Si es una llamada recursiva entonces el esp estará dentro del rango de [UXSTACKTOP; UXSTACKTOP-PGSIZE)
+		bool recursive = ((tf->tf_esp < UXSTACKTOP) && (tf->tf_esp >= UXSTACKTOP-PGSIZE)) ? true : false;
+	
+		if (recursive) {
+			// Si es llamada recursiva, debemos dejar una palabra en blanco (4 bytes) entre el UTrapFrame
+			// Anterior y el nuevo
+			u = (struct UTrapframe *) (tf->tf_esp - 4 - sizeof(struct UTrapframe));
+			// Chequeamos que tengamos permisos para escribir el UTrapFrame en el stack
+			// Y el word (4 bytes adicionales) en blanco para distinguir llamada recursiva
+			user_mem_assert(curenv, (void *) u, sizeof(struct UTrapframe) + 4, PTE_W | PTE_P);
+		} else {
+			// Si no es llamada recursiva, se debe escribir un UTrapFrame en UXSTACKTOP
+			u = (struct UTrapframe *) (UXSTACKTOP - sizeof(struct UTrapframe)); 
+			user_mem_assert(curenv, (void *) u, sizeof(struct UTrapframe), PTE_W | PTE_P);
+		}
+
+		// Chequeamos que el handler de usuario sea accesible para el usuario
+		user_mem_assert(curenv, (void *) curenv->env_pgfault_upcall, 4, PTE_P);
+		
+		// Completamos el UTrapFrame copiando desde tf
+		u->utf_fault_va = fault_va;
+		u->utf_err = tf->tf_err;
+		u->utf_regs = tf->tf_regs;
+		u->utf_eflags = tf->tf_eflags;
+		u->utf_eip = tf->tf_eip;
+		u->utf_esp = tf->tf_esp;
+
+		// Si es recursivo escribimos el ultimo byte en 0
+		if (recursive) {
+			uintptr_t * aux = (uintptr_t *) u;
+			aux += sizeof(struct UTrapframe);
+			*aux = 0;
+		}
+
+		// Cambiar a donde se va a ejecutar el proceso cuando volvamos a él:
+		tf->tf_eip = (uintptr_t) curenv->env_pgfault_upcall;
+		tf->tf_esp = (uintptr_t) u;
+
+		env_run(curenv);
+
+		return;
+	}
+
 	// Destroy the environment that caused the fault.
 	cprintf("[%08x] user fault va %08x ip %08x\n",
 	        curenv->env_id,
@@ -214,4 +523,6 @@ page_fault_handler(struct Trapframe *tf)
 	        tf->tf_eip);
 	print_trapframe(tf);
 	env_destroy(curenv);
+
+	return;
 }
diff --git a/kern/trapentry.S b/kern/trapentry.S
index 22fc640..fcf5080 100644
--- a/kern/trapentry.S
+++ b/kern/trapentry.S
@@ -4,6 +4,7 @@
 #include <inc/memlayout.h>
 #include <inc/trap.h>
 
+#include <kern/picirq.h>
 
 
 ###################################################################
@@ -47,9 +48,66 @@
  * Lab 3: Your code here for generating entry points for the different traps.
  */
 
+TRAPHANDLER_NOEC(trap_0, T_DIVIDE)
+TRAPHANDLER_NOEC(trap_1, T_DEBUG)
+
+TRAPHANDLER_NOEC(trap_3, T_BRKPT)
+TRAPHANDLER_NOEC(trap_4, T_OFLOW)
+TRAPHANDLER_NOEC(trap_5, T_BOUND)
+TRAPHANDLER_NOEC(trap_6, T_ILLOP)
+TRAPHANDLER_NOEC(trap_7, T_DEVICE)
+TRAPHANDLER(trap_8, T_DBLFLT)
+
+TRAPHANDLER(trap_10, T_TSS)
+TRAPHANDLER(trap_11, T_SEGNP)
+TRAPHANDLER(trap_12, T_STACK)
+TRAPHANDLER(trap_13, T_GPFLT)
+TRAPHANDLER(trap_14, T_PGFLT)
+
+TRAPHANDLER_NOEC(trap_16, T_PGFLT)
+TRAPHANDLER(trap_17, T_ALIGN)
+TRAPHANDLER_NOEC(trap_18, T_MCHK)
+TRAPHANDLER_NOEC(trap_19, T_SIMDERR)
+TRAPHANDLER_NOEC(trap_20, 20)
+
+TRAPHANDLER_NOEC(trap_32, IRQ_OFFSET + IRQ_TIMER)
+TRAPHANDLER_NOEC(trap_48, T_SYSCALL)
 
 
 /*
  * Lab 3: Your code here for _alltraps
  */
 
+_alltraps:
+	/* push values to make the stack look like a struct Trapframe */
+	/* Tener en cuenta que el CPU al recibir una interrupción con cambio de privilegios
+	   automáticamente hace un push al stack de SS, ESP, EFLAGS, CS, EIP y Error Code 
+	   En el TRAPHANDLER, antes de llamar a _alltraps, se hizo push de trapno
+	   Por lo tanto hay que pushear en este orden: ds, es y los registros de proposito general */
+	
+	pushl	%ds
+	pushl	%es
+	pushal		/* Lo contrario al popal de env_pop_tf */
+
+	/* load GD_KD into %ds and %es 
+	Ayuda: cargar GD_KD en %ds y %es mediante un registro intermedio de 16 bits 
+	(por ejemplo, %ax). Considerar, además, que GD_KD es una constante numérica, 
+	no una dirección de memoria (‘mov $GD_KD’ vs ‘mov GD_KD’).	
+	*/
+
+	mov $GD_KT, %ax
+	mov %ax, %ds
+	mov %ax, %es
+
+	/* pushl %esp to pass a pointer to the Trapframe as an argument to trap() */
+
+	pushl %esp
+
+	/* call trap */
+	call trap
+	
+
+	
+
+	
+
diff --git a/lib/Makefrag b/lib/Makefrag
index 2f80706..7710df3 100644
--- a/lib/Makefrag
+++ b/lib/Makefrag
@@ -10,6 +10,11 @@ LIB_SRCFILES :=		lib/console.c \
 			lib/string.c \
 			lib/syscall.c
 
+LIB_SRCFILES :=		$(LIB_SRCFILES) \
+			lib/pgfault.c \
+			lib/pfentry.S \
+			lib/fork.c \
+			lib/ipc.c
 
 
 
diff --git a/lib/console.c b/lib/console.c
index 8856873..1307993 100644
--- a/lib/console.c
+++ b/lib/console.c
@@ -18,7 +18,7 @@ getchar(void)
 	int r;
 	// sys_cgetc does not block, but getchar should.
 	while ((r = sys_cgetc()) == 0)
-		;
+		sys_yield();
 	return r;
 }
 
diff --git a/lib/fork.c b/lib/fork.c
new file mode 100644
index 0000000..4c289db
--- /dev/null
+++ b/lib/fork.c
@@ -0,0 +1,302 @@
+// implement fork from user space
+
+#include <inc/string.h>
+#include <inc/lib.h>
+
+// PTE_COW marks copy-on-write page table entries.
+// It is one of the bits explicitly allocated to user processes (PTE_AVAIL).
+#define PTE_COW 0x800
+
+//
+// Custom page fault handler - if faulting page is copy-on-write,
+// map in our own private writable copy.
+//
+static void
+pgfault(struct UTrapframe *utf)
+{
+	void *addr = (void *) utf->utf_fault_va;
+	uint32_t err = utf->utf_err;
+	int r;
+
+	// Check that the faulting access was (1) a write, and (2) to a
+	// copy-on-write page.  If not, panic.
+	// Hint:
+	//   Use the read-only page table mappings at uvpt
+	//   (see <inc/memlayout.h>).
+
+	// LAB 4: Your code here.
+  // Recuperamos la PTE en cuestión
+  pte_t pte = uvpt[PGNUM(addr)];
+  
+  // Verificamos que la página esté mapeada
+  if ((err & FEC_PR) == 0) panic("[pgfault] pgfault por página no mapeada");
+
+  // Verificamos que el page fault no haya sido por una lectura
+  if ((err & FEC_WR) == 0) panic("[pgfault] pgfault por lectura");
+
+  // Verificamos que la página tenga copy-on-write
+  if ((pte & PTE_COW) == 0) panic("[pgfault] pgfault COW no configurado");
+
+	// Allocate a new page, map it at a temporary location (PFTEMP),
+	// copy the data from the old page to the new page, then move the new
+	// page to the old page's address.
+	// Hint:
+	//   You should make three system calls.
+
+	// LAB 4: Your code here.
+
+  // Alocamos una nueva página en PFTEMP
+  r = sys_page_alloc(0, PFTEMP, PTE_W | PTE_U | PTE_P);
+  if (r) panic("[pgfault] sys_page_alloc failed: %e", r);
+
+  // Alineamos y copiamos el contenido de la página
+  addr = (void *)ROUNDDOWN(addr, PGSIZE);
+  memmove(PFTEMP, addr, PGSIZE);
+
+  // Re-mapeamos correctamente
+  r = sys_page_map(0, PFTEMP, 0, addr, PTE_W | PTE_U | PTE_P);
+  if (r) panic("[pgfault] sys_page_map failed: %e", r);
+}
+
+//
+// Map our virtual page pn (address pn*PGSIZE) into the target envid
+// at the same virtual address.  If the page is writable or copy-on-write,
+// the new mapping must be created copy-on-write, and then our mapping must be
+// marked copy-on-write as well.  (Exercise: Why do we need to mark ours
+// copy-on-write again if it was already copy-on-write at the beginning of
+// this function?)
+//
+// Returns: 0 on success, < 0 on error.
+// It is also OK to panic on error.
+//
+static int
+duppage(envid_t envid, unsigned pn)
+{
+	int r;
+
+	// LAB 4: Your code here.
+
+  // Recuperamos la PTE asociada
+  pte_t pte = uvpt[pn];
+
+  // Reconstruimos la dirección de memoria virtual
+  void * va = (void *)(pn << PTXSHIFT);
+
+  // Si la página era de escritura o tenía copy on write
+  if ((pte & PTE_W) || (pte & PTE_COW)) {
+    // Mapeamos la página en el hijo sin PTE_W
+    r = sys_page_map(0, va, envid, va, PTE_COW | PTE_U | PTE_P);
+    if (r) panic("[duppage] sys_page_map: %e", r);
+
+    // Re-mapeamos la página en el padre sin PTE_W
+    r = sys_page_map(0, va, 0, va, PTE_COW | PTE_U | PTE_P);
+    if (r) panic("[duppage] sys_page_map: %e", r);
+  } else {
+    // Si es una pagina de solo lectura simplemente la compartimos
+    r = sys_page_map(0, va, envid, va, PTE_U | PTE_P);
+    if (r) panic("[duppage] sys_page_map: %e", r);
+  }
+
+	return 0;
+}
+
+static void
+dup_or_share(envid_t dstenv, void *va, int perm) {
+	int r;
+
+	// Si la pagina es de escritura
+	// debemos crear una copia, de igual
+	// manera que en duppage de dumbfork
+	if (perm & PTE_W) {
+		// Aloca una pagina para el proceso hijo (dstenv)
+		// y la mapea en addr, con permisos de escritura
+		if ((r = sys_page_alloc(dstenv, va, perm)) < 0)
+			panic("[dup_or_share] sys_page_alloc: %e", r);
+
+		// Mapea la pagina del hijo previamente alocada (addr de dstenv)
+		// en el proceso padre (0 = currenv = proceso padre) en la direccion UTEMP
+		if ((r = sys_page_map(dstenv, va, 0, UTEMP, perm)) < 0)
+			panic("[dup_or_share] sys_page_map: %e", r);
+		
+		// Copia el contenido de la pagina addr (del padre)
+		// en UTEMP (del padre) que esta mapeada con addr (del hijo)
+		// Es decir esta copiando el contenido padre de addr en 
+		// la pagina del hijo (copia del A.S.)
+		memmove(UTEMP, va, PGSIZE);
+
+		// Desmapea el mapeo previo (fue temporal) ya que
+		// solo tenia como objetivo poder copiar el contenido
+		// de la pagina padre a una mapeada con el hijo
+		// (es el modo de copiar el AS al padre al hijo)
+		// por ello el mapeo ya no es necesario
+		// 0 = currenv = padre
+		if ((r = sys_page_unmap(0, UTEMP)) < 0)
+			panic("[dup_or_share] sys_page_unmap: %e", r);
+	} else {
+		// Si la pagina es de solo lectura la compartimos
+		if ((r = sys_page_map(0, va, dstenv, va, perm)) < 0)
+			panic("[dup_or_share] sys_page_map: %e", r);
+	}
+}
+
+/*
+Es muy parecido a dumbfork() ambos realizan las siguientes operaciones:
+ + Una llamada a sys_exofork (syscall para crear proceso hijo)
+ + En el padre devuelve el id del proceso creado, y 0 en el hijo
+ + Ante errores se invoca a panic()
+ + Poner al hijo como RUNNEABLE
+
+Pero hacen cosas ligeramente diferentes:
+ + dumbfork() llama a la función duppage, que copia de manera "boba" las paginas del padre al hijo
+ + fork_v0() llama a dup_or_share()
+
+*/
+
+envid_t
+fork_v0(void)
+{
+	envid_t envid;
+	uintptr_t addr;
+	int r;
+
+	// Creamos un proceso nuevo
+	// El kernel copia los registros y 
+	// continua desde aqui tanto para padre 
+	// (envid > 0 (envid del hijo)) 
+	// como para el hijo (envid = 0).
+	envid = sys_exofork();
+	if (envid < 0)
+		panic("[fork_v0] sys_exofork failed: %e", envid);
+	if (envid == 0) {
+		// Si envid es 0 entonces el proceso
+		// es el hijo, corregimos la variable 
+		// thisenv y retornamos
+		thisenv = &envs[ENVX(sys_getenvid())];
+		return 0;
+	}
+
+	// Si envid > 0, somos el padre y envid tenemos el id del hijo
+	// Procesamos las paginas de memoria de 0 a UTOP
+	// Si la pagina esta mapeada invocamos a dup_or_share()
+	for (addr = 0; addr < UTOP; addr += PGSIZE) {
+		// Recuperamos el page directory entry
+		pde_t pde = uvpd[PDX(addr)];
+
+		// Checkeamos que el Page directory este mapeado
+		if (pde & PTE_P) {
+			pte_t pte = uvpt[PGNUM(addr)];
+
+			// Checkeamos que la page table entry este mapeada
+			if (pte & PTE_P) {
+				// Como la pagina esta mapeada, llamamos a dup_or_share
+				dup_or_share(envid, (void*)addr, pte & PTE_SYSCALL);
+			} 
+		}
+	}
+
+	// Seteamos el proceso hijo como runneable
+	if ((r = sys_env_set_status(envid, ENV_RUNNABLE)) < 0)
+		panic("[fork_v0] sys_env_set_status: %e", r);
+
+	return envid;
+}
+
+//
+// User-level fork with copy-on-write.
+// Set up our page fault handler appropriately.
+// Create a child.
+// Copy our address space and page fault handler setup to the child.
+// Then mark the child as runnable and return.
+//
+// Returns: child's envid to the parent, 0 to the child, < 0 on error.
+// It is also OK to panic on error.
+//
+// Hint:
+//   Use uvpd, uvpt, and duppage.
+//   Remember to fix "thisenv" in the child process.
+//   Neither user exception stack should ever be marked copy-on-write,
+//   so you must allocate a new page for the child's user exception stack.
+//
+envid_t
+fork(void)
+{
+	// LAB 4: Your code here.
+  int error;
+
+  // Configuramos pgfault como el handler del padre
+  // Esto tambien reserva memoria para su pila de excepciones
+	set_pgfault_handler(pgfault);
+
+  // Creamos el proceso hijo y validamos correctamente
+  envid_t envid = sys_exofork();
+  if (envid < 0) panic("[fork] sys_exofork failed: %e", envid);
+
+  if (envid == 0) {
+		// Si envid es 0 entonces el proceso
+		// es el hijo, corregimos la variable 
+		// thisenv y retornamos
+		thisenv = &envs[ENVX(sys_getenvid())];
+		return 0;
+	} else {
+    // Es el proceso padre
+    // Usamos indices para poder iterar
+    // sobre la cantidad minima de paginas posibles
+    size_t pdx;
+    size_t ptx;
+
+    // Procesamos las paginas de memoria de 0 a UTOP
+    // Si la pagina esta mapeada invocamos a dup_or_share()
+    for (pdx = 0 ; pdx < PDX(UTOP) ; pdx++) {
+      // Recuperamos el page directory entry
+      pde_t pde = uvpd[pdx];
+
+      // Verificamos que la Page Table este alocada
+      // caso contrario la ignoramos y continuamos con la siguiente
+      if ((pde & PTE_P) == 0) continue;
+
+      // Si está alocada recorremos las 1024 PTE,
+      // copiando las páginas alocadas.
+      for (ptx = 0 ; ptx < NPTENTRIES ; ptx++) {
+        // Construimos la direccion virtual
+        // Usamos 0 para el offset
+        uintptr_t addr = (uintptr_t)PGADDR(pdx, ptx, 0);
+
+        // Usamos el PGNUM para acceder a uvpt con la VA construida
+        pte_t pte = uvpt[PGNUM(addr)];
+
+        // Si la dirección es el Stack de excepciones
+        // no lo duplicamos sino que alocamos una nueva página
+        // para el proceso hijo
+        if (addr == (UXSTACKTOP - PGSIZE)) {
+          error = sys_page_alloc(envid, (void *)addr, PTE_W | PTE_U | PTE_P);
+          if (error) panic("[fork] sys_page_alloc failed: %e", error);
+          continue;
+        }
+
+        // Si la página no está alocada la salteamos
+        if ((pte & PTE_P) == 0) continue;
+
+        // Si la página está alocada llamamos a duppage()
+        duppage(envid, PGNUM(addr));
+      }
+    }
+
+    // Configuramos pgfault como el handler del hijo
+    error = sys_env_set_pgfault_upcall(envid, thisenv->env_pgfault_upcall);
+    if (error) panic("[fork] sys_env_set_pgfault_upcall failed: %e", error);
+
+    // Seteamos al proceso hijo como RUNNABLE
+    error = sys_env_set_status(envid, ENV_RUNNABLE);
+    if (error) panic("[fork] sys_env_set_status failed: %e", error);
+
+    return envid;
+  }
+}
+
+// Challenge!
+int
+sfork(void)
+{
+	panic("sfork not implemented");
+	return -E_INVAL;
+}
diff --git a/lib/ipc.c b/lib/ipc.c
new file mode 100644
index 0000000..6765b0f
--- /dev/null
+++ b/lib/ipc.c
@@ -0,0 +1,93 @@
+// User-level IPC library routines
+
+#include <inc/lib.h>
+
+// Receive a value via IPC and return it.
+// If 'pg' is nonnull, then any page sent by the sender will be mapped at
+//	that address.
+// If 'from_env_store' is nonnull, then store the IPC sender's envid in
+//	*from_env_store.
+// If 'perm_store' is nonnull, then store the IPC sender's page permission
+//	in *perm_store (this is nonzero iff a page was successfully
+//	transferred to 'pg').
+// If the system call fails, then store 0 in *fromenv and *perm (if
+//	they're nonnull) and return the error.
+// Otherwise, return the value sent by the sender
+//
+// Hint:
+//   Use 'thisenv' to discover the value and who sent it.
+//   If 'pg' is null, pass sys_ipc_recv a value that it will understand
+//   as meaning "no page".  (Zero is not the right value, since that's
+//   a perfectly valid place to map a page.)
+int32_t
+ipc_recv(envid_t *from_env_store, void *pg, int *perm_store)
+{
+	// LAB 4: Your code here.
+	
+	// No se espera recibir una página
+	// Cualquier dirección por mayor o igual a UTOP
+	// es interpretado por sys_ipc_recv como que
+	// no se espera una página.
+	if (!pg) pg = (void *) UTOP;
+
+	int ret = sys_ipc_recv(pg);
+	if (ret < 0) {
+		// Syscall con error
+		if (from_env_store) *from_env_store = 0;
+		if (perm_store) *perm_store = 0;
+		return ret;
+	}
+
+	// Syscall exitosa
+
+	// If 'from_env_store' is nonnull, then store the IPC sender's envid in *from_env_store.
+	if (from_env_store) *from_env_store = thisenv->env_ipc_from;
+	// If 'perm_store' is nonnull, then store the IPC sender's page permission in *perm_store
+	if (perm_store) *perm_store = thisenv->env_ipc_perm;	
+	// Return the value sent by the sender
+	return thisenv->env_ipc_value;
+}
+
+// Send 'val' (and 'pg' with 'perm', if 'pg' is nonnull) to 'toenv'.
+// This function keeps trying until it succeeds.
+// It should panic() on any error other than -E_IPC_NOT_RECV.
+//
+// Hint:
+//   Use sys_yield() to be CPU-friendly.
+//   If 'pg' is null, pass sys_ipc_try_send a value that it will understand
+//   as meaning "no page".  (Zero is not the right value.)
+void
+ipc_send(envid_t to_env, uint32_t val, void *pg, int perm)
+{
+	// LAB 4: Your code here.
+
+	// Si pg es NULL, le pasaremos a sys_ipc_try_send un valor que entenderá que
+	// significa "no page"
+	if (!pg) {
+		pg = (void *)UTOP;
+	}
+
+	int ret;
+	while ((ret = sys_ipc_try_send(to_env, val, pg, perm)) == -E_IPC_NOT_RECV) {
+		// Usamos sys_yield() para ser CPU-Friendly
+		sys_yield();
+	}
+
+	if (ret < 0) {
+		// En cualquier error que no sea -E_IPC_NOT_RECV va a paniquear.
+		panic("sys_ipc_try_send error: %d \n", ret);
+	}
+}
+
+// Find the first environment of the given type.  We'll use this to
+// find special environments.
+// Returns 0 if no such environment exists.
+envid_t
+ipc_find_env(enum EnvType type)
+{
+	int i;
+	for (i = 0; i < NENV; i++)
+		if (envs[i].env_type == type)
+			return envs[i].env_id;
+	return 0;
+}
diff --git a/lib/libmain.c b/lib/libmain.c
index 834edf8..275c24f 100644
--- a/lib/libmain.c
+++ b/lib/libmain.c
@@ -13,7 +13,9 @@ libmain(int argc, char **argv)
 {
 	// set thisenv to point at our Env structure in envs[].
 	// LAB 3: Your code here.
-	thisenv = 0;
+	envid_t id = sys_getenvid();
+	if (id >= 0)
+		thisenv = &envs[ENVX(id)];
 
 	// save the name of the program so that panic() can use it
 	if (argc > 0)
diff --git a/lib/pfentry.S b/lib/pfentry.S
new file mode 100644
index 0000000..06a17ad
--- /dev/null
+++ b/lib/pfentry.S
@@ -0,0 +1,116 @@
+#include <inc/mmu.h>
+#include <inc/memlayout.h>
+
+// Page fault upcall entrypoint.
+
+// This is where we ask the kernel to redirect us to whenever we cause
+// a page fault in user space (see the call to sys_set_pgfault_handler
+// in pgfault.c).
+//
+// When a page fault actually occurs, the kernel switches our ESP to
+// point to the user exception stack if we're not already on the user
+// exception stack, and then it pushes a UTrapframe onto our user
+// exception stack:
+//
+//	trap-time esp
+//	trap-time eflags
+//	trap-time eip
+//	utf_regs.reg_eax
+//	...
+//	utf_regs.reg_esi
+//	utf_regs.reg_edi
+//	utf_err (error code)
+//	utf_fault_va            <-- %esp
+//
+// If this is a recursive fault, the kernel will reserve for us a
+// blank word above the trap-time esp for scratch work when we unwind
+// the recursive call.
+//
+// We then have call up to the appropriate page fault handler in C
+// code, pointed to by the global variable '_pgfault_handler'.
+
+.text
+.globl _pgfault_upcall
+_pgfault_upcall:
+	// Call the C page fault handler.
+	pushl %esp			// function argument: pointer to UTF
+	movl _pgfault_handler, %eax
+	call *%eax
+	addl $4, %esp			// pop function argument
+	
+	// Now the C page fault handler has returned and you must return
+	// to the trap time state.
+	// Push trap-time %eip onto the trap-time stack.
+	//
+	// Explanation:
+	//   We must prepare the trap-time stack for our eventual return to
+	//   re-execute the instruction that faulted.
+	//   Unfortunately, we can't return directly from the exception stack:
+	//   We can't call 'jmp', since that requires that we load the address
+	//   into a register, and all registers must have their trap-time
+	//   values after the return.
+	//   We can't call 'ret' from the exception stack either, since if we
+	//   did, %esp would have the wrong value.
+	//   So instead, we push the trap-time %eip onto the *trap-time* stack!
+	//   Below we'll switch to that stack and call 'ret', which will
+	//   restore %eip to its pre-fault value.
+	//
+	//   In the case of a recursive fault on the exception stack,
+	//   note that the word we're pushing now will fit in the
+	//   blank word that the kernel reserved for us.
+	//
+	// Throughout the remaining code, think carefully about what
+	// registers are available for intermediate calculations.  You
+	// may find that you have to rearrange your code in non-obvious
+	// ways as registers become unavailable as scratch space.
+	//
+	// LAB 4: Your code here.
+	
+
+	// Guardo el ESP actual
+	movl %esp, %eax
+
+	// Muevo a EAX el valor de viejo de EIP
+	movl 40(%esp), %ebx
+
+	// Seteo el stack del proceso
+	movl 48(%esp), %esp
+
+	// Pongo el EIP viejo en el stack del proceso
+	pushl %ebx
+
+	// Guardo el nuevo valor de %esp del stack del proceso
+	movl %esp, 48(%eax)
+
+	// Recupero el stack de excepcion
+	movl %eax, %esp
+
+	// Restore the trap-time registers.  After you do this, you
+	// can no longer modify any general-purpose registers.
+	// LAB 4: Your code here.
+
+	// Me salteo utf_fault_va y utf_err
+	addl $8, %esp 
+	// Restauro los registros de proposito general
+	popal 
+	
+	// Restore eflags from the stack.  After you do this, you can
+	// no longer use arithmetic operations or anything else that
+	// modifies eflags.
+	// LAB 4: Your code here.
+
+	// Me salteo EIP
+	addl $4, %esp 
+	popfl
+
+	// Switch back to the adjusted trap-time stack.
+	// LAB 4: Your code here.
+
+	// Recupero el stack del proceso
+	popl %esp 
+	
+
+	// Return to re-execute the instruction that faulted.
+	// LAB 4: Your code here.
+
+	ret
diff --git a/lib/pgfault.c b/lib/pgfault.c
new file mode 100644
index 0000000..b24f9c1
--- /dev/null
+++ b/lib/pgfault.c
@@ -0,0 +1,49 @@
+// User-level page fault handler support.
+// Rather than register the C page fault handler directly with the
+// kernel as the page fault handler, we register the assembly language
+// wrapper in pfentry.S, which in turns calls the registered C
+// function.
+
+#include <inc/lib.h>
+
+
+// Assembly language pgfault entrypoint defined in lib/pfentry.S.
+extern void _pgfault_upcall(void);
+
+// Pointer to currently installed C-language pgfault handler.
+void (*_pgfault_handler)(struct UTrapframe *utf);
+
+//
+// Set the page fault handler function.
+// If there isn't one yet, _pgfault_handler will be 0.
+// The first time we register a handler, we need to
+// allocate an exception stack (one page of memory with its top
+// at UXSTACKTOP), and tell the kernel to call the assembly-language
+// _pgfault_upcall routine when a page fault occurs.
+//
+void
+set_pgfault_handler(void (*handler)(struct UTrapframe *utf))
+{
+	int r;
+
+	if (_pgfault_handler == 0) {
+		// First time through!
+		// LAB 4: Your code here.
+		// Reservamos una pagina de memoria en UXSTACKTOP
+		r = sys_page_alloc(0, (void*) (UXSTACKTOP-PGSIZE), PTE_P | PTE_W | PTE_U);
+		if (r < 0) {
+			panic("Error 'set_pgfault_handler': %e\n", r);
+		}
+	}
+
+	// Save handler pointer for assembly to call.
+	_pgfault_handler = handler;
+
+	// Llamamos a la syscall que setea el handler utilizando _pgfault_upcall y no el 
+	// handler recibido como parámetro
+
+	r = sys_env_set_pgfault_upcall(0, _pgfault_upcall);
+	if (r < 0) {
+		panic("Error 'set_pgfault_handler': %e\n", r);
+	}
+}
diff --git a/lib/printfmt.c b/lib/printfmt.c
index b1de635..598ae4c 100644
--- a/lib/printfmt.c
+++ b/lib/printfmt.c
@@ -26,6 +26,8 @@ static const char * const error_string[MAXERROR] =
 	[E_NO_MEM]	= "out of memory",
 	[E_NO_FREE_ENV]	= "out of environments",
 	[E_FAULT]	= "segmentation fault",
+	[E_IPC_NOT_RECV]= "env is not recving",
+	[E_EOF]		= "unexpected end of file",
 };
 
 /*
diff --git a/lib/syscall.c b/lib/syscall.c
index 8d28dda..7880c8a 100644
--- a/lib/syscall.c
+++ b/lib/syscall.c
@@ -61,3 +61,53 @@ sys_getenvid(void)
 	 return syscall(SYS_getenvid, 0, 0, 0, 0, 0, 0);
 }
 
+void
+sys_yield(void)
+{
+	syscall(SYS_yield, 0, 0, 0, 0, 0, 0);
+}
+
+int
+sys_page_alloc(envid_t envid, void *va, int perm)
+{
+	return syscall(SYS_page_alloc, 1, envid, (uint32_t) va, perm, 0, 0);
+}
+
+int
+sys_page_map(envid_t srcenv, void *srcva, envid_t dstenv, void *dstva, int perm)
+{
+	return syscall(SYS_page_map, 1, srcenv, (uint32_t) srcva, dstenv, (uint32_t) dstva, perm);
+}
+
+int
+sys_page_unmap(envid_t envid, void *va)
+{
+	return syscall(SYS_page_unmap, 1, envid, (uint32_t) va, 0, 0, 0);
+}
+
+// sys_exofork is inlined in lib.h
+
+int
+sys_env_set_status(envid_t envid, int status)
+{
+	return syscall(SYS_env_set_status, 1, envid, status, 0, 0, 0);
+}
+
+int
+sys_env_set_pgfault_upcall(envid_t envid, void *upcall)
+{
+	return syscall(SYS_env_set_pgfault_upcall, 1, envid, (uint32_t) upcall, 0, 0, 0);
+}
+
+int
+sys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, int perm)
+{
+	return syscall(SYS_ipc_try_send, 0, envid, value, (uint32_t) srcva, perm, 0);
+}
+
+int
+sys_ipc_recv(void *dstva)
+{
+	return syscall(SYS_ipc_recv, 1, (uint32_t)dstva, 0, 0, 0, 0);
+}
+
diff --git a/user/dumbfork.c b/user/dumbfork.c
new file mode 100644
index 0000000..bbe466e
--- /dev/null
+++ b/user/dumbfork.c
@@ -0,0 +1,106 @@
+// Ping-pong a counter between two processes.
+// Only need to start one of these -- splits into two, crudely.
+
+#include <inc/string.h>
+#include <inc/lib.h>
+
+envid_t dumbfork(void);
+
+void
+umain(int argc, char **argv)
+{
+	envid_t who;
+	int i;
+
+	// fork a child process
+	who = dumbfork();
+
+	// print a message and yield to the other a few times
+	for (i = 0; i < (who ? 10 : 20); i++) {
+		cprintf("%d: I am the %s!\n", i, who ? "parent" : "child");
+		sys_yield();
+	}
+}
+
+void
+duppage(envid_t dstenv, void *addr)
+{
+	int r;
+
+	// This is NOT what you should do in your fork.
+
+	// Aloca una pagina para el proceso destino (destenv)
+	// y la mapea en addr, con permisos de escritura
+	if ((r = sys_page_alloc(dstenv, addr, PTE_P|PTE_U|PTE_W)) < 0)
+		panic("sys_page_alloc: %e", r);
+
+	// Mapea la pagina del hijo previamente alocada (addr de dstenv)
+	// en el proceso padre (0 = currenv = proceso padre) en la direccion UTEMP
+	if ((r = sys_page_map(dstenv, addr, 0, UTEMP, PTE_P|PTE_U|PTE_W)) < 0)
+		panic("sys_page_map: %e", r);
+	
+	// Copia el contenido de la pagina addr (del padre)
+	// en UTEMP (del padre) que esta mapeada con addr (del hijo)
+	// Es decir esta copiando el contenido padre de addr en 
+	// la pagina del hijo (copia del A.S.)
+	memmove(UTEMP, addr, PGSIZE);
+
+	// Desmapea el mapeo previo (fue temporal) ya que
+	// solo tenia como objetivo poder copiar el contenido
+	// de la pagina padre a una mapeada con el hijo
+	// (es el modo de copiar el AS al padre al hijo)
+	// por ello el mapeo ya no es necesario
+	// 0 = currenv = padre
+	if ((r = sys_page_unmap(0, UTEMP)) < 0)
+		panic("sys_page_unmap: %e", r);
+}
+
+/*
+Implementación de fork() altamente ineficiente, 
+pues copia físicamente (página a página) el espacio de memoria de padre a hijo. 
+*/
+envid_t
+dumbfork(void)
+{
+	envid_t envid;
+	uint8_t *addr;
+	int r;
+	extern unsigned char end[];
+
+	// Allocate a new child environment.
+	// The kernel will initialize it with a copy of our register state,
+	// so that the child will appear to have called sys_exofork() too -
+	// except that in the child, this "fake" call to sys_exofork()
+	// will return 0 instead of the envid of the child.
+
+	// Aloca un nuevo environment copiando el trapframe del padre
+	envid = sys_exofork();
+	if (envid < 0)
+		panic("sys_exofork: %e", envid);
+	if (envid == 0) {
+		// We're the child.
+		// The copied value of the global variable 'thisenv'
+		// is no longer valid (it refers to the parent!).
+		// Fix it and return 0.
+		thisenv = &envs[ENVX(sys_getenvid())];
+		return 0;
+	}
+
+	// We're the parent.
+	// Eagerly copy our entire address space into the child.
+	// This is NOT what you should do in your fork implementation.
+
+	// Copiamos en el address space del hijo, el Program Data & Heap del padre
+	for (addr = (uint8_t*) UTEXT; addr < end; addr += PGSIZE)
+		duppage(envid, addr); // Llama a duppage con el envid del hijo
+
+	// Also copy the stack we are currently running on.
+	duppage(envid, ROUNDDOWN(&addr, PGSIZE));
+
+	// Start the child environment running
+	if ((r = sys_env_set_status(envid, ENV_RUNNABLE)) < 0)
+		panic("sys_env_set_status: %e", r);
+
+	return envid;
+}
+
diff --git a/user/fairness.c b/user/fairness.c
new file mode 100644
index 0000000..f83b0db
--- /dev/null
+++ b/user/fairness.c
@@ -0,0 +1,25 @@
+// Demonstrate lack of fairness in IPC.
+// Start three instances of this program as envs 1, 2, and 3.
+// (user/idle is env 0).
+
+#include <inc/lib.h>
+
+void
+umain(int argc, char **argv)
+{
+	envid_t who, id;
+
+	id = sys_getenvid();
+
+	if (thisenv == &envs[1]) {
+		while (1) {
+			ipc_recv(&who, 0, 0);
+			cprintf("%x recv from %x\n", id, who);
+		}
+	} else {
+		cprintf("%x loop sending to %x\n", id, envs[1].env_id);
+		while (1)
+			ipc_send(envs[1].env_id, 0, 0, 0);
+	}
+}
+
diff --git a/user/faultalloc.c b/user/faultalloc.c
new file mode 100644
index 0000000..df575b7
--- /dev/null
+++ b/user/faultalloc.c
@@ -0,0 +1,24 @@
+// test user-level fault handler -- alloc pages to fix faults
+
+#include <inc/lib.h>
+
+void
+handler(struct UTrapframe *utf)
+{
+	int r;
+	void *addr = (void*)utf->utf_fault_va;
+
+	cprintf("fault %x\n", addr);
+	if ((r = sys_page_alloc(0, ROUNDDOWN(addr, PGSIZE),
+				PTE_P|PTE_U|PTE_W)) < 0)
+		panic("allocating at %x in page fault handler: %e", addr, r);
+	snprintf((char*) addr, 100, "this string was faulted in at %x", addr);
+}
+
+void
+umain(int argc, char **argv)
+{
+	set_pgfault_handler(handler);
+	cprintf("%s\n", (char*)0xDeadBeef);
+	cprintf("%s\n", (char*)0xCafeBffe);
+}
diff --git a/user/faultallocbad.c b/user/faultallocbad.c
new file mode 100644
index 0000000..2c0898a
--- /dev/null
+++ b/user/faultallocbad.c
@@ -0,0 +1,24 @@
+// test user-level fault handler -- alloc pages to fix faults
+// doesn't work because we sys_cputs instead of cprintf (exercise: why?)
+
+#include <inc/lib.h>
+
+void
+handler(struct UTrapframe *utf)
+{
+	int r;
+	void *addr = (void*)utf->utf_fault_va;
+
+	cprintf("fault %x\n", addr);
+	if ((r = sys_page_alloc(0, ROUNDDOWN(addr, PGSIZE),
+				PTE_P|PTE_U|PTE_W)) < 0)
+		panic("allocating at %x in page fault handler: %e", addr, r);
+	snprintf((char*) addr, 100, "this string was faulted in at %x", addr);
+}
+
+void
+umain(int argc, char **argv)
+{
+	set_pgfault_handler(handler);
+	sys_cputs((char*)0xDEADBEEF, 4);
+}
diff --git a/user/faultbadhandler.c b/user/faultbadhandler.c
new file mode 100644
index 0000000..bda12d3
--- /dev/null
+++ b/user/faultbadhandler.c
@@ -0,0 +1,14 @@
+// test bad pointer for user-level fault handler
+// this is going to fault in the fault handler accessing eip (always!)
+// so eventually the kernel kills it (PFM_KILL) because
+// we outrun the stack with invocations of the user-level handler
+
+#include <inc/lib.h>
+
+void
+umain(int argc, char **argv)
+{
+	sys_page_alloc(0, (void*) (UXSTACKTOP - PGSIZE), PTE_P|PTE_U|PTE_W);
+	sys_env_set_pgfault_upcall(0, (void*) 0xDeadBeef);
+	*(int*)0 = 0;
+}
diff --git a/user/faultdie.c b/user/faultdie.c
new file mode 100644
index 0000000..4959d11
--- /dev/null
+++ b/user/faultdie.c
@@ -0,0 +1,19 @@
+// test user-level fault handler -- just exit when we fault
+
+#include <inc/lib.h>
+
+void
+handler(struct UTrapframe *utf)
+{
+	void *addr = (void*)utf->utf_fault_va;
+	uint32_t err = utf->utf_err;
+	cprintf("i faulted at va %x, err %x\n", addr, err & 7);
+	sys_env_destroy(sys_getenvid());
+}
+
+void
+umain(int argc, char **argv)
+{
+	set_pgfault_handler(handler);
+	*(int*)0xDeadBeef = 0;
+}
diff --git a/user/faultevilhandler.c b/user/faultevilhandler.c
new file mode 100644
index 0000000..d53342e
--- /dev/null
+++ b/user/faultevilhandler.c
@@ -0,0 +1,11 @@
+// test evil pointer for user-level fault handler
+
+#include <inc/lib.h>
+
+void
+umain(int argc, char **argv)
+{
+	sys_page_alloc(0, (void*) (UXSTACKTOP - PGSIZE), PTE_P|PTE_U|PTE_W);
+	sys_env_set_pgfault_upcall(0, (void*) 0xF0100020);
+	*(int*)0 = 0;
+}
diff --git a/user/faultnostack.c b/user/faultnostack.c
new file mode 100644
index 0000000..d4028c7
--- /dev/null
+++ b/user/faultnostack.c
@@ -0,0 +1,12 @@
+// test user fault handler being called with no exception stack mapped
+
+#include <inc/lib.h>
+
+void _pgfault_upcall();
+
+void
+umain(int argc, char **argv)
+{
+	sys_env_set_pgfault_upcall(0, (void*) _pgfault_upcall);
+	*(int*)0 = 0;
+}
diff --git a/user/faultregs.c b/user/faultregs.c
new file mode 100644
index 0000000..21f98bd
--- /dev/null
+++ b/user/faultregs.c
@@ -0,0 +1,146 @@
+// test register restore on user-level page fault return
+
+#include <inc/lib.h>
+
+struct regs
+{
+	struct PushRegs regs;
+	uintptr_t eip;
+	uint32_t eflags;
+	uintptr_t esp;
+};
+
+#define SAVE_REGS(base) \
+	"\tmovl %%edi, "base"+0x00\n" \
+	"\tmovl %%esi, "base"+0x04\n" \
+	"\tmovl %%ebp, "base"+0x08\n" \
+	"\tmovl %%ebx, "base"+0x10\n" \
+	"\tmovl %%edx, "base"+0x14\n" \
+	"\tmovl %%ecx, "base"+0x18\n" \
+	"\tmovl %%eax, "base"+0x1c\n" \
+	"\tmovl %%esp, "base"+0x28\n"
+
+#define LOAD_REGS(base) \
+	"\tmovl "base"+0x00, %%edi\n" \
+	"\tmovl "base"+0x04, %%esi\n" \
+	"\tmovl "base"+0x08, %%ebp\n" \
+	"\tmovl "base"+0x10, %%ebx\n" \
+	"\tmovl "base"+0x14, %%edx\n" \
+	"\tmovl "base"+0x18, %%ecx\n" \
+	"\tmovl "base"+0x1c, %%eax\n" \
+	"\tmovl "base"+0x28, %%esp\n"
+
+static struct regs before, during, after;
+
+static void
+check_regs(struct regs* a, const char *an, struct regs* b, const char *bn,
+	   const char *testname)
+{
+	int mismatch = 0;
+
+	cprintf("%-6s %-8s %-8s\n", "", an, bn);
+
+#define CHECK(name, field)						\
+	do {								\
+		cprintf("%-6s %08x %08x ", #name, a->field, b->field);	\
+		if (a->field == b->field)				\
+			cprintf("OK\n");				\
+		else {							\
+			cprintf("MISMATCH\n");				\
+			mismatch = 1;					\
+		}							\
+	} while (0)
+
+	CHECK(edi, regs.reg_edi);
+	CHECK(esi, regs.reg_esi);
+	CHECK(ebp, regs.reg_ebp);
+	CHECK(ebx, regs.reg_ebx);
+	CHECK(edx, regs.reg_edx);
+	CHECK(ecx, regs.reg_ecx);
+	CHECK(eax, regs.reg_eax);
+	CHECK(eip, eip);
+	CHECK(eflags, eflags);
+	CHECK(esp, esp);
+
+#undef CHECK
+
+	cprintf("Registers %s ", testname);
+	if (!mismatch)
+		cprintf("OK\n");
+	else
+		cprintf("MISMATCH\n");
+}
+
+static void
+pgfault(struct UTrapframe *utf)
+{
+	int r;
+
+	if (utf->utf_fault_va != (uint32_t)UTEMP)
+		panic("pgfault expected at UTEMP, got 0x%08x (eip %08x)",
+		      utf->utf_fault_va, utf->utf_eip);
+
+	// Check registers in UTrapframe
+	during.regs = utf->utf_regs;
+	during.eip = utf->utf_eip;
+	during.eflags = utf->utf_eflags & ~FL_RF;
+	during.esp = utf->utf_esp;
+	check_regs(&before, "before", &during, "during", "in UTrapframe");
+
+	// Map UTEMP so the write succeeds
+	if ((r = sys_page_alloc(0, UTEMP, PTE_U|PTE_P|PTE_W)) < 0)
+		panic("sys_page_alloc: %e", r);
+}
+
+void
+umain(int argc, char **argv)
+{
+	set_pgfault_handler(pgfault);
+
+	asm volatile(
+		// Light up eflags to catch more errors
+		"\tpushl %%eax\n"
+		"\tpushfl\n"
+		"\tpopl %%eax\n"
+		"\torl $0x8d5, %%eax\n"
+		"\tpushl %%eax\n"
+		"\tpopfl\n"
+
+		// Save before registers
+		// eflags
+		"\tmov %%eax, %0+0x24\n"
+		// eip
+		"\tleal 0f, %%eax\n"
+		"\tmovl %%eax, %0+0x20\n"
+		"\tpopl %%eax\n"
+		// others
+		SAVE_REGS("%0")
+
+		// Fault at UTEMP
+		"\t0: movl $42, 0x400000\n"
+
+		// Save after registers (except eip and eflags)
+		SAVE_REGS("%1")
+		// Restore registers (except eip and eflags).  This
+		// way, the test will run even if EIP is the *only*
+		// thing restored correctly.
+		LOAD_REGS("%0")
+		// Save after eflags (now that stack is back); note
+		// that we were very careful not to modify eflags in
+		// since we saved it
+		"\tpushl %%eax\n"
+		"\tpushfl\n"
+		"\tpopl %%eax\n"
+		"\tmov %%eax, %1+0x24\n"
+		"\tpopl %%eax\n"
+		: : "m" (before), "m" (after) : "memory", "cc");
+
+	// Check UTEMP to roughly determine that EIP was restored
+	// correctly (of course, we probably wouldn't get this far if
+	// it weren't)
+	if (*(int*)UTEMP != 42)
+		cprintf("EIP after page-fault MISMATCH\n");
+	after.eip = before.eip;
+
+	check_regs(&before, "before", &after, "after", "after page-fault");
+}
diff --git a/user/forktree.c b/user/forktree.c
new file mode 100644
index 0000000..57c36f5
--- /dev/null
+++ b/user/forktree.c
@@ -0,0 +1,38 @@
+// Fork a binary tree of processes and display their structure.
+
+#include <inc/lib.h>
+
+#define DEPTH 3
+
+void forktree(const char *cur);
+
+void
+forkchild(const char *cur, char branch)
+{
+	char nxt[DEPTH+1];
+
+	if (strlen(cur) >= DEPTH)
+		return;
+
+	snprintf(nxt, DEPTH+1, "%s%c", cur, branch);
+	if (fork() == 0) {
+		forktree(nxt);
+		exit();
+	}
+}
+
+void
+forktree(const char *cur)
+{
+	cprintf("%04x: I am '%s'\n", sys_getenvid(), cur);
+
+	forkchild(cur, '0');
+	forkchild(cur, '1');
+}
+
+void
+umain(int argc, char **argv)
+{
+	forktree("");
+}
+
diff --git a/user/hello.c b/user/hello.c
index 486c9dc..2e77b03 100644
--- a/user/hello.c
+++ b/user/hello.c
@@ -5,5 +5,5 @@ void
 umain(int argc, char **argv)
 {
 	cprintf("hello, world\n");
-	cprintf("i am environment %08x\n", thisenv->env_id);
+	cprintf("i am environment %08x\n", sys_getenvid());
 }
diff --git a/user/idle.c b/user/idle.c
new file mode 100644
index 0000000..4ae8b51
--- /dev/null
+++ b/user/idle.c
@@ -0,0 +1,20 @@
+// idle loop
+
+#include <inc/x86.h>
+#include <inc/lib.h>
+
+void
+umain(int argc, char **argv)
+{
+	binaryname = "idle";
+
+	// Loop forever, simply trying to yield to a different environment.
+	// Instead of busy-waiting like this,
+	// a better way would be to use the processor's HLT instruction
+	// to cause the processor to stop executing until the next interrupt -
+	// doing so allows the processor to conserve power more effectively.
+	while (1) {
+		sys_yield();
+	}
+}
+
diff --git a/user/pingpong.c b/user/pingpong.c
new file mode 100644
index 0000000..8fbe3bb
--- /dev/null
+++ b/user/pingpong.c
@@ -0,0 +1,29 @@
+// Ping-pong a counter between two processes.
+// Only need to start one of these -- splits into two with fork.
+
+#include <inc/lib.h>
+
+void
+umain(int argc, char **argv)
+{
+	envid_t who;
+
+	if ((who = fork()) != 0) {
+		// get the ball rolling
+		cprintf("send 0 from %x to %x\n", sys_getenvid(), who);
+		ipc_send(who, 0, 0, 0);
+	}
+
+	while (1) {
+		uint32_t i = ipc_recv(&who, 0, 0);
+		cprintf("%x got %d from %x\n", sys_getenvid(), i, who);
+		if (i == 10)
+			return;
+		i++;
+		ipc_send(who, i, 0, 0);
+		if (i == 10)
+			return;
+	}
+
+}
+
diff --git a/user/pingpongs.c b/user/pingpongs.c
new file mode 100644
index 0000000..42f1bb1
--- /dev/null
+++ b/user/pingpongs.c
@@ -0,0 +1,33 @@
+// Ping-pong a counter between two shared-memory processes.
+// Only need to start one of these -- splits into two with sfork.
+
+#include <inc/lib.h>
+
+uint32_t val;
+
+void
+umain(int argc, char **argv)
+{
+	envid_t who;
+	uint32_t i;
+
+	i = 0;
+	if ((who = sfork()) != 0) {
+		cprintf("i am %08x; thisenv is %p\n", sys_getenvid(), thisenv);
+		// get the ball rolling
+		cprintf("send 0 from %x to %x\n", sys_getenvid(), who);
+		ipc_send(who, 0, 0, 0);
+	}
+
+	while (1) {
+		ipc_recv(&who, 0, 0);
+		cprintf("%x got %d from %x (thisenv is %p %x)\n", sys_getenvid(), val, who, thisenv, thisenv->env_id);
+		if (val == 10)
+			return;
+		++val;
+		ipc_send(who, 0, 0, 0);
+		if (val == 10)
+			return;
+	}
+
+}
diff --git a/user/primes.c b/user/primes.c
new file mode 100644
index 0000000..a9219f0
--- /dev/null
+++ b/user/primes.c
@@ -0,0 +1,53 @@
+// Concurrent version of prime sieve of Eratosthenes.
+// Invented by Doug McIlroy, inventor of Unix pipes.
+// See http://swtch.com/~rsc/thread/.
+// The picture halfway down the page and the text surrounding it
+// explain what's going on here.
+//
+// Since NENVS is 1024, we can print 1022 primes before running out.
+// The remaining two environments are the integer generator at the bottom
+// of main and user/idle.
+
+#include <inc/lib.h>
+
+unsigned
+primeproc(void)
+{
+	int i, id, p;
+	envid_t envid;
+
+	// fetch a prime from our left neighbor
+top:
+	p = ipc_recv(&envid, 0, 0);
+	cprintf("CPU %d: %d ", thisenv->env_cpunum, p);
+
+	// fork a right neighbor to continue the chain
+	if ((id = fork()) < 0)
+		panic("fork: %e", id);
+	if (id == 0)
+		goto top;
+
+	// filter out multiples of our prime
+	while (1) {
+		i = ipc_recv(&envid, 0, 0);
+		if (i % p)
+			ipc_send(id, i, 0, 0);
+	}
+}
+
+void
+umain(int argc, char **argv)
+{
+	int i, id;
+
+	// fork the first prime process in the chain
+	if ((id = fork()) < 0)
+		panic("fork: %e", id);
+	if (id == 0)
+		primeproc();
+
+	// feed all the integers through
+	for (i = 2; ; i++)
+		ipc_send(id, i, 0, 0);
+}
+
diff --git a/user/sendpage.c b/user/sendpage.c
index 1adfe94..d956f2b 100644
--- a/user/sendpage.c
+++ b/user/sendpage.c
@@ -17,7 +17,8 @@ umain(int argc, char **argv)
 	if ((who = fork()) == 0) {
 		// Child
 		ipc_recv(&who, TEMP_ADDR_CHILD, 0);
-		cprintf("%x got message: %s\n", who, TEMP_ADDR_CHILD);
+		cprintf("%x got message from %x: %s\n",
+			thisenv->env_id, who, TEMP_ADDR_CHILD);
 		if (strncmp(TEMP_ADDR_CHILD, str1, strlen(str1)) == 0)
 			cprintf("child received correct message\n");
 
@@ -32,7 +33,8 @@ umain(int argc, char **argv)
 	ipc_send(who, 0, TEMP_ADDR, PTE_P | PTE_W | PTE_U);
 
 	ipc_recv(&who, TEMP_ADDR, 0);
-	cprintf("%x got message: %s\n", who, TEMP_ADDR);
+	cprintf("%x got message from %x: %s\n",
+		thisenv->env_id, who, TEMP_ADDR);
 	if (strncmp(TEMP_ADDR, str2, strlen(str2)) == 0)
 		cprintf("parent received correct message\n");
 	return;
diff --git a/user/spin.c b/user/spin.c
new file mode 100644
index 0000000..6f0b920
--- /dev/null
+++ b/user/spin.c
@@ -0,0 +1,31 @@
+// Test preemption by forking off a child process that just spins forever.
+// Let it run for a couple time slices, then kill it.
+
+#include <inc/lib.h>
+
+void
+umain(int argc, char **argv)
+{
+	envid_t env;
+
+	cprintf("I am the parent.  Forking the child...\n");
+	if ((env = fork()) == 0) {
+		cprintf("I am the child.  Spinning...\n");
+		while (1)
+			/* do nothing */;
+	}
+
+	cprintf("I am the parent.  Running the child...\n");
+	sys_yield();
+	sys_yield();
+	sys_yield();
+	sys_yield();
+	sys_yield();
+	sys_yield();
+	sys_yield();
+	sys_yield();
+
+	cprintf("I am the parent.  Killing the child...\n");
+	sys_env_destroy(env);
+}
+
diff --git a/user/spin0.c b/user/spin0.c
new file mode 100644
index 0000000..e54b067
--- /dev/null
+++ b/user/spin0.c
@@ -0,0 +1,25 @@
+// Forkless spin; pid 0 spins, pid 1 yields.
+
+#include <inc/lib.h>
+#define TICK (1U << 15)
+
+void
+umain(int argc, char **argv)
+{
+	envid_t me = sys_getenvid();
+	unsigned n = 0;
+	bool yield = me & 1;
+
+	while (n++ < 5 || !yield) {
+		unsigned i = TICK;
+		while (i--)
+			;
+		if (yield) {
+			cprintf("I am %08x and I like my interrupt #%u\n", me, n);
+			sys_yield();
+		}
+		else {
+			cprintf("I am %08x and my spin will go on #%u\n", me, n);
+		}
+	}
+}
diff --git a/user/stresssched.c b/user/stresssched.c
new file mode 100644
index 0000000..0faa7e5
--- /dev/null
+++ b/user/stresssched.c
@@ -0,0 +1,39 @@
+#include <inc/lib.h>
+
+volatile int counter;
+
+void
+umain(int argc, char **argv)
+{
+	int i, j;
+	int seen;
+	envid_t parent = sys_getenvid();
+
+	// Fork several environments
+	for (i = 0; i < 20; i++)
+		if (fork() == 0)
+			break;
+	if (i == 20) {
+		sys_yield();
+		return;
+	}
+
+	// Wait for the parent to finish forking
+	while (envs[ENVX(parent)].env_status != ENV_FREE)
+		asm volatile("pause");
+
+	// Check that one environment doesn't run on two CPUs at once
+	for (i = 0; i < 10; i++) {
+		sys_yield();
+		for (j = 0; j < 10000; j++)
+			counter++;
+	}
+
+	if (counter != 10*10000)
+		panic("ran on two CPUs at once (counter is %d)", counter);
+
+	// Check that we see environments running on different CPUs
+	cprintf("[%08x] stresssched on CPU %d\n", thisenv->env_id, thisenv->env_cpunum);
+
+}
+
diff --git a/user/yield.c b/user/yield.c
new file mode 100644
index 0000000..27a003f
--- /dev/null
+++ b/user/yield.c
@@ -0,0 +1,16 @@
+// yield the processor to other environments
+
+#include <inc/lib.h>
+
+void
+umain(int argc, char **argv)
+{
+	int i;
+
+	cprintf("Hello, I am environment %08x, cpu %d.\n", thisenv->env_id, thisenv->env_cpunum);
+	for (i = 0; i < 5; i++) {
+		sys_yield();
+		cprintf("Back in environment %08x, iteration %d, cpu %d.\n", thisenv->env_id, i, thisenv->env_cpunum);
+	}
+	cprintf("All done in environment %08x.\n", thisenv->env_id);
+}
